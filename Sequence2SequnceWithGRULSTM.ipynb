{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sequence2SequnceWithGRULSTM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMzT4eYOnxMzWmfH8Wpyl8V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"yKn6Fzlr9eNx"},"source":["from google.colab import files\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense,Input,GRU,LSTM\n","from tensorflow.keras.models import Model\n","import keras.backend as K\n","from tensorflow.keras.callbacks import LearningRateScheduler\n","from keras.callbacks import ReduceLROnPlateau"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"3coHd6J_GRgm","executionInfo":{"status":"ok","timestamp":1616302554952,"user_tz":-330,"elapsed":6246,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"f1bb3cde-7303-40a3-8837-57f64183d839"},"source":["tf.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"JKmDCdznF33p"},"source":["#!pip install tensorflow-gpu==2.3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":72},"id":"8EdlqGzM9n7a","executionInfo":{"status":"ok","timestamp":1616302570594,"user_tz":-330,"elapsed":14006,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"8e243662-7970-4ab5-c0a5-02515f7fc0f9"},"source":["uploaded=files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-3bdc1907-ebd1-4b7b-835a-9ab45904d7d0\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-3bdc1907-ebd1-4b7b-835a-9ab45904d7d0\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving prepared_data.csv to prepared_data.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xeGzPq7N-jMG","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1616302573218,"user_tz":-330,"elapsed":1016,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"139c9d0b-bce2-4c72-c3be-8a3fc4211664"},"source":["data=pd.read_csv('prepared_data.csv')\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SMS_TEXT</th>\n","      <th>ENGLISH_TEXT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>U wan me to \"chop\" seat 4 u nt?</td>\n","      <td>Do you want me to reserve seat for you or not?</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Yup. U reaching. We order some durian pastry a...</td>\n","      <td>Yeap. You reaching? We ordered some Durian pas...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>They become more ex oredi... Mine is like 25.....</td>\n","      <td>They become more expensive already. Mine is li...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I'm thai. what do u do?</td>\n","      <td>I'm Thai. What do you do?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Hi! How did your week go? Haven heard from you...</td>\n","      <td>Hi! How did your week go? Haven't heard from y...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            SMS_TEXT                                       ENGLISH_TEXT\n","0                    U wan me to \"chop\" seat 4 u nt?     Do you want me to reserve seat for you or not?\n","1  Yup. U reaching. We order some durian pastry a...  Yeap. You reaching? We ordered some Durian pas...\n","2  They become more ex oredi... Mine is like 25.....  They become more expensive already. Mine is li...\n","3                            I'm thai. what do u do?                          I'm Thai. What do you do?\n","4  Hi! How did your week go? Haven heard from you...  Hi! How did your week go? Haven't heard from y..."]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"aShXbLJs_f60"},"source":["def preprocessing_steps(data):\n","    \"\"\"Applying the length on both sms_text and english_text and filtering the sentences based on length \n","    adding start token and end token for inputs and output dataframe\n","    \\t-> start token which represents start of the sentence\n","    \\n-> end token which represents end of the sentence.\n","    Removing the sms_length, english_length, and ENGLISH_TEXT and appending ENGLISH_INPUT,ENGLISH_OUTPUT for the decoder.\"\"\"\n","    data['sms_length']=data['SMS_TEXT'].apply(len)\n","    data['eng_length']=data['ENGLISH_TEXT'].apply(len)\n","    data=data[data['sms_length']<=170]\n","    data=data[data['eng_length']<=200]\n","    data['ENGLISH_INPUT']='\\t '+data['ENGLISH_TEXT'].astype(str)\n","    data['ENGLISH_OUTPUT']=data['ENGLISH_TEXT'].astype(str)+' \\n'\n","    data=data.drop(['sms_length','eng_length','ENGLISH_TEXT'],axis=1)\n","    return data\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aLYMpA4RSKOz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616302582909,"user_tz":-330,"elapsed":1167,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"892f5aef-711b-4a94-9d04-2efd8c84afa0"},"source":["preprocessed_data=preprocessing_steps(data)\n","print(preprocessed_data.shape)\n","preprocessed_data.iloc[0]['ENGLISH_INPUT']=str(preprocessed_data.iloc[0]['ENGLISH_INPUT'])+' \\n'\n","preprocessed_data.iloc[0]['ENGLISH_OUTPUT']=str(preprocessed_data.iloc[0]['ENGLISH_OUTPUT'])+' \\n'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1993, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzFE-ifrWD1j","executionInfo":{"status":"ok","timestamp":1616302586641,"user_tz":-330,"elapsed":1658,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"69938a6e-7eb4-484d-bf6f-ee51e4b84174"},"source":["from sklearn.model_selection import train_test_split\n","train_data,test_data= train_test_split(preprocessed_data,test_size=0.01, random_state=42)\n","print(train_data.shape)\n","print(test_data.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1973, 3)\n","(20, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w4yqfMq1Fp1H"},"source":["def preparing_data_for_model(preprocessed_data):\n","    \"\"\"1. Creating input and output characters list.\n","       2. Creating input and output vocabluary list\n","       3. Initialising np.array with zeros for encoder_input_data,decoder_input_data and decoder_output_data.\n","       4. One hot encoding of encoder_input_data,decoder_input_data and decoder_output_data.\n","       5. Decoder_output_data would be one time step ahead of decoder_input_data which is known as teacher enforcing.\n","       6. Return input_token_index,output_token_index,encoder_input_data,decoder_output_data,decoder_input_data.\n","    \"\"\"\n","    #creating vocabluary.\n","    input_charcters_list=sorted(list(set(preprocessed_data['SMS_TEXT'].apply(list).sum())))\n","    output_charcters_list=sorted(list(set(preprocessed_data['ENGLISH_INPUT'].apply(list).sum())))\n","    input_token_index = dict((c, i) for i, c in enumerate(input_charcters_list))   \n","    output_token_index=dict((c, i) for i, c in enumerate(output_charcters_list))\n","    print(len(input_token_index))\n","    print(len(output_token_index))\n","    #intialising np.array with zeros for one hot encoding.\n","    encoder_input_data = np.zeros((len(preprocessed_data),170,len(input_token_index)), dtype=\"int32\")\n","    decoder_input_data = np.zeros((len(preprocessed_data),202,len(output_token_index)), dtype=\"int32\")\n","    decoder_output_data = np.zeros((len(preprocessed_data),202,len(output_token_index)), dtype=\"int32\")\n","    #one hot encoding of encoder input data\n","    for i,input_text in enumerate(list(preprocessed_data['SMS_TEXT'].values)):\n","        for t,char in enumerate(input_text):\n","            encoder_input_data[i,t,input_token_index[char]]=1\n","        encoder_input_data[i,t+1,input_token_index[\" \"]]=1   \n","    #one hot encoding of decoder input data and decoder output data   \n","    for i,output_text in enumerate(list(preprocessed_data['ENGLISH_INPUT'].values)):\n","        for t,char in enumerate(output_text):\n","            decoder_input_data[i,t,output_token_index[char]]=1\n","            if t > 0:\n","            # decoder_target_data will be ahead by one timestep\n","            # and will not include the start character.\n","               decoder_output_data[i, t - 1, output_token_index[char]] = 1\n","        decoder_input_data[i, t + 1 :, output_token_index[\" \"]] = 1\n","        decoder_output_data[i, t:, output_token_index[\" \"]] = 1   \n","    return input_token_index,output_token_index,encoder_input_data,decoder_input_data,decoder_output_data  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V33iwxlFRyHi"},"source":["def preparing_val_data_for_model(preprocessed_data,input_token_index,output_token_index):\n","    \"\"\"1. Getting the arguments as data,input token vocabulary and output token vocabulary.\n","       2. Initialising np.array with zeros for encoder_input_data,decoder_input_data and decoder_output_data.\n","       3. One hot encoding of encoder_input_data,decoder_input_data and decoder_output_data.\n","       4. Decoder_output_data would be one time step ahead of decoder_input_data which is known as teacher enforcing.\n","       5. Return encoder_input_data,decoder_output_data,decoder_input_data.\n","    \"\"\"\n","    \n","   \n","    #intialising np.array with zeros for one hot encoding.\n","    encoder_input_data = np.zeros((len(preprocessed_data),170,len(input_token_index)), dtype=\"int32\")\n","    decoder_input_data = np.zeros((len(preprocessed_data),202,len(output_token_index)), dtype=\"int32\")\n","    decoder_output_data = np.zeros((len(preprocessed_data),202,len(output_token_index)), dtype=\"int32\")\n","    #one hot encoding of encoder input data\n","    for i,input_text in enumerate(list(preprocessed_data['SMS_TEXT'].values)):\n","        for t,char in enumerate(input_text):\n","            encoder_input_data[i,t,input_token_index[char]]=1\n","        encoder_input_data[i,t+1,input_token_index[\" \"]]=1   \n","    #one hot encoding of decoder input data and decoder output data   \n","    for i,output_text in enumerate(list(preprocessed_data['ENGLISH_INPUT'].values)):\n","        for t,char in enumerate(output_text):\n","            decoder_input_data[i,t,output_token_index[char]]=1\n","            if t > 0:\n","            # decoder_target_data will be ahead by one timestep\n","            # and will not include the start character.\n","               decoder_output_data[i, t - 1, output_token_index[char]] = 1\n","        decoder_input_data[i, t + 1 :, output_token_index[\" \"]] = 1\n","        decoder_output_data[i, t:, output_token_index[\" \"]] = 1   \n","    return encoder_input_data,decoder_input_data,decoder_output_data  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SyF5rPwy5EK2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616302603891,"user_tz":-330,"elapsed":1981,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"3e7f3a95-abbb-4251-a3d9-fb42fb0f167c"},"source":["#for trained data\n","input_token_index,output_token_index,encoder_input_data,decoder_input_data,decoder_output_data=preparing_data_for_model(train_data)\n","#for validation data\n","cv_encoder_input_data,cv_decoder_input_data,cv_decoder_output_data=preparing_val_data_for_model(test_data,input_token_index,output_token_index)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["103\n","92\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TIK8MpenHIgu"},"source":["<h2> GRU </h2>"]},{"cell_type":"code","metadata":{"id":"9KVkU_yzTDt1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616214647553,"user_tz":-330,"elapsed":1458,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"dc6191f2-7629-4647-880c-300ce0c3996f"},"source":["tf.keras.backend.clear_session()\n","encoder_inputs = tf.keras.Input(shape=(None,len(input_token_index)))\n","encoder = tf.keras.layers.GRU(100, return_state=True)\n","encoder_outputs,state_h= encoder(encoder_inputs)\n","#storing encoder states\n","encoder_states = state_h\n"," \n","# Set up the decoder, using encoder_states as initial state.\n","decoder_inputs = tf.keras.Input(shape=(None, len(output_token_index)))\n"," \n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_gru = tf.keras.layers.GRU(100, return_sequences=True, return_state=True)\n","decoder_outputs, _ = decoder_gru(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = tf.keras.layers.Dense(len(output_token_index), activation=\"softmax\")\n","decoder_outputs = decoder_dense(decoder_outputs)\n"," \n","# Define the model\n","model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None, 103)]  0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None, 92)]   0                                            \n","__________________________________________________________________________________________________\n","gru (GRU)                       [(None, 100), (None, 61500       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","gru_1 (GRU)                     [(None, None, 100),  58200       input_2[0][0]                    \n","                                                                 gru[0][1]                        \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 92)     9292        gru_1[0][0]                      \n","==================================================================================================\n","Total params: 128,992\n","Trainable params: 128,992\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":422},"id":"tBUKwNcXspSl","executionInfo":{"status":"ok","timestamp":1616153972744,"user_tz":-330,"elapsed":1627,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"2084e8f3-94c9-4c09-a66e-0a86cd9bb17f"},"source":["tf.keras.utils.plot_model(model, show_shapes=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAA3IAAAGVCAIAAAA0a1SlAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdeVwTV78/8BNIyGbCIgiUTRYRcW2rVUB+1LpU5RFFRLlqLfq6vWhtEbciVhARrYqPcKHw+HKp7aOtuEDBoqhFi5aKPlZFKCoirriBiISdEOb3x9w7N09ACCEhAT7vv5xzJjPfmYwnX2bOnMOiKIoAAAAAAHSNnrYDAAAAAIDeAGklAAAAAKgB0koAAAAAUAOklQAAAACgBmz5hdzc3F27dmkrFAAA3eTm5rZq1SptRwEAoOv+7W7lkydPjh8/rq1QQDcdP368tLRU21Fo3OXLly9fvqztKEAXXb58OTc3V9tRAAD0AOzWRceOHev+OEBnsVislStXzp07V9uBaJa/vz/BxQ9toa8NAADoEPpWAgAAAIAaIK0EAAAAADVAWgkAAAAAaoC0EgAAAADUAGklAAAAAKgB0krQiFOnThkaGv7yyy/aDkTNli5dyvpfCxculK/KysoKCwtLSUlxcHCgV/jkk0/kV5gyZYpIJNLX1x86dOj169e7N3BCCNHl2BgtLS2xsbHu7u6tq3Jycjw8PAQCgaWlZWhoaGNjI1O1fft2FxcXPp8vFApdXFzCw8MlEglddeLEie3bt8tkMmbltLQ05ks0NTXV9BEBAPQdSCtBIyiK0nYImmJiYpKZmVlUVLR//36mcOPGjfHx8evXr/fz87t//76jo2P//v0PHTp08uRJZp2zZ88eO3ZsxowZhYWF7733XvdHrsux0YqLi//f//t/q1atqqurU6gqLCycMmXKxIkTy8vLU1NTv/vuu2XLljG1v//++2efffb48eOXL19u3rx5+/btc+bMoat8fHx4PN7EiRPfvHlDl8ycObO0tPTixYvTp0/vnuMCAOgjkFaCRnh7e1dVVc2YMUPTO6qvr2/zzpbm8Pn8qVOnOjs7c7lcumTbtm3JyclHjx4ViUTMavHx8Xp6ekFBQVVVVd0ZnjJ0M7abN2+uW7du2bJlo0aNal27efNmCwuLTZs2CYVCNze30NDQ77///s6dO3StgYHB8uXLzczM+vXr5+/vP2vWrF9//fX58+d07YoVK0aOHDl9+vTm5mZCCIvFsrKy8vT0HDRoULcdHQBAX4C0Enq2/fv3l5WVaTGAe/fuhYeHb9q0icfjyZe7u7uHhIQ8ffp0zZo12ortbXQztpEjR6akpCxYsIDJ1xnNzc0nT5708vJisVh0ybRp0yiKSk9PpxdTU1Plz7+VlRUhpKamhimJjIzMy8uLi4vT7DEAAPRtSCtB/XJycmxtbVks1rfffksISUpKEgqFAoEgPT192rRpYrHY2tr68OHD9Mrx8fE8Hm/AgAFLly61tLTk8Xju7u5Xrlyha4ODgw0MDCwsLOjF5cuXC4VCFov16tUrQkhISMjq1atLSkpYLJaTkxMh5PTp02KxeMuWLd12sPHx8RRF+fj4tK6Kjo52dnbet29fVlZWm5+lKGrXrl1DhgzhcrnGxsazZs1ibr+1f9IIITKZLCIiwtbWls/njxgx4siRI50KW5dja+3+/fs1NTW2trZMiaOjIyEkPz+/zfWLi4uNjIzs7OyYEmNjYy8vr7i4uF7cPQMAQOuQVoL6jR8//tKlS8zi559/vnLlyvr6epFIdOTIkZKSEgcHh88++0wqlRJCgoODAwMD6+rqVqxY8fDhw+vXrzc3N0+ePPnJkyeEkPj4ePl5IxMTEzdt2sQsxsXFzZgxw9HRkaKoe/fuEULoNzNaWlq67WBPnjw5ePBggUDQuorP53///fd6enqfffZZbW1t6xUiIyPDwsK+/vrrsrKyixcvPnnyxNPT8+XLl6Sjk0YIWbdu3Y4dO2JjY58/fz5jxoz58+f/+eefyoety7G19uLFC0KIfB8DHo/H5/PpeBhSqfTp06fffvttVlZWQkKCgYGBfO2777779OnTmzdvdiUSAABoB9JK6D7u7u5isdjMzCwgIKC2tvbx48dMFZvNpm+Mubq6JiUlVVdXHzhwQIVdeHt7SySS8PBw9UXdntra2gcPHtB3ztrk5ua2cuXKhw8frlu3TqGqvr5+165ds2fPXrhwoaGh4fDhw3fv3v3q1as9e/bIr9bmSWtoaEhKSvL19fXz8zMyMtqwYQOHw+nsGdPl2BTQL33r6+vLF3I4nPr6evkSGxsba2vryMjIHTt2zJs3T2EjdE/KgoKCrkQCAADtQFoJWkDfRmJubikYPXq0QCBgHrnqsrKyMoqi2rxVyYiOjh48eHBiYmJOTo58eWFhYU1NzejRo5mSMWPGGBgYMB0AFMiftKKiorq6umHDhtFVfD7fwsJChTOmy7HJo/tN0i/cMJqamvh8vnzJkydPysrKfvrppx9++OHdd99V6HRLf00KNzgBAECNkFaCLuJyueXl5dqOomMNDQ2EkNavmMjj8XgHDhxgsVhLliyRv7tGj3fTr18/+ZWNjIyqq6s73C/92HrDhg3M+IuPHj1qPShPh3Q5Nnl051pmKEpCSF1dXUNDg6WlpfxqHA7HzMxsypQpycnJhYWFW7dula+lc1D6KwMAAE1AWgk6RyqVvnnzxtraWtuBdIzOVOSH2m6Tm5vbqlWriouLN2/ezBQaGRkRQhQSNSUP3MzMjBASGxtLycnNzVXhEHQ5Noa9vb1IJHr06BFTQnelHTFiRJvrOzk56evrFxYWyhc2NTWR//3KAABAE5BWgs7Jzs6mKGrcuHH0IpvNftvjcq0bMGAAi8VSZvTHzZs3u7i43LhxgykZNmxYv3795N9luXLlSlNT0/vvv9/h1mxsbHg8Xl5enmph96DYaGw2e/r06RcvXmRexsrMzGSxWPQL+BUVFfPnz5dfv7i4WCaT2djYyBfSX5O5ubkaAwMAAHlIK0EntLS0VFZWNjc35+fnh4SE2NraBgYG0lVOTk6vX79OS0uTSqXl5eXyt6wIISYmJs+ePXv48GF1dbVUKs3MzOzOAYYEAoGDg0NpaWmHa9KPm+VfOuHxeKtXr05NTT106JBEIikoKFi2bJmlpWVQUJAyW1u8ePHhw4eTkpIkEolMJistLaVH/w4ICDA3N+/UBIy6HBsjPDz85cuXGzdurK2tzc3NjYmJCQwMHDx4MCFEKBSePXv2/PnzEolEKpXeuHHj008/FQqFq1atkt8C/TUNHz5chb0DAIBS5B9U0cPLUQByCCFHjhzp1EcSEhLoznACgcDHxycxMZF+W2LQoEElJSV79uwRi8WEEDs7u7t371IUFRQUxOFwrKys2Gy2WCyeNWtWSUkJs7WKiooJEybweDx7e/svv/xy7dq1hBAnJ6fHjx9TFHX9+nU7Ozs+nz9+/PgXL16cOnVKJBJFR0d39jDnzJkzZ86cDlcLCgqysrKSLwkODuZwOHV1dfRiamoq/WK4qanpF198ofDxtWvXzpw5k1lsaWmJiYkZNGgQh8MxNjb29fUtKiqiqzo8aY2NjaGhoba2tmw228zMzM/Pr7CwkKIoX19fQkhERETr4HU5NoqicnNzPTw8mO6SFhYW7u7uFy5cYFa4cOHCBx98wOVyLS0t165d29DQwFT5+PjY29v369ePy+U6OjoGBAQUFBQobN/b29vKyqqlpYUpWbFiRf/+/dsMRp6S1wYAACCthA6okFZ2VlBQkImJiUZ30SGV08ri4mI2m33w4EGNhdY5MpnM09Nz//792g6kDVqM7dWrVzweb+fOnfKFSCsBANQLD8FBJ3T41ovuqK+vP3PmTHFxMf0KiJOTU1RUVFRUlPxUgdoik8nS0tKqq6sDAgK0HYsi7cYWGRk5atSo4OBgQghFUc+ePcvJyaHf+wEAAHVBWgnQOa9fv546daqzs/OSJUvokrCwMH9//4CAAGXe3dGo7OzslJSUzMzM9ofS1AotxrZr1668vLxTp05xOBxCSHp6upWVlaen58mTJ7s5EgCA3k2VtPLUqVOGhoa//PKL2qPpupaWltjYWHd3d+U/cvny5SFDhujp6bFYLHNz8+joaM2FpyAlJcXBwYEe28/CwmLhwoXdtmvdsX79+gMHDlRVVdnb2x8/flzb4XRg9+7dzK3+Q4cOMeVbtmwJDg7+5ptvtBgbIWTixIk//vgjM4W6TtFWbOnp6Y2NjdnZ2cbGxnTJrFmzmC+RnlweAADUgq3CZyiKUnscalFcXLx48eI//vhj5MiRyn9q3Lhxt2/fnjp16pkzZ4qKiugR+7qHn5+fn5+fk5PTq1ev6FmP+6CtW7cqDFvdQ02ZMmXKlCnajgIUzZw5c+bMmdqOAgCgT1DlbqW3t3dVVdWMGTPUHo2C+vp65e873rx5c926dcuWLRs1apRGo+qiTh0UAAAAQE+h030r9+/frzCrbztGjhyZkpKyYMGC9mfS07pOHRQAAABAT9HptDInJ8fW1pbFYn377beEkKSkJKFQKBAI0tPTp02bJhaLra2tDx8+TK8cHx/P4/EGDBiwdOlSS0tLHo/n7u5+5coVujY4ONjAwIDpa7V8+XKhUMhisejeTiEhIatXry4pKWGxWE5OTl08ztOnTys/SrauHdTvv//u6upqaGjI4/GGDx9+5swZQsh//ud/0p0yHR0d6flRFi9eLBAIDA0NT5w4QQiRyWQRERG2trZ8Pn/EiBH06FE7duwQCAQikaisrGz16tVWVlZFRUXKn0YAAACAt5IfbUjJcSufPHlCCElISKAXv/76a0LIuXPnqqqqysrKPD09hUJhU1MTXRsUFCQUCm/dutXQ0FBYWDhmzBiRSEQPZE1R1IIFC8zNzZktx8TEEELKy8vpRT8/P0dHx86OmTR27NiRI0cqFGZkZIhEoqioqLd96uOPPyaEVFZWdv9BOTo6GhoatnNEx44di4yMfP36dUVFxbhx45iR9vz8/PT19Z8+fcqsOX/+/BMnTtD/XrNmDZfLPX78eGVl5fr16/X09K5evcoc2ooVKxISEmbPnn379u12dk11y7iVugBjE8Lb4NoAAFCS2h6Cu7u7i8ViMzOzgICA2trax48fM1VsNnvIkCFcLtfV1TUpKam6uvrAgQPq2q+SvL29JRJJeHh4pz6lIwc1Z86cjRs3Ghsbm5iY+Pj4VFRUlJeXE0KWLVsmk8mY/UokkqtXr06fPp0Q0tDQkJSU5Ovr6+fnZ2RktGHDBg6HIx/htm3bvvjii5SUFBcXFw2FDQAAAH2KKm+Ct8/AwIAQIpVK26wdPXq0QCC4c+eO2verUbpzUPTAe/Tg4R999JGzs/N33323fv16FouVnJwcEBBAz+xcVFRUV1c3bNgw+lN8Pt/CwkLlCOfNmzdv3jw1HYFOY7FY2g4BdNGcOXO0HQIAQA+g/rSyQ1wul77Z1pto9KBOnjwZExNTWFgokUjkU1sWi7V06dJVq1adO3du0qRJ//znP3/88Ue6qra2lhCyYcOGDRs2MOszsy13VkhIiJubWxeOoAeIjY0lhKxcuVLbgYDOoa8NAADoUHenlVKp9M2bN9bW1t28X43SxEFdvHjx2rVrK1eufPz4sa+v7+zZs7/77rt33nknISHhq6++YlYLDAxcv379vn37bGxsxGKxnZ0dXW5mZkYIiY2NDQkJ6Xowbm5uc+fO7fp2dNmxY8cIIb3+MEEF9LUBAAAd6u60Mjs7m6KocePG/c/u2ey3PVnuQTRxUNeuXRMKhYSQgoICqVT6+eefOzg4kFZPaY2NjefNm5ecnCwSiT777DOm3MbGhsfj5eXldTEMAAAAACV1x7iVLS0tlZWVzc3N+fn5ISEhtra2gYGBdJWTk9Pr16/T0tKkUml5efmjR4/kP2hiYvLs2bOHDx9WV1d3MVHLzMxUfoAhZWjuoKRS6cuXL7Ozs+m00tbWlhCSlZXV0NBQXFzMjGTEWLZsWWNjY0ZGhvwA9Tweb/HixYcPH05KSpJIJDKZrLS09Pnz5+o6fAAAAABF8q+FKzPAUEJCAj0oo0Ag8PHxSUxMFAgEhJBBgwaVlJTs2bNHLBYTQuzs7O7evUtRVFBQEIfDsbKyYrPZYrF41qxZJSUlzNYqKiomTJjA4/Hs7e2//PLLtWvXEkKcnJzowXquX79uZ2fH5/PHjx//4sWL9gPLzc318PBgug9aWFi4u7tfuHCBrj116pRIJIqOjm79wcuXLw8dOlRPT4/+1JYtW7rtoP7xj384Ojq+7atJTU2lNxgaGmpiYmJkZOTv708PF+ro6MiMZ0RR1LvvvhsWFqZwXI2NjaGhoba2tmw228zMzM/Pr7CwcPv27Xw+nxBiY2Nz8ODB9k8pjWCAIejbcG0AACiJRclN8H306NF58+ZRap3ye+nSpceOHauoqFDjNrVO1w7K29v722+/tbe318TGWSzWkSNHen2nQ39/f4JedNAWXBsAAErqjofg9Gg4vYzWD4p5gJ6fn0/fGdVuPAAAANDH6fSc4Iw7d+6w3i4gIEDbAWpBaGhocXHx3bt3Fy9evHnzZm2H01csXbqUufAWLlwoX5WVlRUWFpaSkuLg4ECv8Mknn8ivMGXKFJFIpK+vP3To0OvXr3dv4IQQosuxMVpaWmJjY93d3VtX5eTkeHh4CAQCS0vL0NDQxsZGpmr79u0uLi58Pl8oFLq4uISHh0skErrqxIkT27dvl/87MC0tjfkSTU1NNX1EAAB9iPwTcSUnb1ReWFgYPZD4wIEDjx07psYta5GOHNTXX3+tp6dnY2PDzNaoIQR9K+UEBQWZmJhkZmYWFRU1NDQw5RERETNmzJBIJPSio6Nj//79CSEZGRnyH8/MzJw5c6Z6I+8sXY7t7t27Hh4ehJDW86/+9ddffD4/PDy8pqbm0qVLpqamixcvZmq9vb137txZVlZWXV199OhRDoczefJkpjYuLs7Ly4uZmrWlpaW0tPTixYvTp09npkJtB/pWAgAoSbN3K7du3drY2EhR1IMHD3rNNBU6clDR0dEymezx48fyL4D3RPX19W3emtLuptrB5/OnTp3q7OzM5XLpkm3btiUnJx89elQkEjGrxcfH6+npBQUFVVVVaTqkztLN2G7evLlu3bply5aNGjWqde3mzZstLCw2bdokFArd3NxCQ0O///57ZuIoAwOD5cuXm5mZ9evXz9/ff9asWb/++isz9MGKFStGjhw5ffr05uZmQgiLxbKysvL09Bw0aFC3HR0AQF/QMx6CQy+2f//+srIyXduU8u7duxceHr5p0yYejydf7u7uHhIS8vTp0zVr1nRzSB3SzdhGjhyZkpKyYMECJl9nNDc3nzx50svLixm3ddq0aRRFpaen04upqany59/KyooQUlNTw5RERkbm5eXFxcVp9hgAAPo2pJWgBhRF7dq1a8iQIVwu19jYeNasWcxtpODgYAMDA3pQKkLI8uXLhUIhi8V69eoVISQkJGT16tUlJSUsFsvJySk+Pp7H4w0YMGDp0qWWlpY8Hs/d3Z0ZqrNTmyKEnD59Wr2DlbYpPj6eoigfH5/WVdHR0c7Ozvv27cvKymrzs+2ct6SkJKFQKBAI0tPTp02bJhaLra2tDx8+zHxWJpNFRETY2try+fwRI0bQPViUp8uxtXb//v2amhp6DFcaPTJXfn5+m+sXFxcbGRkxk04RQoyNjb28vOLi4ii1jnQBAAD/Rv6JuNr7VkIvQJToWxkREWFgYHDw4ME3b97k5+e/9957pqamzFCjCxYsMDc3Z1aOiYkhhJSXl9OLfn5+jo6OTG1QUJBQKLx161ZDQ0NhYeGYMWNEIhEzSGenNpWRkSESiaKiopQ5TOX7VlpZWcmXODg4uLq6Kqzm6Oj44MEDiqIuXbqkp6c3cODAmpoaqlX/xfbP29dff00IOXfuXFVVVVlZmaenp1AobGpqomvXrFnD5XKPHz9eWVm5fv16PT29q1evKnOkuhwbbezYsQp9Ky9cuEAIiYmJkS/k8/kTJ06UL2lqaiotLU1ISOByua2HZQ0LCyOE3LhxgylZsWIF+lYCAKgR7lZCV9XX1+/atWv27NkLFy40NDQcPnz47t27X716tWfPHtU2yGaz6Ztkrq6uSUlJ1dXVBw4cUGE73t7eEokkPDxctTCUUVtb++DBg3bGtHdzc1u5cuXDhw/XrVunUKXkeXN3dxeLxWZmZgEBAbW1tY8fPyaENDQ0JCUl+fr6+vn5GRkZbdiwgcPhdPYs6XJsCuiXvvX19eULORxOfX29fImNjY21tXVkZOSOHTvmzZunsBG6J2VBQUFXIgEAgHYgrYSuKiwsrKmpGT16NFMyZswYAwOD1vNMqmD06NECgYB5/KprysrKKIqi52R6m+jo6MGDBycmJubk5MiXd/a80eMP0OOVFhUV1dXVDRs2jK7i8/kWFhYqnCVdjk0e3W+SfuGG0dTURE8ZxXjy5ElZWdlPP/30ww8/vPvuuwodbemv6eXLl12JBAAA2oG0ErrqzZs3hJB+/frJFxoZGVVXV6tl+1wut7y8XC2bUruGhgZCSOtXTOTxeLwDBw6wWKwlS5bI313rynmrra0lhGzYsIEZf/HRo0d1dXWdjV+XY5NHd6hlhqIkhNTV1TU0NDCTtdI4HI6ZmdmUKVOSk5MLCwu3bt0qX0vnoPRXBgAAmoC0ErrKyMiIEKKQcLx588ba2rrrG5dKperalCbQmUqHUy65ubmtWrWquLhYfuD6rpw3MzMzQkhsbKx8j5bc3FwVDkGXY2PY29uLRKJHjx4xJffu3SOEjBgxos31nZyc9PX1CwsL5QubmprI/35lAACgCUgroauGDRvWr1+/P//8kym5cuVKU1PT+++/Ty+y2WxmqsnOys7Opihq3LhxXd+UJgwYMIDFYikz+uPmzZtdXFxu3LjBlHR43tphY2PD4/Hy8vJUC7sHxUZjs9nTp0+/ePFiS0sLXZKZmclisegX8CsqKubPny+/fnFxsUwms7GxkS+kvyZzc3M1BgYAAPKQVkJX8Xi81atXp6amHjp0SCKRFBQULFu2zNLSMigoiF7Bycnp9evXaWlpUqm0vLxc/p4TIcTExOTZs2cPHz6srq6mU8aWlpbKysrm5ub8/PyQkBBbW9vAwEAVNpWZmanpAYYEAoGDg0NpaWmHa9KPm+VfOunwvLW/tcWLFx8+fDgpKUkikchkstLSUnr074CAAHNz805NwKjLsTHCw8Nfvny5cePG2tra3NzcmJiYwMDAwYMHE0KEQuHZs2fPnz8vkUikUumNGzc+/fRToVC4atUq+S3QX9Pw4cNV2DsAAChF/kEVBhiC1ogSAwy1tLTExMQMGjSIw+EYGxv7+voWFRUxtRUVFRMmTODxePb29l9++eXatWsJIU5OTvSwQdevX7ezs+Pz+ePHj3/x4kVQUBCHw7GysmKz2WKxeNasWSUlJapt6tSpUyKRKDo6WpnDVHmAoeDgYA6HU1dXRy+mpqbSL4abmpp+8cUXCh9fu3at/CA+7Zy3xMRE+hWTQYMGlZSU7NmzRywWE0Ls7Ozu3r1LUVRjY2NoaKitrS2bzTYzM/Pz8yssLKQoytfXlxASERHROnhdjo2iqNzcXA8PD6a7pIWFhbu7+4ULF5gVLly48MEHH3C5XEtLy7Vr18pPnunj42Nvb9+vXz8ul+vo6BgQEFBQUKCwfW9vbysrq5aWFqYEAwwBAKgX0krogDJppRrRk2532+4YKqeVxcXFbDa79SiJ2iKTyTw9Pffv36/tQNqgxdhevXrF4/F27twpX4i0EgBAvfAQHHROh2/AaFd9ff2ZM2eKi4vpV0CcnJyioqKioqLkpwrUFplMlpaWVl1dHRAQoO1YFGk3tsjIyFGjRgUHBxNCKIp69uxZTk4O/d4PAACoC9JKgM55/fr11KlTnZ2dlyxZQpeEhYX5+/sHBAQo8+6ORmVnZ6ekpGRmZrY/lKZWaDG2Xbt25eXlnTp1isPhEELS09OtrKw8PT1PnjzZzZEAAPRuSCtBh6xfv/7AgQNVVVX29vbHjx/Xdjht2L17N3Or/9ChQ0z5li1bgoODv/nmGy3GRgiZOHHijz/+yEybrlO0FVt6enpjY2N2draxsTFdMmvWLOZLpCeUBwAAtWBrOwCA/7N161aFIax7kClTpkyZMkXbUYCimTNnzpw5U9tRAAD0CbhbCQAAAABqgLQSAAAAANQAaSUAAAAAqAHSSgAAAABQgzZe2Tl69Gj3xwG6LDc3V9shaBw9sx8ufmittLTU2tpa21EAAPQALIqimIWjR4/OmzdPi9EAAOigOXPmHDt2TNtRAADoun9LKwF0B4vFOnLkyNy5c7UdCAAAACgFfSsBAAAAQA2QVgIAAACAGiCtBAAAAAA1QFoJAAAAAGqAtBIAAAAA1ABpJQAAAACoAdJKAAAAAFADpJUAAAAAoAZIKwEAAABADZBWAgAAAIAaIK0EAAAAADVAWgkAAAAAaoC0EgAAAADUAGklAAAAAKgB0koAAAAAUAOklQAAAACgBkgrAQAAAEANkFYCAAAAgBogrQQAAAAANUBaCQAAAABqgLQSAAAAANQAaSUAAAAAqAHSSgAAAABQA6SVAAAAAKAGSCsBAAAAQA2QVgIAAACAGiCtBAAAAAA1QFoJAAAAAGqAtBIAAAAA1ABpJQAAAACoAdJKAAAAAFADpJUAAAAAoAZIKwEAAABADVgURWk7BgBCCAkKCioqKmIWr1+/bm9vb2xsTC/q6+v/8MMP1tbWWooOAAAAOsDWdgAA/8Pc3HzPnj3yJfn5+cy/HRwckFMCAADoMjwEB10xf/78t1UZGBgEBgZ2YywAAADQaXgIDjpk2LBht27davOaLCoqcnZ27v6QAAAAQEm4Wwk6ZNGiRfr6+gqFLBZr5MiRyCkBAAB0HNJK0CH/8R//IZPJFAr19fU//fRTrcQDAAAAysNDcNAt7u7uV65caWlpYUpYLNaTJ0+srKy0GBUAAAB0CHcrQbd88sknLBaLWdTT0xs/fjxySgAAAN2HtBJ0i7+/v/wii8xFZiMAACAASURBVMVatGiRtoIBAAAA5SGtBN1iamo6ceJE5sUdFovl6+ur3ZAAAABAGUgrQecsXLiQ7vKrr6//8ccf9+/fX9sRAQAAQMeQVoLOmT17toGBASGEoqiFCxdqOxwAAABQCtJK0DlCofBvf/sbIcTAwGDGjBnaDgcAAACUgrQSdNGCBQsIIb6+vkKhUNuxAAAAgHIolWg7agAANThy5IhqbaC8I0eOaPs4AAC0Q6EVZau8oZCQEDc3NzVG1vvk5ubGxcX1hZ+cefPmqf16OHToUEBAAJut+iUK0L558+apcWt94X86KE8TraIOio2NJYSsXLlS24GAdrRuRVX/zXZzc5s7d27X4un94uLi+sJZmjdvntqvBx8fHx6Pp8YNAihQb1rZF/6ng/I00SrqoGPHjhFc/H1Y61YUfStBRyGnBAAA6FmQVgIAAACAGiCtBAAAAAA1QFoJAAAAAGqAtBIAAAAA1ABppc45deqUoaHhL7/8ou1AeqqsrKywsLCUlBQHBwcWi8VisT755BP5FaZMmSISifT19YcOHXr9+vXuj1CXY2O0tLTExsa6u7u3rsrJyfHw8BAIBJaWlqGhoY2NjUzV9u3bXVxc+Hy+UCh0cXEJDw+XSCR01YkTJ7Zv3y6TybrpAAB6oN7a/i9dupT1vxSm5EWL3UVSqTQiIsLBwcHAwMDKymrNmjX19fVMbVRUlKurq1gs5nK5Tk5OX331VU1NDV3Vuk1OS0tjviZTU1MVA1J5OHS1DCPcu9Hj2HX2UxkZGWKx+MSJE5oISUN053qIiIiYMWOGRCKhFx0dHfv3708IycjIkF8tMzNz5syZ2gjw/+hybHfv3vXw8CCEjBw5UqHqr7/+4vP54eHhNTU1ly5dMjU1Xbx4MVPr7e29c+fOsrKy6urqo0ePcjicyZMnM7VxcXFeXl6VlZXddBgdUdd1q9r/dOjdVLu6elz7P2fOnDlz5nS4WlBQkImJSWZmZlFRUUNDA1OOFrvrPv/8cx6Pd/jwYYlE8ttvv4nF4vnz5zO1Xl5eiYmJFRUVEonkyJEjHA5n6tSpTK1Cm9zS0lJaWnrx4sXp06f3799fmb23vs5xt1LneHt7V1VVdcNc2PX19W3ei+q5tm3blpycfPToUZFIxBTGx8fr6ekFBQVVVVVpMbY26WZsN2/eXLdu3bJly0aNGtW6dvPmzRYWFps2bRIKhW5ubqGhod9///2dO3foWgMDg+XLl5uZmfXr18/f33/WrFm//vrr8+fP6doVK1aMHDly+vTpzc3N3Xc8AD1HL27/+Xz+1KlTnZ2duVwuXYIWu+vu37+/e/fuRYsWBQQEiESiDz/8MDg4+Keffrp9+za9Qr9+/eicXiQSzZ0719fX9/Tp00+ePKFrFdpkFotlZWXl6ek5aNAglUNCWtl37d+/v6ysTNtRqM29e/fCw8M3bdqkMOClu7t7SEjI06dP16xZo63Y3kY3Yxs5cmRKSsqCBQuY1p/R3Nx88uRJLy8vFotFl0ybNo2iqPT0dHoxNTVV/vxbWVkRQphnLoSQyMjIvLy8uLg4zR4DALRL6+0/Wmy1uHr1aktLy9ixY5mSqVOnEkLOnDlDL2ZkZOjr6zO19KPturo6pkTtbTLSSt2Sk5Nja2vLYrG+/fZbQkhSUpJQKBQIBOnp6dOmTROLxdbW1ocPH6ZXjo+P5/F4AwYMWLp0qaWlJY/Hc3d3v3LlCl0bHBxsYGBgYWFBLy5fvlwoFLJYrFevXhFCQkJCVq9eXVJSwmKxnJycCCGnT58Wi8VbtmzRwmGrQ3x8PEVRPj4+rauio6OdnZ337duXlZXV5mcpitq1a9eQIUO4XK6xsfGsWbOY22/tfwWEEJlMFhERYWtry+fzR4wY0dkZ/HQ5ttbu379fU1Nja2vLlDg6OhJC8vPz21y/uLjYyMjIzs6OKTE2Nvby8oqLi6OfngAAo0+1/2ix1RKbnp4eIYTP5zMl9I1G5m6lgqdPn/L5fHt7e6ZE/W2yas/yic70pdNlqvW4ou9OJyQk0Itff/01IeTcuXNVVVVlZWWenp5CobCpqYmuDQoKEgqFt27damhoKCwsHDNmjEgkevz4MV27YMECc3NzZssxMTGEkPLycnrRz8/P0dGRqc3IyBCJRFFRUSocqS5cDw4ODq6urgqFjo6ODx48oCjq0qVLenp6AwcOrKmpoVr1homIiDAwMDh48OCbN2/y8/Pfe+89U1PTFy9e0LXtfwVr1qzhcrnHjx+vrKxcv369np7e1atXlQlYl2OjjR07VqFv5YULFwghMTEx8oV8Pn/ixInyJU1NTaWlpQkJCVwu9+DBgwqbDQsLI4TcuHFD+Ug0RF3XLfpWQmuqXV09rv1Xvm+llZWVfAlabLXERv9JHx4ezpTQj7N9fX1br1xbWysSiYKDgxXKW7fJK1asQN/KXs7d3V0sFpuZmQUEBNTW1j5+/JipYrPZ9B9Grq6uSUlJ1dXVBw4cUGEX3t7eEokkPDxcfVF3n9ra2gcPHtB3ztrk5ua2cuXKhw8frlu3TqGqvr5+165ds2fPXrhwoaGh4fDhw3fv3v3q1as9e/bIr9bmV9DQ0JCUlOTr6+vn52dkZLRhwwYOh9PZ86/LsSmgX/qWf6RCCOFwOPIvHhJCbGxsrK2tIyMjd+zY0XrGWPqP6YKCgq5EAtB39L72Hy22umIbPnz41KlTExMTz58/39DQ8OLFi9TUVBaLJZVKW6+8detWS0vL6OhohXL1tslIK3sYAwMDQkibVwwhZPTo0QKBgLnl3neUlZVRFCUQCNpZJzo6evDgwYmJiTk5OfLlhYWFNTU1o0ePZkrGjBljYGDAPE5SIP8VFBUV1dXVDRs2jK7i8/kWFhYqnH9djk0e3QtK4YWbpqYm+UcwhJAnT56UlZX99NNPP/zww7vvvqvQhYv+ml6+fNmVSAD6oF7T/qPFVmNsycnJ/v7+ixYtMjEx8fDw+PnnnymKol9al5eamnr06NEzZ87IvyBFU2+bjLSyt+FyueXl5dqOors1NDQQQlq/YiKPx+MdOHCAxWItWbJE/u7amzdvCCH9+vWTX9nIyKi6urrD/dbW1hJCNmzYwIz19ejRI/ne0ErS5djk0V21mKEoCSF1dXUNDQ2Wlpbyq3E4HDMzsylTpiQnJxcWFm7dulW+ls5B6a8MANSop7T/aLHVGJuhoeHu3btLS0vr6upKSkr+/ve/E0Leeecd+XWSk5O3bduWnZ09cODA1ltQb5uMtLJXkUqlb968sba21nYg3Y3+X9HhUNtubm6rVq0qLi7evHkzU2hkZEQIUfhvr+RpNDMzI4TExsbK9yzJzc1V4RB0OTaGvb29SCR69OgRU3Lv3j1CyIgRI9pc38nJSV9fv7CwUL6wqamJ/HsfcwDouh7U/qPF1lxsV69eJYRMmDCBKUlISDh06ND58+cVck2GettkpJW9SnZ2NkVR48aNoxfZbPbbHpf0MgMGDGCxWMqMJbZ582YXF5cbN24wJcOGDevXr9+ff/7JlFy5cqWpqen999/vcGs2NjY8Hi8vL0+1sHtQbDQ2mz19+vSLFy+2tLTQJZmZmSwWi36ds6KiYv78+fLrFxcXy2QyGxsb+UL6azI3N1djYADQg9p/tNiai23v3r329vZeXl6EEIqiQkNDCwoK0tLSFO6hylNvm4y0ssdraWmprKxsbm7Oz88PCQmxtbUNDAykq5ycnF6/fp2WliaVSsvLy+VvMhFCTExMnj179vDhw+rqaqlUmpmZ2XMHGBIIBA4ODqWlpR2uST+8kH/phMfjrV69OjU19dChQxKJpKCgYNmyZZaWlkFBQcpsbfHixYcPH05KSpJIJDKZrLS0lB79OyAgwNzcvFPTeelybIzw8PCXL19u3LixtrY2Nzc3JiYmMDBw8ODBhBChUHj27Nnz589LJBKpVHrjxo1PP/1UKBSuWrVKfgv01zR8+HAV9g4A8npo+48WW42xffDBB48ePWpubn748OGaNWuysrL2799P99q8devWjh079u7dy+FwWHJ27twpvwU1t8nKvECuzCvl0JoKw44kJCTQ3dcEAoGPj09iYiLdl3bQoEElJSV79uwRi8WEEDs7u7t371IUFRQUxOFwrKys2Gy2WCyeNWtWSUkJs7WKiooJEybweDx7e/svv/xy7dq1hBAnJyd6BIrr16/b2dnx+fzx48e/ePHi1KlTIpEoOjpahSPVheshODiYw+HU1dXRi6mpqfRrhqampl988YXCymvXrpUfEqKlpSUmJmbQoEEcDsfY2NjX17eoqIiu6vAraGxsDA0NtbW1ZbPZZmZmfn5+hYWFFEX5+voSQiIiIlqHqsuxURSVm5vr4eHBdJe0sLBwd3e/cOECs8KFCxc++OADLpdraWm5du1a+anYfHx87O3t+/Xrx+VyHR0dAwICCgoKFLbv7e1tZWXV0tLS5t67k7quWwwwBK2pcHX1xPZf5QGG0GKrq8WePHmykZERm802Njb29vaWH5PobS93KwwS17pN7soAQ0grNagbfmzoSZk0ugtl6ML1UFxczGazW4+SqC0ymczT03P//v3aDqQNWozt1atXPB5v586d3b/r1pBWguZ0Q6uoC+2/ymklWmzlaTS2NttkjFvZp3XY67mPcHJyioqKioqKkp8qUFtkMllaWlp1dXVAQIC2Y1Gk3dgiIyNHjRoVHBzc/bsG6H16UPtfX19/5syZ4uJi+gURtNhK0nRs8m0yRVHPnj3Lycmh38VUTa9KK+/evfvll18OHTpULBYbGBiYmZm5uLjMnj37559/pldISUlxcHCQ72FAPyBYsmTJgwcPmO3893//9zvvvMNisfT09JydneXnaPrb3/4mFov19PRcXFz++OOP7j5CaFdYWJi/v39AQIAyPcE1Kjs7OyUlJTMzs/2B2bRCi7Ht2rUrLy/v1KlTHA6nm3etC06dOmVoaPjLL79oO5B/ExUV5erqKhaLuVyuk5PTV199peTP/OXLl4cMGaKnp8disczNzVuPsaw58i25hYXFwoULu23XoLLXr19PnTrV2dl5yZIldAlabGVoNDaFNjk9Pd3KysrT0/PkyZOqb1S1u6ZEBx56Kjhw4ICBgcH48eNPnz5dWVnZ0NBQUlLyyy+/eHt7BwUFya/p6OhoaGhIUZRMJnv58uU///lPgUAwYMCAV69eya9GCBk7dmzrHf32228KU9W9jaYfjYWFhdHdcgcOHHjs2DHN7ahDOnU9nDlzJjQ0VNtRgKK0tLStW7c2NzdrO5D/o67rVsn/6RkZGWKx+MSJE13foxp5eXklJiZWVFRIJJIjR45wOJypU6cq//GPP/6YEFJZWam5CN+Gacl1k6ZbRR1p/5V8CN4OtNjaopY2ufV13kvSytzcXH19/Q8//FAqlSpUlZSUvC2tZHz11VeEkOTkZPlC3U8rdYeuXQ8AyujmtLLb1NXVubm5Kbmyt7e3/O/K3LlzCSHMvNId6ra0svVB9fG0Ukd0Pa2EHq31dd59D8Epijp27JjCzJjqsmXLFplM9s0337DZbIUqBweH3bt3t/9xJycnQsiLFy80ERsAQHfav3+/woSZ7cjIyJAfIcXU1JQQ0sXZmDShUwcFANqiwbRSJpNt3bp18ODBfD7f1NTU3t5+69at9J/CO3bsEAgEIpGorKxs9erVVlZWH3/8sYGBAT22AiFk+fLlQqGQxWK9evWKLjl9+vTbRtVqamrKysoyMTFhhoHtrOLiYkLIyJEjVfs4AED7cnJybG1tWSzWt99+SwhJSkoSCoUCgSA9PX3atGlisdja2vrw4cP0yvHx8Tweb8CAAUuXLrW0tOTxeO7u7sy0wsHBwe20liEhIatXry4pKWGxWPQfzJ3y9OlTPp9vb29PL7bT8Lamawf1+++/u7q6Ghoa8ni84cOHnzlzhhDyn//5n3SnTEdHR3og68WLFwsEAkNDwxMnThBCZDJZRESEra0tn88fMWIEfSu69W9WUVGRkmEA9C3quu3Z2pYtW/T19dPT0+vq6q5du2Zubv7hhx8ytV9//TUhZMWKFQkJCbNnz759+/aCBQvMzc2ZFWJiYggh5eXl9GJGRoZIJIqKimq9o7t37xJCxo0bp2Tw8o9OKisrv//+e4FA4O3t3foY8RBcScpcDwC6Rl3XrZL/0588eUIISUhIoBfpNvDcuXNVVVVlZWWenp5CobCpqYmuDQoKEgqFt27damhoKCwsHDNmjEgkYp5Nt99a+vn5OTo6qnAgtbW1IpEoODiYKWmn4aUpPATvzoPq8CH4sWPHIiMjX79+XVFRMW7cOGbAFD8/P319/adPnzJrzp8/n+nzumbNGi6Xe/z48crKyvXr1+vp6dEDAbb+zWpn11SfaRXxELyPa32da/BuZVpa2vvvv+/j48Pn8997772ZM2devHiRHlmAsW3bti+++CIlJcXFxaX9rXl7e0skkvDw8NZVEomEtJrcvX1VVVX0H6zGxsaLFy9ev34987Y4AEC3cXd3F4vFZmZmAQEBtbW1jx8/ZqrYbPaQIUO4XK6rq2tSUlJ1dfWBAwc0GszWrVstLS3l3+lup+Fth44c1Jw5czZu3GhsbGxiYuLj41NRUVFeXk4IWbZsmUwmY/YrkUiuXr06ffp0QkhDQ0NSUpKvr6+fn5+RkdGGDRs4HI58hMr/ZgH0TYo9EdWooaGBx+MxizKZjMPhyHfiURc6oaytrVUoP3r0aGho6MOHDwkhLi4uFy5cGDBgAF1laGj45s0bQshXX30VExNjaGiouRFPjh49qqEt65Tc3FxthwDQg9Fv9b5tEufRo0cLBII7d+5oLoDU1NSjR4+ePXtWJBKpa5taPygG3cLTozx+9NFHzs7O33333fr161ksVnJyckBAAP3bVFRUVFdXN2zYMPpTfD7fwsJC5Qj7QqtIz/vXR37mQBkaTCunT58eExOTnp4+ZcqUwsLCtLS0v/3tb5pIK+3s7LhcbuvRO+fOnTt37tyBAwc2NDTcvn27zc+Gh4cfPHhw/fr1M2fOtLGxUahtaWlp/RE6P1Y+vHnz5im/cs8VFxcXFxen7SgAei0ul0vfbNOE5OTkXbt2ZWdnv/POOxraRZs0elAnT56MiYkpLCykJ6lnylks1tKlS1etWnXu3LlJkyb985///PHHH+kq+vbEhg0bNmzYwKzPTGTaWX2nVewjP3OgDA0+BI+MjPzoo48CAwPFYvHs2bPnzp27d+9eTeyIx+NNmjSpvLz88uXLnf2sSCTatm1bdXX1559/rlBlYmLy7Nmz1h958OBB6wS0Hdrq8dCdSN/oRQS9TGebCy2SSqVv3ryxtrbWxMYTEhIOHTp0/vz5bs4pNXFQFy9ejI2NJYQ8fvzY19fXwsLiypUrVVVV27dvl18tMDCQx+Pt27evqKhILBbb2dnR5WZmZoSQ2NhY+etE5ZuOfaFVRN/KPq71Za/BtLKwsLCkpKS8vFwqlT5+/DgpKcnY2Lid9dls9tuelXRo06ZNHA5n7dq1Kmxh0aJFY8eOzcjIULiN/9FHHz19+vTSpUvyhRRFff/992PHjlUtTgAAFWRnZ1MUxQx20ZXWUh5FUaGhoQUFBWlpaZ3qnq4Wmjioa9euCYVCQkhBQYFUKv38888dHBx4PB6LxZJfzdjYeN68eWlpaTt37vzss8+YchsbGx6Pl5eX18UwAPosDaaVX3zxha2trfLTfTo5Ob1+/TotLU0qlZaXlz969Ei+NjMzs51xLt5///2DBw9eu3btww8/PH369PPnz5ubmx89enTw4MHXr1+3v18WixUfH89isYKDgysrK5ny6OhoIyMjf3//n3/+uba2trGx8ebNm/Pnz29ubv7kk0+UPCgAANW0tLRUVlY2Nzfn5+eHhITY2toGBgbSVe23lvSTlocPH1ZXV7efqN26dWvHjh179+7lcDjys9ru3LmTXqH9hlenDkoqlb58+TI7O5tOK21tbQkhWVlZDQ0NxcXFzEhGjGXLljU2NmZkZMyYMYMp5PF4ixcvPnz4cFJSkkQikclkpaWlz58/V9fhA/R+Kt/27PD2/vnz5/v378/siMPhDBkyJCUlhaKo7du38/l8QoiNjc3Bgwfp9SsqKiZMmEBP0v3ll1+uXbuWEOLk5EQPP3Hq1CmRSBQdHd3OHh88eBASEjJ06FChUEhvx9PTc926dRcvXqRX+OOPP5ydnel43nnnnaVLlzKfpZs2IyOjb775Rn6Dn332mb29vYGBAZ/Pd3V1jYiIqKmpUfIsYYAhAF2mrutWmf/pCQkJ9KCMAoHAx8cnMTGRnuF30KBBJSUle/bsEYvFhBA7O7u7d+9SFBUUFMThcKysrNhstlgsnjVrVklJCbO19lvL69ev29nZ8fn88ePHv3jxop2oCgoK2vxdiImJoVdop+G9fPny0KFD9fT0CCEWFhZbtmzptoP6xz/+4ejo+LYftdTUVHqDoaGhJiYm9N0BerhQR0dH+QmE3n333bCwMIXjamxsDA0NtbW1ZbPZZmZmfn5+hYWFbf5mta+PtIp4CN7Htb7ONZhWJiYmhoSEMIuNjY0rV67kcrl1dXWq7bTHQVoJoMu6M63srKCgIBMTE/VuU+t07aCmT59+//59DW28j7SKSCv7uNbXuabeBH/x4kVwcLB8DxUDAwNbW1upVCqVSuk/+wAA4G3o0XB6Ga0flFQqpYfyyM/Pp++MajcegF5GU30r+Xw+h8PZv3//y5cvpVLps2fP9u3bFxERERAQQD8WAQAAjbpz5w7r7QICArQdoBaEhoYWFxffvXt38eLFmzdv1nY4AL2NptJKQ0PDs2fP/vXXX87OznSvxAMHDmzbtu2HH37Q0B5Bxy1dupT5PVu4cKF8VVZWVlhYWEpKioODA72CwktRU6ZMEYlE+vr6Q4cOvX79evcG/m9aWlpiY2Pd3d1bV+Xk5Hh4eAgEAktLy9DQ0MbGRmVqT5w4sX37dtVu4eC8yZ+3tLQ05gIzNTXV6OFo2vr16w8cOFBVVWVvb3/8+HGVt+Pi4tLO06vk5GQ1xtwhdR1UFwkEAhcXl0mTJkVGRrq6umorjL6mR7f/uhwbIUQqlUZERDg4OBgYGFhZWa1Zs6a+vp6pjYqKcnV1FYvFXC7Xycnpq6++Yl6k1lQrqq6n6dAa+lbKo7tVZWZmFhUVNTQ0MOUREREzZsyQSCT0oqOjI/2mV0ZGhvzHMzMzZ86cqfbIO+Xu3bseHh6EkJEjRypU/fXXX3w+Pzw8vKam5tKlS6amposXL1ayNi4uzsvLi5lVWUk4bwrnraWlpbS09OLFi9OnT2dmf26futqxvvM/HZTXR34llexb2Qvaf52N7fPPP+fxeIcPH5ZIJL/99ptYLJ4/fz5T6+XllZiYWFFRIZFIjhw5wuFwpk6dytRqohVFWqlB3fBjU1dX5+bmpvVNKZlWWllZKRR+8803zs7O9fX1TImjo+OPP/6op6dnZWX15s0bplzr/3Xz8vJmz5596NChUaNGtU6P5s2bZ29v39LSQi/GxMSwWKzbt28rU0tRVHBwsJubm1QqVTIYnDdam+dtxYoVSCtB6zT9K6kjjb/yaWWPbv8pXY2tpKRET0/vv/7rv5gSeoKoW7du0Yve3t7Nzc1M7dy5cwkh8uMhqL0V1eC4ldAN9u/fX1ZWpmubUtK9e/fCw8M3bdokP3c8IcTd3T0kJOTp06dr1qzpznjaN3LkyJSUlAULFnC5XIWq5ubmkydPenl5MUMuT5s2jaKo9PT0DmtpkZGReXl5Ss7zhvPGbKFT5w2gN+nRjT/pae0YTQdju3r1aktLi/wULVOnTiWEnDlzhl7MyMiQnzSbfrRdV1fHlKi9FUVaqX0URe3atWvIkCFcLtfY2HjWrFl37tyhq4KDgw0MDOjh7gghy5cvFwqFLBbr1atXhJCQkJDVq1eXlJSwWCwnJ6f4+HgejzdgwIClS5daWlryeDx3d3dmEOBObYoQcvr0afUOg9xafHw8RVE+Pj6tq6Kjo52dnfft25eVldXmZ9s5aUlJSUKhUCAQpKenT5s2TSwWW1tbHz58mPmsTCaLiIiwtbXl8/kjRoygbzV1xf3792tqaujhl2n0oHr5+fkd1tKMjY29vLzi4uIoJWYUxHljSjp13gB0TZ9t/EmPbcd0LTZ64Fj50XUGDRpECLl9+3ab6z99+pTP58sPgKD+VlSZm5zK3PaE1pR8NBYREWFgYHDw4ME3b97k5+e/9957pqamzCDGCxYsMDc3Z1aOiYkhhJSXl9OLfn5+jo6OTG1QUJBQKLx161ZDQ0NhYeGYMWNEIhFzu7tTm8rIyBCJRFFRUcocqTLXQ+uHIA4ODq6urgqrOTo6PnjwgKKoS5cu6enpDRw4kB5/XuFBQ/sn7euvvyaEnDt3rqqqqqyszNPTUygUNjU10bVr1qzhcrnHjx+vrKxcv369np7e1atXlTlM2tixYxUe5l64cIHIjSBN4/P5EydO7LCWERYWRgi5ceNGhwHgvMmXtD5veAgOukCZq6sXNP4qPwTvce2YbsZG/5kdHh7OlDQ3NxNCfH19W69cW1srEomCg4MVytXbiuJupZbV19fv2rVr9uzZCxcuNDQ0HD58+O7du1+9erVnzx7VNshms+m/k1xdXZOSkqqrqw8cOKDCdry9vSUSSXh4uGphdKi2tvbBgwftTJXh5ua2cuXKhw8frlu3TqFKyZPm7u4uFovNzMwCAgJqa2sfP35MCGloaEhKSvL19fXz8zMyMtqwYQOHw1HtFDHo15PlHzQQQjgcDv06Xvu1DPpPzLfNesLAeVPtvAHomj7b+JMe3o7pVGzDhw+fOnVqYmLi+fPnGxoaXrx4kZqaymKx2pzgdOvWrZaWltHR0Qrl6m1FkVZqWWFhYU1NzejRo5mSMWPGGBgYtJ7BVgWjR48WCATMHXidK6a2lgAAIABJREFUUlZWRlEUPdXb20RHRw8ePDgxMTEnJ0e+vLMnzcDAgBBC/zcrKiqqq6sbNmwYXcXn8y0sLLp4iui+QfTfiIympib6wUT7tQz6VLx8+bL9feG8qXbeAHRNn238Sc9vx3QqtuTkZH9//0WLFpmYmHh4ePz8888URclPnU1LTU09evTomTNnRCKRQpV6W1GklVr25s0bQki/fv3kC42MjKqrq9WyfS6XW15erpZNqVdDQwMhpPVrHPJ4PN6BAwdYLNaSJUvk71F15aTV1tYSQjZs2MCMzvXo0SP5/ssqoDstSSQSpqSurq6hocHS0rLDWgadLdGnpR04b6qdNwBd02cbf9Lz2zGdis3Q0HD37t2lpaV1dXUlJSV///vfCSHvvPOO/DrJycnbtm3Lzs4eOHBg6y2otxVFWqllRkZGhBCFa+7NmzfW1tZd37hUKlXXptSOvo47HAbczc1t1apVxcXF8vNhdOWkmZmZEUJiY2Pl+4Lk5uaqcAgMe3t7kUj06NEjpuTevXuEkBEjRnRYy2hqaiL/3vO6TThvqp03AF3TZxt/0ivaMZ2N7erVq4SQCRMmMCUJCQmHDh06f/68Qq7JUG8rirRSy4YNG9avX78///yTKbly5UpTU9P7779PL7LZ7DY7SSgjOzuboqhx48Z1fVNqN2DAABaLVVVV1eGamzdvdnFxuXHjBlPS4Ulrh42NDY/Hk5+tvuvYbPb06dMvXrzY0tJCl2RmZrJYLPolx/ZrGfSpMDc3b39fOG+qnTcAXdNnG3/SW9ox3Yxt79699vb2Xl5ehBCKokJDQwsKCtLS0hTuocpTbyuKtFLLeDze6tWrU1NTDx06JJFICgoKli1bZmlpGRQURK/g5OT0+vXrtLQ0qVRaXl4uf/OGEGJiYvLs2bOHDx9WV1fTrUZLS0tlZWVzc3N+fn5ISIitrW1gYKAKm8rMzNToGBMCgcDBwaG0tLTDNenHDfKvbnR40trf2uLFiw8fPpyUlCSRSGQyWWlp6fPnzwkhAQEB5ubmqk3AFR4e/vLly40bN9bW1ubm5sbExAQGBg4ePFiZWhp9KoYPH95+JDhv7Zw3gB6kzzb+pLe0YzoS2wcffPDo0aPm5uaHDx+uWbMmKytr//79dK/NW7du7dixY+/evRwOhyVn586d8ltQcyuqzAvkyrxSDq0pOexIS0tLTEzMoEGDOByOsbGxr69vUVERU1tRUTFhwgQej2dvb//ll1+uXbuWEOLk5ESPHHH9+nU7Ozs+nz9+/PgXL14EBQVxOBwrKys2my0Wi2fNmlVSUqLapk6dOiUSiaKjo5U5UmWuh9YDTAQHB3M4nLq6OnoxNTWVfjHQ1NT0iy++UPj42rVr5QdxaOekJSYm0h2QBw0aVFJSsmfPHrFYTAixs7O7e/cuRVGNjY2hoaG2trZsNtvMzMzPz6+wsJCiKF9fX0JIREREm/Hn5uZ6eHgwHfssLCzc3d0vXLjArHDhwoUPPviAy+VaWlquXbtWfoKyDmspivL29raysqJnlGk/Epy3t503GgYYAl2gzNXVCxp/lQcY6kHtmC7HRlHU5MmTjYyM2Gy2sbGxt7e3/JhEb3u5W2HgNvW2okgrNaj7f2zoeVe7c4801dLK4uJiNpt98OBBTYbWCTKZzNPTc//+/d2/61evXvF4vJ07dyoTCc4bQ+G80ZBWgi7o5l9JbTX+KqeVaMeUp9HY1N6K4iF4b9NhJ2gtqq+vP3PmTHFxMd1B2MnJKSoqKioqqqamRtuhEZlMlpaWVl1dHRAQ0P17j4yMHDVqVHBwsDKR4Lwx5M8bRVHPnj3Lycmh3+wB6Gt0ufEnaP9VpenY1N6KIq2E7vP69eupU6c6OzsvWbKELgkLC/P39w8ICFCm77ZGZWdnp6SkZGZmtj+Umibs2rUrLy/v1KlTHA5HyUhw3kir85aenm5lZeXp6Xny5MlujgQAOoT2XzUajU0jrahqd00JHoIroZsfjYWFhdG9dAcOHHjs2LFu2y/V5evhzJkzoaGhaoynB0lLS9u6dWtzc7MKn8V5U+28MdTVjuEhOLTWnb+SWmz8lXwI3o6+3I5pl4ZaUXZXc13QGVu3bt26dau2o1DFlClTpkyZou0otGPmzJkzZ85U7bM4b9qOAkAn9NzGn/Ttdky7NNSK4iE4AAAAAKgB0koAAAAAUAOklQAAAACgBkgrAQAAAEANVH9lJzY29tixY2oMpfehJ0Ty9/fXdiDdAdcDo6Kion///tqOArpbH/mf3ltJJBIej0e/T60ufaFVvHz5MsHFD3JY9PvhnYVrCKBN1dXVZ86cMTY2dnV1ZWYsBJ21atUqNze3Lm4kNzd3165daokHup9EIrl169bTp09HjBgxaNAgbYcD0MMotKIqppUA8DZ//fVXVFTU8ePHhw8fvmHDhjlz5rBYLG0HBQCKbt26tW3btp9++snFxeWrr75asGCBvr6+toMC6NnQtxJAzYYNG3b06NGbN28OHjx43rx57777Lj1AsbbjAoD/cevWrUWLFo0YMeL69evffffdzZs3Fy1ahJwSoOuQVgJoxPDhw+nk0tnZGcklgI5AQgmgUUgrATSITi7z8vLo5NLd3f2XX37RdlAAfRESSoBugLQSQONGjBhBJ5c2NjYzZ850c3NDcgnQbZBQAnQbpJUA3YROLm/cuEEnl7hzCaBpSCgBuhnSSoBuNXLkyKNHj166dKl///4+Pj4eHh5ILgHUDgklgFYgrQTQgnHjxv3yyy+5ubkmJiY+Pj7jx49HcgmgFkgoAbQIaSWA1tDJ5aVLl4yNjenk8ty5c9oOCqCnQkIJoHVIKwG0jH6D548//jA2Np40aRKSS4DOQkIJoCOQVgLoBPoNnpycHCa5PH/+vLaDAtB1SCgBdArSSgAdQr/Bk5OTw+PxJk6cOH78+N9++03bQQHoIiSUADoIaSWAzvHw8MjKyvr99995PN5HH300fvz47OxsbQcFoCuQUALoLKSVADpq/PjxdHLJ5XInTJgwfvz4CxcuaDsoAG1CQgmg45BWAug0+g2e33//3cDA4MMPP5w8efKVK1e0HRRAd0NCCdAjIK0E6AHoN3h+//335ubmcePGTZ48+V//+pe2gwLoDkgoAXoQpJUAPQb9Bs/vv/8ulUrHjh07efLkq1evajsoAE1BQgnQ4yCtBOhh6Dd4fv311+rq6g8++ADJJfQ+SCgBeiiklQA90qRJky5fvvzrr79KJBI6ufzzzz+1HRRAVyGhBOjRkFYC9GCTJk26cuXKr7/+WlVVNWbMmMmTJ1+7dk3bQQGoAgklQC+AtBKgx5s0adK//vUvJrmcMWPG9evXtR0UgLKQUAL0GkgrAXoJOrk8e/bsixcvRo8ejeQSdB8SSoBeBmklQK8yadKkq1evnj179vnz53RyeePGDW0HBaAICSVAr4S0EqAXopPL9PT0Z8+e0cllXl6etoMCIAQJJUCvhrQSoHdisVgzZsz4888/09LSnj179v7778+YMePmzZvajgv6LiSUAL0e0kqA3kw+uXz69Ol77703d+7cO3fuaDsu6FuQUAL0EUgrAXo/Orm8du1aWlpacXHx0KFD586dW1RUpO24oPdDQgnQpyCtBOgr5JPLu3fvurq6IrkEzUFCCdAHIa0E6Fv09PTosYeSk5MLCgro5PLu3bvajgt6DySUAH0W0kqAvkhPT8/f37+wsDA5OTk/P3/IkCFILqHrkFAC9HFIKwH6Ljq5vHXrlnxyWVxcrO24oOdBQgkABGklAMgnlzdv3hw6dOiiRYvu3bun7bigZ0BCCQAMpJUAQMj/Jpe3b9/+8ccfr1y54urqiuQS2oeEEgAUIK0EgP8jn1xevnyZTi5LSkq0HRfoFiSUANAmpJUAoIh5oWffvn25ublDhgxZtGjR/fv3tR0XaB8SSgBoB9JKAGgbh8NZtGjRrVu3kFwCQUIJAEpAWgkA7WGSy7179166dGnIkCFBQUGlpaXtf6q5ubl7woOuk8lk7a+AhBIAlIS0EgA6RieXt2/f3rt377lz5xwdHYOCgp4+fdrmyjU1NWPHjn306FE3BwkqyMnJWbhw4dtqkVACQKcgrQQAZcknl1lZWQ4ODm0ml3FxcdevX58wYcKLFy+0EicoKScnZ/LkyUeOHLl27ZpCFRJKAFABi6IobccAAD1PU1PT999/v3nz5rKyssDAwI0bN77zzjuEkKqqKltbW4lEwmazHRwccnJyzMzMtB3s/2/vzsOiuNL9gZ+C3rGbRdaAKLtxv+6ABo2jV2VckCjEJYM+yeAWgitihCgiGjFgdODxcbkkVzMIEQJGQXOJUR9H49UoLhgVUTCobAo0W0Mv9fujfqnpCwgNNN0NfD9/zDN1TvWpt0417ZuqOudAK65fv/7+++83NjZSFDV9+vSsrCym/MGDB3v27PnnP/85ePDgzZs3L1myBNkkAGgIdysBoDN4PN7f//73goKCgwcPnj17lrlz+fLly6+//rq+vp4QolAonj175uPj8+bNG30HC83duXNnxowZjY2NSqVSoVBkZ2ffuHEDdygBoItwtxIAukomkx0+fHjPnj1VVVWEkIaGBraKy+UOHjz40qVL5ubm+gsQ/o979+699957tbW17MgqDoczaNCgp0+fDhkyJDIy0t/f38gINx0AoMOQVgKAdjQ0NCxYsCAnJ6fZMHAulztq1KgLFy7069dPX7EB6/Hjx97e3lVVVS1H6+/evXvz5s1IKAGg0/DzAQDa0dTU9K9//atlsiKXy2/fvu3r66t+FxP04smTJ5MmTWo1p+RwOJcvX0ZOCQBdgV8QANCOuLi4tyWOCoXi6tWrc+bMaWxs1HFUwHr+/PmUKVNazSkJIewblroPDAB6DTwEBwAtqKysHDBgQF1dXRv7GBsbz549Oy0tjcvl6iwwYBQXF3t6epaWlsrl8rftY2xsPH369OzsbF0GBgC9Ce5WAoAWfPvtt+ytSg6Hw+fzKYpqto9SqczKylqyZEm7y7qAdr169Wry5Mmt5pRGRkZ8Pp/D4RBClErlTz/9dP/+fX3ECAC9Ae5WQjdKTU3VdwigO3K5vKKiokxNSUlJWVkZM98QIYTL5SqVSpVK9d57761evbpl3gndobq6+osvvnj16hVFUUZGRmxOb2JiYmlpaW9vb21tbWVlxfyvlZUVk2JCX+Dl5eXg4KDvKKBXQVoJ3Qh5AwCAwUpJSVm0aJG+o4BeBf9VCt0LP1vdKjU1NSAgoIf+x6FKpdJ83DFFUfgudUKHOhn6FPxnP3QH/NwAgH4g3dEBdDIA6BJ+cQAAAABAC5BWAgAAAIAWIK0EAAAAAC1AWgkAAAAAWoC0EgAAAAC0AGklQJ+TlZVlamr6448/6juQ7rVy5UrqT0uXLlWvysnJCQ8PT0tLc3Z2ZnZYtmyZ+g4zZswQi8XGxsZDhw69deuWbgMnhBBDjo0QIpfLIyMjnZ2deTyevb39xo0b1ZeDj4qKGjJkiEQi4fP5rq6umzdvrq2tZapOnz795Zdfdm6ZJcO/aiyVShUfH+/l5dWy6sqVK97e3iKRyM7OLiwsrLGxUZPalv2WkZHBfr0tLS279XQAOoAG6DaEkJSUFH1H0ZulpKR04q/4zJkzEonk9OnT3RFSN+nEdyk4ONjCwiI7O/vRo0cymYwtj4yMnDNnjlQqZTZdXFz69+9PCDlz5oz6x7Ozs+fNm9f1yLvCYGNbvXq1QCBITk6WSqW//PKLRCJZvHgxW+vj45OQkPD69WupVJqSksLlcmfOnMnW7t+/38fHp7KyskNH7EFX7fHjx97e3oSQkSNHNqu6f/++UCiMiIiora29evWqpaXl8uXLNaxt1m8qlaq4uPjy5cuzZ8/u379/J+LE7zN0B6SV0I3ws9XdOpdW6kx9fb2np6dWmupcWmlvb9+scPfu3e7u7g0NDWyJi4vLd999Z2RkZG9vX1VVxZYbQoJimLEVFBQYGRn9/e9/Z0u2bdtGCHnw4AGz6evrq1Ao2FpmEvvnz5+zJSEhIZ6ennK5XMMj9qCrlpubu2DBghMnTowaNaplWhkQEODk5KRSqZjN2NhYiqJ+//13TWrpt/TbZ599hrQSDAceggNAdzl27FhZWZm+o/i3J0+eRERE7NixQyAQqJd7eXmFhoa+ePFi48aN+ortbQwwths3bqhUqgkTJrAlM2fOJIScP3+e2Txz5oyxsTFbyzyiZZeGJ4Rs3749Nzd3//79mhyuZ121kSNHpqWlLVmyhM/nN6tSKBRnz5718fFhl7eZNWsWTdOZmZnt1jI61G8AeoG0EqBvuXLliqOjI0VR//jHPwghiYmJJiYmIpEoMzNz1qxZEonEwcEhOTmZ2fnAgQMCgcDa2nrlypV2dnYCgcDLy+v69etMbUhICI/Hs7W1ZTbXrFljYmJCUVRFRQUhJDQ0dMOGDQUFBRRFubq6EkLOnTsnkUh27dqlh9P+83Romp47d27LqujoaHd396NHj+bk5LT6WZqm4+Li3n33XT6fb25uPn/+/IcPHzJVbfchIUSpVEZGRjo6OgqFwhEjRjD3mDVnaLExK/cIhUK2xM3NjRDy+++/t7r/ixcvhEKhk5MTW2Jubu7j47N//35ag3VHe+hVa+np06e1tbWOjo5siYuLCyHk7t277dYyOtRvAPqht/uk0AcQPGTpZp17CP7HH38QQg4ePMhsfv7554SQn3/+ubq6uqysbPLkySYmJk1NTUxtcHCwiYnJgwcPZDJZXl7euHHjxGIx+0BzyZIlNjY2bMuxsbGEkPLycmbT39/fxcWFrT1z5oxYLI6KiurEmXbiu9TyIbizs/OQIUOa7ebi4vLs2TOapq9evWpkZDRo0KDa2lq6xePUyMhIHo93/Pjxqqqqu3fvjh492tLSsqSkhKltuw83btzI5/NPnTpVWVm5detWIyOjGzduaHIKhhkbk+hERESwJQqFghDi5+fXcue6ujqxWBwSEtKsPDw8nBBy+/btdjuhx101xoQJE5o9BL906RIhJDY2Vr1QKBROmzat3VpWy37DQ3AwKLhbCQCEEOLl5SWRSKysrAIDA+vq6p4/f85WcTgc5n7PkCFDEhMTa2pqkpKSOnEIX19fqVQaERGhvag7oK6u7tmzZ8wdoFZ5enquW7eusLBwy5YtzaoaGhri4uIWLFiwdOlSU1PT4cOHHzp0qKKi4vDhw+q7tdqHMpksMTHRz8/P39/fzMxs27ZtXC63ox1oULENHz585syZCQkJFy5ckMlkJSUl6enpFEXJ5fKWO8fExNjZ2UVHRzcrZ25w3rt3r+1j9eir1gwzrFv99QBCCJfLZQbRt13L0rDfAPQFaSUA/B88Ho8Q0mqKQAgZO3asSCRinyT2IGVlZTRNi0SiNvaJjo728PBISEi4cuWKenleXl5tbe3YsWPZknHjxvF4PPZ9gGbU+/DRo0f19fXDhg1jqoRCoa2tbSc60KBiO3ny5MKFCz/66CMLCwtvb+8ffviBpmlmaLa69PT01NTU8+fPi8XiZlXMhSgtLW37QD39qqlj3g1l7uyympqamNcJ2q5ladhvAPqCtBIAOobP55eXl+s7ig6TyWSEkJYDKdQJBIKkpCSKolasWKF+l6iqqooQ0q9fP/WdzczMampq2j1uXV0dIWTbtm3sLINFRUXq41c0ZFCxmZqaHjp0qLi4uL6+vqCg4KuvviKEvPPOO+r7nDx5cs+ePRcvXhw0aFDLFphsibkobejpV00d8xayVCplS+rr62UymZ2dXbu1LA37DUBfkFYCQAfI5fKqqioHBwd9B9JhzL/H7U7E7enpuX79+vz8/J07d7KFZmZmhJBm6YiG/WBlZUUIiY+PV3/96Nq1a504BYON7caNG4SQqVOnsiUHDx48ceLEhQsXmuWarKamJvJ/x/20qhdcNZaTk5NYLC4qKmJLnjx5QggZMWJEu7UsDfsNQF+QVgJAB1y8eJGm6YkTJzKbHA7nbY/LDY21tTVFUdXV1e3uuXPnzsGDB9++fZstGTZsWL9+/W7evMmWXL9+vampacyYMe22NmDAAIFAkJub27mwe0RsR44ccXJy8vHxIYTQNB0WFnbv3r2MjIxmdwrVMRfCxsam7ZZ7x1VjcDic2bNnX758WaVSMSXZ2dkURTGD3NuuZWnYbwD6grQSANqhUqkqKysVCsXdu3dDQ0MdHR2DgoKYKldX1zdv3mRkZMjl8vLycvV7LYQQCwuLly9fFhYW1tTUyOXy7OxsPU4wJBKJnJ2di4uL292TeaiqPnhCIBBs2LAhPT39xIkTUqn03r17q1atsrOzCw4O1qS15cuXJycnJyYmSqVSpVJZXFz86tUrQkhgYKCNjU2Hlhk0kNjGjx9fVFSkUCgKCws3btyYk5Nz7Ngx5t3EBw8e7N2798iRI1wul1Kzb98+9RaYCzF8+PC2j9U7rhorIiKitLT0iy++qKuru3btWmxsbFBQkIeHhya1DPV+AzBE3TzSHPo0ggksulknJhg6ePAg8xaXSCSaO3duQkICMwjAzc2toKDg8OHDEomEEDJw4MDHjx/TNB0cHMzlcu3t7TkcjkQimT9/fkFBAdva69evp06dKhAInJycPv30002bNhFCXF1dmRmIbt26NXDgQKFQOGnSpJKSkqysLLFYHB0d3Ykz7cR3qeUEQyEhIVwut76+ntlMT09nhhhbWlquXbu22cc3bdqkPlWNSqWKjY11c3Pjcrnm5uZ+fn6PHj1iqtrtw8bGxrCwMEdHRw6HY2Vl5e/vn5eXR9O0n58fISQyMrJl8IYcG03T06dPNzMz43A45ubmvr6+6jPvvG2QcrOpc3x9fe3t7ZkVZdo+Vg+6ajRNX7t2zdvbm30h0tbW1svL69KlS+wOly5dGj9+PJ/Pt7Oz27Rpk/qyou3WNus3BiYYAoOCtBK6EX62upsOFm9kVtbu1kNoQitpZX5+PofDOX78uFZD6zylUjl58uRjx47pO5BWdGtsFRUVAoFg3759mhwLV43VrN8YSCvBoOAhOAC0o90BEwaroaHh/Pnz+fn5zEAHV1fXqKioqKio2tpafYdGlEplRkZGTU1NYGCgvmNprrtj2759+6hRo0JCQjQ5Fq4aS73faJp++fLllStXmJE9AAYCaSX0OSqVKj4+3svLqxOfffz48aeffjp06FCJRMLj8aysrAYPHrxgwYIffviB2SEtLc3Z2Vn9lTLmAfGKFSuePXvGtvP111+/8847FEUZGRm5u7urLz3317/+VSKRGBkZDR48+F//+lcXT7aPe/PmzcyZM93d3VesWMGUhIeHL1y4MDAwUJNRIN3q4sWLaWlp2dnZbU/KqBfdGltcXFxubm5WVhaXy9XwWLhqpEW/ZWZm2tvbT548+ezZszqOBKAt+r5dCr0ZMbyHLI8fP/b29iaENFtXTRNJSUk8Hm/SpEnnzp2rrKyUyWQFBQU//vijr69vcHCw+p4uLi6mpqY0TSuVytLS0v/+7/8WiUTW1tYVFRXquxFCJkyY0PJAv/zyS7MV296mux+Ch4eHM+MwBg0a9P3333ffgdql3e/S+fPnw8LCtNUaaC4jIyMmJkahUHTis335qnWl397GAH+foRfg6DGjBdCxO3fuREVFrVq1qq6ujqbpDn32119//fjjjydPnvw///M/HM7//8NxdnZmFizeu3dvq58yMjKytrZetmzZ/fv39+7dm5OTExAQ0NXT0KGYmJiYmBh9R6F9M2bMmDFjhr6j6IvmzZs3b968zn22L1+1rvQbgC7hITgYFpqmv//++2aL9mrLyJEj09LSlixZ0vaiHa3atWuXUqncvXs3m1OynJ2dDx061PbHXV1dCSElJSUdPS4AAEBPgbQS9EypVMbExHh4eAiFQktLSycnp5iYmEWLFhFC9u7dKxKJxGJxWVnZhg0b7O3t//M//5PH4zHz4xBC1qxZY2JiQlFURUVF1yM5d+7c22ZVbGpqysnJsbCwYKcB76j8/HxCyMiRI7sUIgAAgAFDWgl69uWXX0ZGRsbGxr558+ann36SyWRmZmbMqmubN29ev359bW1tTEyMk5PTxIkTv/76aybjZCQkJOzYsUNbkTDjndklLtQVFRXJZDJ3d/dONFtVVfXtt98mJCT4+vpOmTKli0ECAAAYLLxbCXqWkZExZswYZoGy0aNHz5s37+jRo01NTcxIEcaePXsEAsHatWu7NRJfX1+pVNpqFVPexkp0LVVXV1MUxfx/iqJ27ty5efPmrgcJAABgsJBWgp7JZDKBQMBuKpVKLpervgKbIWASyrq6umblqampYWFhhYWFhJDBgwdfunTJ2tqaqTI1Na2qqiKEbN68OTY21tTUlJkWpDssXLiwm1o2KPHx8d9//72+owAAgLfCQ3DQs9mzZ//222+ZmZkNDQ03b97MyMj461//amhp5cCBA/l8fstphxctWvTs2bOBAwfa2Nj8/vvvbE6pLiIiwtbWduvWrX/88UfL2lafuTO5tVYiBwAA0BncrQQ92759+2+//RYUFFRbW2tnZ7do0aJWB83ol0Ag+Mtf/nL27Nlff/21o6N2xGLxnj17goKCVq9e/eOPP6pXWVhYvHz5suVHnj17NmDAAM0P0Rfu4VEUtW7dOvU3awGgK9i3dAC0CHcrQc/y8vIKCgrKy8vlcvnz588TExPNzc3b2J/D4cjlcp2Fx9qxYweXy920aVMnjv7RRx9NmDDhzJkzqamp6uXvv//+ixcvrl69ql5I0/Q333wzYcKErkYMAACgW0grQc/Wrl3r6Oio+Wq/rq6ub968ycjIkMvl5eXlRUVF2ookOzv7bRMMEULGjBlz/Pjx3377bcqUKefOnXv16pVCoSgqKjp+/PibN2/abpmiqAMHDlAUFRISUllZyZZHR0ebmZktXLjwhx9+qKura2xsvHPnzuI73CK+AAAgAElEQVTFixUKxbJly7R1XgAAALqBtBL0LCYm5v79++bm5swK2jweb8iQIenp6YSQvXv3xsXFEULc3d1PnDjB7L969eqpU6d++OGHHh4eO3fuFAqFhBBPT89W31xs5tdff500adI777xz/fr1O3fu2NnZeXt7X758WcNQAwICHjx4MH78+I0bN7q5uYnF4qlTpx45cmTNmjXsY+irV696eHgUFBRUV1fb29uvWrWKKR8/fvzf/va30tJSZ2fnPXv2MIUeHh63b9/29fXdsGGDhYWFubn54sWL3d3df/75Z/WB8AAAAD0C1dEl7AA0R1FUSkpK2+/DJSYm5ufnx8fHM5tNTU1btmxJTEysrKxkUkZoQ2pqakBAQF/4K9bkuwQAmsPfFHQHDNkBfSopKQkJCcnNzWVLeDyeo6OjXC6Xy+VIKwEAAHoQPAQHfRIKhVwu99ixY6WlpXK5/OXLl0ePHo2MjAwMDJRIJB1q6uHDh9TbBQYGdtMpgOFYuXIle8WXLl2qXpWTkxMeHp6Wlubs7Mzs0Ozt1RkzZojFYmNj46FDh966dUu3gRNCiCHHxlKpVPHx8V5eXi2rrly54u3tLRKJ7OzswsLCGhsbNak9ffr0l19+ySxw1VGGf01ZOui3jIwM9stvaWnZracD0BYaoNsQQlJSUtre5/Lly3/5y18kEomxsbGpqamXl1dCQoJcLtdNhD1dSkpKH/kr1uS7FBwcbGFhkZ2d/ejRI5lMxpZHRkbOmTNHKpUymy4uLv379yeEnDlzRv3j2dnZ8+bN03rkHWLIsT1+/Njb25sQMnLkyGZV9+/fFwqFERERtbW1V69etbS0XL58uYa1+/fv9/Hxqays7FAwPeia6qbfVCpVcXHx5cuXZ8+e3b9/f00C0+RvCqCj+sQ/SKAv+NnqbjpIK+vr6z09PfXelIZppb29fbPC3bt3u7u7NzQ0sCUuLi7fffedkZGRvb19VVUVW24IKYjBxpabm7tgwYITJ06MGjWqZXoUEBDg5OSkUqmYzdjYWIqifv/9d01qaZoOCQnx9PTU/D8me9A11X2/ffbZZ0grQY/wEBwA2nLs2LGysjJDa0pDT548iYiI2LFjh/oCoYQQLy+v0NDQFy9ebNy4UZfxaMIwYxs5cmRaWtqSJUv4fH6zKoVCcfbsWR8fH3Z67VmzZtE0nZmZ2W4tY/v27bm5ufv379ckkp51TQ2n3wB0A2klQO9H03RcXNy7777L5/PNzc3nz5//8OFDpiokJITH49na2jKba9asMTExoSiqoqKCEBIaGrphw4aCggKKolxdXQ8cOCAQCKytrVeuXGlnZycQCLy8vK5fv96Jpggh586da2OiUK04cOAATdNz585tWRUdHe3u7n706NGcnJxWP9tGpyUmJpqYmIhEoszMzFmzZkkkEgcHh+TkZPazSqUyMjLS0dFRKBSOGDGCuamsOUOOraWnT5/W1tY6OjqyJS4uLoSQu3fvtlvLMDc39/Hx2b9/P63BnAY99Jq2pON+A9AR/dwkhb6B4CFLN9PwIXhkZCSPxzt+/HhVVdXdu3dHjx5taWlZUlLC1C5ZssTGxobdOTY2lhBSXl7ObPr7+7u4uLC1wcHBJiYmDx48kMlkeXl548aNE4vFz58/70RTZ86cEYvFUVFRmpypJt+llg/BnZ2dhwwZ0mw3FxeXZ8+e0TR99epVIyOjQYMG1dbW0i0emLbdaZ9//jkh5Oeff66uri4rK5s8ebKJiUlTUxNTu3HjRj6ff+rUqcrKyq1btxoZGd24cUOT0zTk2BgTJkxo9jD30qVLhJDY2Fj1QqFQOG3atHZrWeHh4YSQ27dvtxtAj7umDJ31Gx6Cg37hbiVAL9fQ0BAXF7dgwYKlS5eampoOHz780KFDFRUVhw8f7lyDHA6Hud8zZMiQxMTEmpqapKSkTrTj6+srlUojIiI6F0a76urqnj17xtzjaZWnp+e6desKCwu3bNnSrErDTvPy8pJIJFZWVoGBgXV1dc+fPyeEyGSyxMREPz8/f39/MzOzbdu2cbncjnaRIcfWDDM82djYWL2Qy+U2NDS0W8tyc3MjhNy7d6/tY/Xoa9qMLvsNQGeQVgL0cnl5ebW1tWPHjmVLxo0bx+Px2IfXXTF27FiRSMQ+STQoZWVlNE2LRKI29omOjvbw8EhISLhy5Yp6eUc7jVkViVkv/tGjR/X19cOGDWOqhEKhra1tJ7rIkGNTx7zjqFAo1AubmpqYeWfbrmUxl6m0tLTtY/X0a6pOl/0GoDNIKwF6uaqqKkJIv3791AvNzMxqamq00j6fzy8vL9dKU9olk8kIIS2HSqgTCARJSUkURa1YsUL9PlBXOq2uro4Qsm3bNnYewaKiovr6+o7Gb8ixqWPeppVKpWxJfX29TCazs7Nrt5bFZEvMJWtDT7+m6nTZbwA6g7QSoJczMzMjhDT7t7OqqsrBwaHrjcvlcm01pXXMv7jtTrXt6em5fv36/Pz8nTt3soVd6TQrKytCSHx8vPr7RteuXevEKRhybCwnJyexWFxUVMSWPHnyhBAyYsSIdmtZTU1N5M9L1oZecE1Zuuw3AJ1BWgnQyw0bNqxfv343b95kS65fv97U1DRmzBhmk8PhME/6OuHixYs0TU+cOLHrTWmdtbU1RVHV1dXt7rlz587Bgwffvn2bLWm309owYMAAgUCgviRpVxhybAwOhzN79uzLly+rVCqmJDs7m6IoZrB227Us5jLZ2Ni0fazecU0Zuuw3AJ1BWgnQywkEgg0bNqSnp584cUIqld67d2/VqlV2dnbBwcHMDq6urm/evMnIyJDL5eXl5eo3SAghFhYWL1++LCwsrKmpYVJGlUpVWVmpUCju3r0bGhrq6OgYFBTUiaays7O7dYIhkUjk7OxcXFzc7p7MY1P14RHtdlrbrS1fvjw5OTkxMVEqlSqVyuLi4levXhFCAgMDbWxsOrSQoCHHxoqIiCgtLf3iiy/q6uquXbsWGxsbFBTk4eGhSS2DuUzDhw9vO5LecU1Z2u03AIPQ7WPNoQ8jmMCim2k4wZBKpYqNjXVzc+Nyuebm5n5+fo8ePWJrX79+PXXqVIFA4OTk9Omnn27atIkQ4urqykwbdOvWrYEDBwqFwkmTJpWUlAQHB3O5XHt7ew6HI5FI5s+fX1BQ0LmmsrKyxGJxdHS0JmeqyXep5QRDISEhXC63vr6e2UxPT2cGEVtaWq5du7bZxzdt2qQ+GU0bnZaQkMAMlXBzcysoKDh8+DCzhP3AgQMfP35M03RjY2NYWJijoyOHw7GysvL398/Ly6Np2s/PjxASGRnZMnhDjo2m6WvXrnl7e7Mv9tna2np5eV26dInd4dKlS+PHj+fz+XZ2dps2bVJfPLPdWpqmfX197e3tmRVl2o6kB11THfcbAxMMgX4hrYRuhJ+t7qb7NcGZdbd1eURG59LK/Px8Dodz/Pjx7gytA5RK5eTJk48dO6bvQFqhx9gqKioEAsG+ffs0iQTXlNWs3xhIK0G/8BAcADqm3QETetTQ0HD+/Pn8/HxmKIOrq2tUVFRUVFRtba2+QyNKpTIjI6OmpiYwMFDfsTSn39i2b98+atSokJAQTSLBNWWp9xtN0y9fvrxy5QozsgdAX5BWAkDv8ebNm5kzZ7q7u69YsYIpCQ8PX7hwYWBgoCbjPLrVxYsX09LSsrOz2552US/0GFtcXFxubm5WVhaXy9UwElxT0qLfMjMz7e3tJ0+efPbsWR1HAqCOorGWKHQbiqJSUlIWLVqk70B6rdTU1ICAAJ39FW/duvWrr75qamoaNGhQbGzsBx98oJvjki5/l3766acLFy7s2bNHu1FBF2VmZj548GDz5s3NlpPRRF++pl3pNxZ+n6E7IK2EboSfre6m47RSj/BdAtAu/E1Bd8BDcAAAAADQAqSVAAAAAKAFSCsBAAAAQAuQVgIAAACAFiCtBAAAAAAtwEhw6EYURek7BAAAaB1GgoPWcfQdAPRmzNKCAL1DQEBAaGiop6envgMB0A4vLy99hwC9De5WAgBoBPP8AQC0De9WAgAAAIAWIK0EAAAAAC1AWgkAAAAAWoC0EgAAAAC0AGklAAAAAGgB0koAAAAA0AKklQAAAACgBUgrAQAAAEALkFYCAAAAgBYgrQQAAAAALUBaCQAAAABagLQSAAAAALQAaSUAAAAAaAHSSgAAAADQAqSVAAAAAKAFSCsBAAAAQAuQVgIAAACAFiCtBAAAAAAtQFoJAAAAAFqAtBIAAAAAtABpJQAAAABoAdJKAAAAANACpJUAAAAAoAVIKwEAAABAC5BWAgAAAIAWIK0EAAAAAC1AWgkAAAAAWoC0EgAAAAC0AGklAAAAAGgB0koAAAAA0AKklQAAAACgBUgrAQAAAEALOPoOAADAQCUnJ9fU1KiX5OTkVFVVsZt+fn5WVlY6jwsAwEBRNE3rOwYAAEMUFBT07bffcrlcZpP5taQoihCiVCr79etXVlbG5/P1GSIAgCHBQ3AAgNZ9+OGHhBD5nxQKhUKhYP6/sbHxwoULkVMCAKjD3UoAgNYpFAobG5s3b960Wvvzzz+///77Og4JAMCQ4W4lAEDrOBzOhx9+yD4EV2dpaenj46P7kAAADBnSSgCAt/rwww/lcnmzQi6Xu2zZMmNjY72EBABgsPAQHADgrWiadnR0LC4ublb+v//7v+PGjdNLSAAABgt3KwEA3oqiqKVLlzZ7Dj5gwICxY8fqKyQAAIOFtBIAoC3NnoNzudygoCBmmiEAAFCHh+AAAO0YPHjwo0eP2M379+8PHTpUj/EAABgm3K0EAGjHsmXL2OfgQ4YMQU4JANAqpJUAAO1YunSpQqEghHC53L/97W/6DgcAwEDhITgAQPvGjh3722+/URRVWFjo6Oio73AAAAwR7lYCALTvo48+IoRMmDABOSUAwNtw9B0AgP4tXLhQ3yGAoZPJZBRFNTY24tsC7Vq/fr2np6e+owDQA9ytBCCnTp1qOd81dJPi4uJTp07pO4oOEwgENjY2Dg4Omn8E36u+6dSpU3/88Ye+owDQD9ytBCCEkHXr1i1atEjfUfQJqampAQEB33//vb4D6bAnT564urpqvj9FUfhe9UGY0xT6MtytBADQSIdySgCAPghpJQAAAABoAdJKAAAAANACpJUAAAAAoAVIKwEAAABAC5BWAkAPkJWVZWpq+uOPP+o7kO6Sk5MTHh6elpbm7OxMURRFUcuWLVPfYcaMGWKx2NjYeOjQobdu3dJ9hIYcG0ulUsXHx3t5ebWsunLlire3t0gksrOzCwsLa2xs1KT29OnTX375pVKp1EX0AD0f0koA6AF69zKzX3zxxYEDB7Zu3erv7//06VMXF5f+/fufOHHi7Nmz7D4//fTT999/P2fOnLy8vNGjR+s+SEOOjZGfn//ee++tX7++vr6+WVVeXt6MGTOmTZtWXl6enp7+X//1X6tWrdKkdu7cuQKBYNq0aVVVVbo7E4AeC2klAPQAvr6+1dXVc+bM6e4DNTQ0tHqvq/vs2bPn5MmTqampYrGYLTxw4ICRkVFwcHB1dbUug9GEYcZ2586dLVu2rFq1atSoUS1rd+7caWtru2PHDhMTE09Pz7CwsG+++ebhw4ea1H722WcjR46cPXu2QqHQ3fkA9ExIKwEA/u3YsWNlZWU6O9yTJ08iIiJ27NghEAjUy728vEJDQ1+8eLFx40adBaMhw4xt5MiRaWlpS5Ys4fP5zaoUCsXZs2d9fHzYicpnzZpF03RmZma7tYzt27fn5ubu379fJ6cC0IMhrQQAQ3flyhVHR0eKov7xj38QQhITE01MTEQiUWZm5qxZsyQSiYODQ3JyMrPzgQMHBAKBtbX1ypUr7ezsBAKBl5fX9evXmdqQkBAej2dra8tsrlmzxsTEhKKoiooKQkhoaOiGDRsKCgooimImPz937pxEItm1a1c3ndqBAwdomp47d27LqujoaHd396NHj+bk5LT6WZqm4+Li3n33XT6fb25uPn/+fPYGW9tdRAhRKpWRkZGOjo5CoXDEiBEpKSkdCtuQY2vp6dOntbW1jo6ObImLiwsh5O7du+3WMszNzX18fPbv39+7X8YA6DqklQBg6CZNmnT16lV2c/Xq1evWrWtoaBCLxSkpKQUFBc7Ozp988olcLieEhISEBAUF1dfXf/bZZ4WFhbdu3VIoFNOnT2eWaT5w4ID6aooJCQk7duxgN/fv3z9nzhwXFxeapp88eUIIYcZqqFSqbjq1s2fPenh4iESillVCofCbb74xMjL65JNP6urqWu6wffv28PDwzz//vKys7PLly3/88cfkyZNLS0tJe11ECNmyZcvevXvj4+NfvXo1Z86cxYsX37x5U/OwDTm2lkpKSggh6u8YCAQCoVDIxNN2Les//uM/Xrx4cefOna5EAtDrIa0EgJ7Ky8tLIpFYWVkFBgbW1dU9f/6creJwOMytsiFDhiQmJtbU1CQlJXXiEL6+vlKpNCIiQntR/1tdXd2zZ8+Ye2Ot8vT0XLduXWFh4ZYtW5pVNTQ0xMXFLViwYOnSpaampsOHDz906FBFRcXhw4fVd2u1i2QyWWJiop+fn7+/v5mZ2bZt27hcbkf7x5Bja4YZ1m1sbKxeyOVyGxoa2q1lubm5EULu3bvXlUgAej2klQDQ4/F4PEIIe7urmbFjx4pEIvYhrOEoKyujabrVW5Ws6OhoDw+PhISEK1euqJfn5eXV1taOHTuWLRk3bhyPx2Mf9zej3kWPHj2qr68fNmwYUyUUCm1tbTvRP4YcmzrmvdVmA26ampqEQmG7tSzmMjW7hQkAzSCtBIDej8/nl5eX6zuK5mQyGSGk5RATdQKBICkpiaKoFStWqN8/Y+a76devn/rOZmZmNTU17R6XeWy9bds26k9FRUUtJ+VplyHHpo55lVYqlbIl9fX1MpnMzs6u3VoWk2UylwwA3gZpJQD0cnK5vKqqysHBQd+BNMdkKu1Ote3p6bl+/fr8/PydO3eyhWZmZoSQZomahqdpZWVFCImPj6fVXLt2rROnYMixsZycnMRicVFREVvCvDg7YsSIdmtZTU1N5M9LBgBvg7QSAHq5ixcv0jQ9ceJEZpPD4bztcbmOWVtbUxSlyeyPO3fuHDx48O3bt9mSYcOG9evXT30sy/Xr15uamsaMGdNuawMGDBAIBLm5uZ0LuwfFxuBwOLNnz758+TI79Co7O5uiKGYAftu1LOYy2djYaDEwgN4HaSUA9EIqlaqyslKhUNy9ezc0NNTR0TEoKIipcnV1ffPmTUZGhlwuLy8vV79NRQixsLB4+fJlYWFhTU2NXC7Pzs7uvgmGRCKRs7NzcXFxu3syj5vVh5UIBIINGzakp6efOHFCKpXeu3dv1apVdnZ2wcHBmrS2fPny5OTkxMREqVSqVCqLi4tfvXpFCAkMDLSxsenQAoyGHBsrIiKitLT0iy++qKuru3btWmxsbFBQkIeHhya1DOYyDR8+vBNHB+hDaIA+jxCSkpKi7yj6CmYawg595ODBg8wLcCKRaO7cuQkJCcz4CTc3t4KCgsOHD0skEkLIwIEDHz9+TNN0cHAwl8u1t7fncDgSiWT+/PkFBQVsa69fv546dapAIHBycvr00083bdpECHF1dX3+/DlN07du3Ro4cKBQKJw0aVJJSUlWVpZYLI6Oju7EmWryvQoJCeFyufX19cxmeno6MzDc0tJy7dq1zXbetGnTvHnz2E2VShUbG+vm5sblcs3Nzf38/B49esRUtdtFjY2NYWFhjo6OHA7HysrK398/Ly+Ppmk/Pz9CSGRkZMtQDTk2mqavXbvm7e3NvhBpa2vr5eV16dIldodLly6NHz+ez+fb2dlt2rRJJpOpf7ztWpqmfX197e3tVSpVq0dXh98T6MuQVgLgnwGd6kRa2VHBwcEWFhbdeghNaPK9ys/P53A4x48f101I7VIqlZMnTz527Ji+A2mFHmOrqKgQCAT79u3TZGf8nkBfhofgANALtTsOxkC4urpGRUVFRUXV1tbqOxaiVCozMjJqamoCAwP1HUtz+o1t+/bto0aNCgkJ0f2hAXoWpJUAAPoUHh6+cOHCwMBATcbudKuLFy+mpaVlZ2e3PZWmXugxtri4uNzc3KysLC6Xq+NDA/Q4SCsBOuzjjz8Wi8UURWl3vGqnpaWlOTs7U2p4PJ61tfWUKVNiY2MrKyv1HaBObd26NSkpqbq62snJ6dSpU/oORyO7du0KCQnZvXu3fsOYNm3ad999xy6YblD0FVtmZmZjY+PFixfNzc11fGiAnghpJUCHHT169MiRI/qO4t/8/f2fPn3q4uJiampK07RKpSorK0tNTXVycgoLCxs6dGgXl1TuWWJiYhobG2mafvbs2QcffKDvcDQ1Y8aMPXv26DsKaG7evHnh4eHNlnYEgLdBWgnQ21AUZWZmNmXKlKSkpNTU1NLSUl9fX70/YAUAgF4PaSVAZ1AUpe8QNPLBBx8EBQWVlZUdOnRI37EAAEAvh7QSQCM0TcfGxnp4ePD5fFNTU2ayQ5ZSqYyMjHR0dBQKhSNGjGDm0ElMTDQxMRGJRJmZmbNmzZJIJA4ODsnJyeynmKnyRCKRRCIZPnw4sypxq00RQs6dO9e5ebmZacCzs7N1FioAAPRNSCsBNBIREREWFhYcHFxaWlpSUrJlyxb12i1btuzduzc+Pv7Vq1dz5sxZvHjxzZs3V69evW7duoaGBrFYnJKSUlBQ4Ozs/MknnzArB9bV1c2dO/eDDz548+ZNfn6+u7s7s+hwq02RP2fMYdeX09yoUaMIIU+fPtVZqAAA0Efped5MAANA2pu+uL6+XiQSTZ8+nS1h7uTdvn2bpumGhgaRSBQYGMjuzOfzV69eTdP0559/TghpaGhgqhISEgghT548oWn6/v37hJAzZ86oH6iNptrFDtlpiXnb0kBC1cF06Aai3e8V9Eq47tCX4W4lQPuePHlSX18/bdq0VmsfPXpUX18/bNgwZlMoFNra2j58+LDlnjwejxDC3AJ0dna2trZeunTp9u3bCwsLO9qU5urq6miaZtbHM5xQqT6AEBIQEKDvKEDXuvLXCtDTcfQdAEAPUFxcTAixsrJqtbauro4Qsm3btm3btrGF7NrEbyMUCi9cuLBly5Zdu3ZFRUUtWrQoKSmpc0217fHjx4SQwYMHG1SofeFFzICAgNDQUE9PT30HAjoVEBCg7xAA9AZpJUD7BAIBIaSxsbHVWibdjI+PDw0N7VCzQ4cO/fHHH8vLy+Pi4vbs2TN06FBmYbpONNWGc+fOEUJmzZplUKEuWrSoE5/qWQICAjw9PfvCmYI6pJXQl+EhOED7hg0bZmRkdOnSpVZrBwwYIBAIOrrizsuXLx88eEAIsbKy2r179+jRox88eNC5ptpQUlISHx/v4OCwYsUKAw8VAAB6OqSVAO2zsrLy9/c/derUsWPHpFLp3bt3Dx8+zNYKBILly5cnJycnJiZKpVKlUllcXPzq1au223z58uXKlSsfPnzY1NR0+/btoqKiiRMnttFUdnZ2uxMM0TRdW1urUqlomi4vL09JSfH29jY2Ns7IyGDerdRNqAAA0EfpecgQgAEgGozcrKmp+fjjj/v379+vX79JkyZFRkYSQhwcHO7cuUPTdGNjY1hYmKOjI4fDYXLQvLy8hIQEkUhECHFzcysoKDh8+DCT2w0cOPDx48eFhYVeXl7m5ubGxsbvvPPO559/rlAo3tYUTdNZWVlisTg6OrplbKdPnx4xYoRIJOLxeEZGRuTPhXbGjx8fFRX1+vVr9Z11EGrbMBIcejdcd+jLKJqm9ZXRAhgIiqJSUlLwDpxupKamBgQE9IVfHnyv+iZcd+jL8BAcAAAAALQAaSUAgMHJyckJDw9PS0tzdnZmZkNctmyZ+g4zZswQi8XGxsZDhw69deuW7iM05NgIIXK5PDIy0tnZmcfj2dvbb9y4saGhga2NiooaMmSIRCLh8/murq6bN2+ura1lqk6fPv3ll18yi1oBQIfp+yk8gP4RvAulQ3i3sl2RkZFz5syRSqXMpouLS//+/UmLhY6ys7PnzZunhUC7wGBjW716tUAgSE5Olkqlv/zyi0QiWbx4MVvr4+OTkJDw+vVrqVSakpLC5XJnzpzJ1u7fv9/Hx6eysrJzh8bvCfRluFsJAL1NQ0ODl5eXoTWloT179pw8eTI1NVUsFrOFBw4cMDIyCg4Orq6u1mUwmjDA2J4+fXro0KGPPvooMDBQLBZPmTIlJCTkn//85++//87s0K9fv+DgYAsLC7FYvGjRIj8/v3Pnzv3xxx9M7WeffTZy5MjZs2crFAr9nQRAj4S0EgB6m2PHjpWVlRlaU5p48uRJRETEjh07mBn4WV5eXqGhoS9evNi4caPOgtGQAcZ248YNlUo1YcIEtmTmzJmEkPPnzzObZ86cMTY2ZmstLS0JIfX19WzJ9u3bc3Nz9+/fr6OIAXoLpJUAYIhomo6Li3v33Xf5fL65ufn8+fPZBcdDQkJ4PJ6trS2zuWbNGhMTE4qiKioqCCGhoaEbNmwoKCigKMrV1fXAgQMCgcDa2nrlypV2dnYCgcDLy+v69eudaIoQcu7cuXZnD+2KAwcO0DQ9d+7cllXR0dHu7u5Hjx7Nyclp9bNt9FhiYqKJiYlIJMrMzJw1a5ZEInFwcEhOTmY/q1QqIyMjHR0dhULhiBEjOrq0pqHFxkyzJRQK2RI3NzdCCHu3spkXL14IhUInJye2xNzc3MfHZ//+/XQfmLIAQJv0+ggewCAQvAulQxq+WxkZGcnj8Y4fP15VVXX37t3Ro0dbWlqWlJQwtUuWLLGxsWF3jo2NJYSUl5czm/7+/i4uLmxtcHCwiYnJgwcPZDJZXl7euHHjxGLx8+fPO9HUmTNnxGJxVFSUJmfaie+Vs7PzkCFDmhW6uLg8e/aMpumrV8BZbOMAAAa8SURBVK8aGRkNGjSotraWbvH+Yts99vnnnxNCfv755+rq6rKyssmTJ5uYmDQ1NTG1Gzdu5PP5p06dqqys3Lp1q5GR0Y0bNzQJ2DBju3v3LiEkIiKCLWEeZ/v5+bXcua6uTiwWh4SENCsPDw8nhNy+fVuTflCH3xPoy3C3EgAMTkNDQ1xc3IIFC5YuXWpqajp8+PBDhw5VVFSoL27UIRwOh7lVNmTIkMTExJqamqSkpE604+vrK5VKIyIiOhdG2+rq6p49e+bi4vK2HTw9PdetW1dYWLhly5ZmVRr2mJeXl0QisbKyCgwMrKure/78OSFEJpMlJib6+fn5+/ubmZlt27aNy+V2tH8MKrbhw4fPnDkzISHhwoULMpmspKQkPT2doii5XN5y55iYGDs7u+jo6GblzA3Oe/fudagfAPo4pJUAYHDy8vJqa2vHjh3LlowbN47H47EPr7ti7NixIpGIfQhrOMrKymiaZpY7epvo6GgPD4+EhIQrV66ol3e0x3g8HiGESbMePXpUX18/bNgwpkooFNra2naifwwqtpMnTy5cuPCjjz6ysLDw9vb+4YcfaJpmBq2rS09PT01NPX/+vPoAKQZzIUpLS9s9FgCwkFYCgMGpqqoihPTr10+90MzMrKamRivt8/n88vJyrTSlRTKZjBDC5/Pb2EcgECQlJVEUtWLFCvWJGLvSY3V1dYSQbdu2UX8qKipSH7+iIYOKzdTU9NChQ8XFxfX19QUFBV999RUh5J133lHf5+TJk3v27Ll48eKgQYNatsC8mslcFADQENJKADA4ZmZmhJBmaUdVVZWDg0PXG5fL5dpqSruYPKbdibg9PT3Xr1+fn5+/c+dOtrArPWZlZUUIiY+PV39B6tq1a504BYON7caNG4SQqVOnsiUHDx48ceLEhQsXmuWarKamJvJ/x/0AQLuQVgKAwRk2bFi/fv1u3rzJlly/fr2pqWnMmDHMJofDafU9OU1cvHiRpumJEyd2vSntsra2pihKk9kfd+7cOXjw4Nu3b7Ml7fZYGwYMGCAQCHJzczsXdo+I7ciRI05OTj4+PoQQmqbDwsLu3buXkZHR7B6qOuZC2NjYdPHQAH0K0koAMDgCgWDDhg3p6eknTpyQSqX37t1btWqVnZ1dcHAws4Orq+ubN28yMjLkcnl5eXlRUZH6xy0sLF6+fFlYWFhTU8OkjCqVqrKyUqFQ3L17NzQ01NHRMSgoqBNNZWdnd98EQyKRyNnZubi4uN09mcfN6jMvtttjbbe2fPny5OTkxMREqVSqVCqLi4tfvXpFCAkMDLSxsenQAowGEtv48eOLiooUCkVhYeHGjRtzcnKOHTvGvLX54MGDvXv3HjlyhMvlUmr27dun3gJzIYYPH675uQMAJhgCwIQgOqXhBEMqlSo2NtbNzY3L5Zqbm/v5+T169Iitff369dSpUwUCgZOT06effrpp0yZCiKurKzNt0K1btwYOHCgUCidNmlRSUhIcHMzlcu3t7TkcjkQimT9/fkFBQeeaysrKEovF0dHRmpxpJ75XISEhXC63vr6e2UxPT2cGhltaWq5du7bZzps2bVKfxKeNHktISGAGoLi5uRUUFBw+fFgikRBCBg4c+PjxY5qmGxsbw8LCHB0dORyOlZWVv79/Xl4eTdN+fn6EkMjIyJahGnJsNE1Pnz7dzMyMw+GYm5v7+vqqz0n0tsHdsbGx6i34+vra29urVKrWL9Xb4fcE+jKklQD4Z0CndL8mOLNMny6PyOjE9yo/P5/D4Rw/frybQuoopVI5efLkY8eO6TuQVnRrbBUVFQKBYN++fZ34LH5PoC/DQ3AA6P3aHQdjIFxdXaOioqKiompra/UdC1EqlRkZGTU1NYGBgfqOpbnujm379u2jRo0KCQnpjsYBejGklQAABiQ8PHzhwoWBgYGajN3pVhcvXkxLS8vOzm57Kk296NbY4uLicnNzs7KyuFyu1hsH6N2QVgJAb7Z169akpKTq6monJ6dTp07pOxyN7Nq1KyQkZPfu3foNY9q0ad999x27YLpB6b7YMjMzGxsbL168aG5urvXGAXo9jr4DAADoRjExMTExMfqOosNmzJgxY8YMfUfRF82bN2/evHn6jgKgp8LdSgAAAADQAqSVAAAAAKAFSCsBAAAAQAuQVgIAAACAFmDIDgAhhFy7dk3fIfQVTFenpqbqOxBdwPcKAPoUiqZpfccAoGcURek7BADoPVJSUhYtWqTvKAD0AGklAAAAAGgB3q0EAAAAAC1AWgkAAAAAWoC0EgAAAAC0AGklAAAAAGjB/wOMxG0LNVgVXgAAAABJRU5ErkJggg==\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"gm2_wEY4HPGJ"},"source":["<h3>Training GRU model for 260 epochs </h3>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2vx1PWWV0Ve","executionInfo":{"status":"ok","timestamp":1616214920867,"user_tz":-330,"elapsed":259039,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"129252d7-a2eb-436f-8e4d-b6d2115d820f"},"source":["#model with 1% validation data with Adam optimizer.\n","optimizer = tf.keras.optimizers.Adam(0.0001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data],decoder_output_data,validation_data=([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data),batch_size=64,epochs=260,callbacks=[rl])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/260\n","31/31 [==============================] - 35s 57ms/step - loss: 4.3960 - val_loss: 4.2950\n","Epoch 2/260\n","31/31 [==============================] - 1s 27ms/step - loss: 4.2349 - val_loss: 4.0985\n","Epoch 3/260\n","31/31 [==============================] - 1s 27ms/step - loss: 3.9942 - val_loss: 3.6156\n","Epoch 4/260\n","31/31 [==============================] - 1s 27ms/step - loss: 3.0955 - val_loss: 1.8410\n","Epoch 5/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.6462 - val_loss: 1.7022\n","Epoch 6/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.5482 - val_loss: 1.6097\n","Epoch 7/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.4849 - val_loss: 1.5465\n","Epoch 8/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.4083 - val_loss: 1.5009\n","Epoch 9/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.3482 - val_loss: 1.4687\n","Epoch 10/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.3538 - val_loss: 1.4457\n","Epoch 11/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2829 - val_loss: 1.4274\n","Epoch 12/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2843 - val_loss: 1.4126\n","Epoch 13/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.3078 - val_loss: 1.4015\n","Epoch 14/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2760 - val_loss: 1.3888\n","Epoch 15/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2491 - val_loss: 1.3798\n","Epoch 16/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2545 - val_loss: 1.3694\n","Epoch 17/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2318 - val_loss: 1.3611\n","Epoch 18/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2421 - val_loss: 1.3523\n","Epoch 19/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2213 - val_loss: 1.3444\n","Epoch 20/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2456 - val_loss: 1.3386\n","Epoch 21/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1979 - val_loss: 1.3295\n","Epoch 22/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2175 - val_loss: 1.3224\n","Epoch 23/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1887 - val_loss: 1.3158\n","Epoch 24/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1895 - val_loss: 1.3097\n","Epoch 25/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1802 - val_loss: 1.3045\n","Epoch 26/260\n","31/31 [==============================] - 1s 26ms/step - loss: 1.2087 - val_loss: 1.2974\n","Epoch 27/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.2068 - val_loss: 1.2917\n","Epoch 28/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1762 - val_loss: 1.2866\n","Epoch 29/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1498 - val_loss: 1.2817\n","Epoch 30/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1760 - val_loss: 1.2773\n","Epoch 31/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1720 - val_loss: 1.2724\n","Epoch 32/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1532 - val_loss: 1.2685\n","Epoch 33/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1305 - val_loss: 1.2646\n","Epoch 34/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.1658 - val_loss: 1.2602\n","Epoch 35/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.1497 - val_loss: 1.2566\n","Epoch 36/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1187 - val_loss: 1.2530\n","Epoch 37/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1448 - val_loss: 1.2496\n","Epoch 38/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1482 - val_loss: 1.2461\n","Epoch 39/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1503 - val_loss: 1.2429\n","Epoch 40/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1375 - val_loss: 1.2396\n","Epoch 41/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0985 - val_loss: 1.2365\n","Epoch 42/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1082 - val_loss: 1.2332\n","Epoch 43/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1181 - val_loss: 1.2300\n","Epoch 44/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.1100 - val_loss: 1.2268\n","Epoch 45/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.1316 - val_loss: 1.2236\n","Epoch 46/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.1037 - val_loss: 1.2205\n","Epoch 47/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.1123 - val_loss: 1.2172\n","Epoch 48/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0892 - val_loss: 1.2140\n","Epoch 49/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0895 - val_loss: 1.2108\n","Epoch 50/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0932 - val_loss: 1.2075\n","Epoch 51/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.1080 - val_loss: 1.2042\n","Epoch 52/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0901 - val_loss: 1.2008\n","Epoch 53/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0998 - val_loss: 1.1975\n","Epoch 54/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0731 - val_loss: 1.1940\n","Epoch 55/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0832 - val_loss: 1.1906\n","Epoch 56/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0782 - val_loss: 1.1871\n","Epoch 57/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0719 - val_loss: 1.1835\n","Epoch 58/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0705 - val_loss: 1.1797\n","Epoch 59/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0675 - val_loss: 1.1759\n","Epoch 60/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0786 - val_loss: 1.1721\n","Epoch 61/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0540 - val_loss: 1.1683\n","Epoch 62/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0813 - val_loss: 1.1646\n","Epoch 63/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0354 - val_loss: 1.1605\n","Epoch 64/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0513 - val_loss: 1.1566\n","Epoch 65/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0369 - val_loss: 1.1525\n","Epoch 66/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0412 - val_loss: 1.1485\n","Epoch 67/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0170 - val_loss: 1.1443\n","Epoch 68/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0344 - val_loss: 1.1402\n","Epoch 69/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0515 - val_loss: 1.1359\n","Epoch 70/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0189 - val_loss: 1.1317\n","Epoch 71/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0501 - val_loss: 1.1274\n","Epoch 72/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0228 - val_loss: 1.1232\n","Epoch 73/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0252 - val_loss: 1.1190\n","Epoch 74/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0144 - val_loss: 1.1147\n","Epoch 75/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0225 - val_loss: 1.1105\n","Epoch 76/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0152 - val_loss: 1.1062\n","Epoch 77/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0077 - val_loss: 1.1020\n","Epoch 78/260\n","31/31 [==============================] - 1s 28ms/step - loss: 1.0207 - val_loss: 1.0977\n","Epoch 79/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0108 - val_loss: 1.0936\n","Epoch 80/260\n","31/31 [==============================] - 1s 27ms/step - loss: 1.0025 - val_loss: 1.0894\n","Epoch 81/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9919 - val_loss: 1.0852\n","Epoch 82/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9737 - val_loss: 1.0810\n","Epoch 83/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9768 - val_loss: 1.0770\n","Epoch 84/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9641 - val_loss: 1.0729\n","Epoch 85/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9750 - val_loss: 1.0689\n","Epoch 86/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9638 - val_loss: 1.0649\n","Epoch 87/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9809 - val_loss: 1.0609\n","Epoch 88/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9654 - val_loss: 1.0571\n","Epoch 89/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9483 - val_loss: 1.0532\n","Epoch 90/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9677 - val_loss: 1.0496\n","Epoch 91/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9393 - val_loss: 1.0457\n","Epoch 92/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9660 - val_loss: 1.0422\n","Epoch 93/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9722 - val_loss: 1.0386\n","Epoch 94/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9416 - val_loss: 1.0353\n","Epoch 95/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9405 - val_loss: 1.0319\n","Epoch 96/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9348 - val_loss: 1.0285\n","Epoch 97/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9216 - val_loss: 1.0253\n","Epoch 98/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9408 - val_loss: 1.0220\n","Epoch 99/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9232 - val_loss: 1.0188\n","Epoch 100/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9259 - val_loss: 1.0156\n","Epoch 101/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9191 - val_loss: 1.0125\n","Epoch 102/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9340 - val_loss: 1.0095\n","Epoch 103/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9110 - val_loss: 1.0065\n","Epoch 104/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.9057 - val_loss: 1.0037\n","Epoch 105/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9188 - val_loss: 1.0008\n","Epoch 106/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9118 - val_loss: 0.9979\n","Epoch 107/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9158 - val_loss: 0.9952\n","Epoch 108/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9107 - val_loss: 0.9924\n","Epoch 109/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8837 - val_loss: 0.9898\n","Epoch 110/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9297 - val_loss: 0.9869\n","Epoch 111/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.9080 - val_loss: 0.9843\n","Epoch 112/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.9240 - val_loss: 0.9817\n","Epoch 113/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8965 - val_loss: 0.9792\n","Epoch 114/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8795 - val_loss: 0.9768\n","Epoch 115/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8999 - val_loss: 0.9742\n","Epoch 116/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8758 - val_loss: 0.9718\n","Epoch 117/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8812 - val_loss: 0.9693\n","Epoch 118/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8872 - val_loss: 0.9669\n","Epoch 119/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8897 - val_loss: 0.9648\n","Epoch 120/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8769 - val_loss: 0.9623\n","Epoch 121/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8641 - val_loss: 0.9600\n","Epoch 122/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8900 - val_loss: 0.9577\n","Epoch 123/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8476 - val_loss: 0.9557\n","Epoch 124/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8822 - val_loss: 0.9536\n","Epoch 125/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8675 - val_loss: 0.9512\n","Epoch 126/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8628 - val_loss: 0.9490\n","Epoch 127/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8481 - val_loss: 0.9469\n","Epoch 128/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8752 - val_loss: 0.9446\n","Epoch 129/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8631 - val_loss: 0.9426\n","Epoch 130/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8601 - val_loss: 0.9404\n","Epoch 131/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8560 - val_loss: 0.9384\n","Epoch 132/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8564 - val_loss: 0.9361\n","Epoch 133/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8762 - val_loss: 0.9341\n","Epoch 134/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8348 - val_loss: 0.9320\n","Epoch 135/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8521 - val_loss: 0.9301\n","Epoch 136/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8502 - val_loss: 0.9278\n","Epoch 137/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8291 - val_loss: 0.9259\n","Epoch 138/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8569 - val_loss: 0.9239\n","Epoch 139/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.8376 - val_loss: 0.9219\n","Epoch 140/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8441 - val_loss: 0.9200\n","Epoch 141/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8394 - val_loss: 0.9180\n","Epoch 142/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8407 - val_loss: 0.9161\n","Epoch 143/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8295 - val_loss: 0.9142\n","Epoch 144/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8211 - val_loss: 0.9122\n","Epoch 145/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8239 - val_loss: 0.9104\n","Epoch 146/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8332 - val_loss: 0.9085\n","Epoch 147/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8200 - val_loss: 0.9066\n","Epoch 148/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8153 - val_loss: 0.9048\n","Epoch 149/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8302 - val_loss: 0.9029\n","Epoch 150/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8226 - val_loss: 0.9010\n","Epoch 151/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8047 - val_loss: 0.8993\n","Epoch 152/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8393 - val_loss: 0.8975\n","Epoch 153/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8185 - val_loss: 0.8957\n","Epoch 154/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8089 - val_loss: 0.8941\n","Epoch 155/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8467 - val_loss: 0.8924\n","Epoch 156/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8201 - val_loss: 0.8907\n","Epoch 157/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8276 - val_loss: 0.8890\n","Epoch 158/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8204 - val_loss: 0.8872\n","Epoch 159/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8010 - val_loss: 0.8855\n","Epoch 160/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8021 - val_loss: 0.8841\n","Epoch 161/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8033 - val_loss: 0.8825\n","Epoch 162/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8231 - val_loss: 0.8808\n","Epoch 163/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8135 - val_loss: 0.8794\n","Epoch 164/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.7986 - val_loss: 0.8778\n","Epoch 165/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.7865 - val_loss: 0.8763\n","Epoch 166/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7887 - val_loss: 0.8749\n","Epoch 167/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7917 - val_loss: 0.8737\n","Epoch 168/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7940 - val_loss: 0.8718\n","Epoch 169/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7847 - val_loss: 0.8704\n","Epoch 170/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.8015 - val_loss: 0.8691\n","Epoch 171/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8036 - val_loss: 0.8676\n","Epoch 172/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8090 - val_loss: 0.8663\n","Epoch 173/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.8001 - val_loss: 0.8650\n","Epoch 174/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8092 - val_loss: 0.8635\n","Epoch 175/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7999 - val_loss: 0.8622\n","Epoch 176/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.8047 - val_loss: 0.8609\n","Epoch 177/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7880 - val_loss: 0.8594\n","Epoch 178/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7860 - val_loss: 0.8580\n","Epoch 179/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7889 - val_loss: 0.8568\n","Epoch 180/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7811 - val_loss: 0.8557\n","Epoch 181/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7809 - val_loss: 0.8540\n","Epoch 182/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7874 - val_loss: 0.8528\n","Epoch 183/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7822 - val_loss: 0.8520\n","Epoch 184/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7679 - val_loss: 0.8504\n","Epoch 185/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7879 - val_loss: 0.8490\n","Epoch 186/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7844 - val_loss: 0.8479\n","Epoch 187/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7914 - val_loss: 0.8465\n","Epoch 188/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7716 - val_loss: 0.8454\n","Epoch 189/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.7750 - val_loss: 0.8439\n","Epoch 190/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7691 - val_loss: 0.8429\n","Epoch 191/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7734 - val_loss: 0.8414\n","Epoch 192/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7852 - val_loss: 0.8401\n","Epoch 193/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7683 - val_loss: 0.8390\n","Epoch 194/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7764 - val_loss: 0.8377\n","Epoch 195/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7764 - val_loss: 0.8367\n","Epoch 196/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7608 - val_loss: 0.8353\n","Epoch 197/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7584 - val_loss: 0.8340\n","Epoch 198/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7605 - val_loss: 0.8328\n","Epoch 199/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7762 - val_loss: 0.8316\n","Epoch 200/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7719 - val_loss: 0.8303\n","Epoch 201/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7645 - val_loss: 0.8291\n","Epoch 202/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7447 - val_loss: 0.8283\n","Epoch 203/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7564 - val_loss: 0.8267\n","Epoch 204/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7462 - val_loss: 0.8256\n","Epoch 205/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7769 - val_loss: 0.8244\n","Epoch 206/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7567 - val_loss: 0.8232\n","Epoch 207/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7588 - val_loss: 0.8221\n","Epoch 208/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7627 - val_loss: 0.8210\n","Epoch 209/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7594 - val_loss: 0.8197\n","Epoch 210/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7452 - val_loss: 0.8185\n","Epoch 211/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7463 - val_loss: 0.8174\n","Epoch 212/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.7399 - val_loss: 0.8167\n","Epoch 213/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7305 - val_loss: 0.8151\n","Epoch 214/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7459 - val_loss: 0.8141\n","Epoch 215/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7594 - val_loss: 0.8129\n","Epoch 216/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7410 - val_loss: 0.8117\n","Epoch 217/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7275 - val_loss: 0.8106\n","Epoch 218/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7268 - val_loss: 0.8093\n","Epoch 219/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7449 - val_loss: 0.8081\n","Epoch 220/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7557 - val_loss: 0.8072\n","Epoch 221/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7278 - val_loss: 0.8060\n","Epoch 222/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7501 - val_loss: 0.8046\n","Epoch 223/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7398 - val_loss: 0.8038\n","Epoch 224/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7400 - val_loss: 0.8035\n","Epoch 225/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7244 - val_loss: 0.8020\n","Epoch 226/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7471 - val_loss: 0.8011\n","Epoch 227/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7455 - val_loss: 0.7998\n","Epoch 228/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7384 - val_loss: 0.7987\n","Epoch 229/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7512 - val_loss: 0.7976\n","Epoch 230/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7355 - val_loss: 0.7966\n","Epoch 231/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7245 - val_loss: 0.7954\n","Epoch 232/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7427 - val_loss: 0.7940\n","Epoch 233/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7326 - val_loss: 0.7924\n","Epoch 234/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7377 - val_loss: 0.7915\n","Epoch 235/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7469 - val_loss: 0.7904\n","Epoch 236/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7203 - val_loss: 0.7892\n","Epoch 237/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7211 - val_loss: 0.7883\n","Epoch 238/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.7290 - val_loss: 0.7871\n","Epoch 239/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6995 - val_loss: 0.7861\n","Epoch 240/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7255 - val_loss: 0.7852\n","Epoch 241/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7107 - val_loss: 0.7839\n","Epoch 242/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7339 - val_loss: 0.7827\n","Epoch 243/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7287 - val_loss: 0.7812\n","Epoch 244/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7384 - val_loss: 0.7804\n","Epoch 245/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7473 - val_loss: 0.7793\n","Epoch 246/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7102 - val_loss: 0.7784\n","Epoch 247/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7154 - val_loss: 0.7771\n","Epoch 248/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7316 - val_loss: 0.7760\n","Epoch 249/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7074 - val_loss: 0.7745\n","Epoch 250/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7197 - val_loss: 0.7738\n","Epoch 251/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7200 - val_loss: 0.7726\n","Epoch 252/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7295 - val_loss: 0.7718\n","Epoch 253/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7154 - val_loss: 0.7707\n","Epoch 254/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7041 - val_loss: 0.7696\n","Epoch 255/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7267 - val_loss: 0.7686\n","Epoch 256/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7158 - val_loss: 0.7675\n","Epoch 257/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7140 - val_loss: 0.7663\n","Epoch 258/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7074 - val_loss: 0.7654\n","Epoch 259/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7105 - val_loss: 0.7641\n","Epoch 260/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7085 - val_loss: 0.7635\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fac46df6590>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"Ot3ohcLYHXCL"},"source":["<h3> Training GRU for another 260 epochs </h3>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvlZ6IviZ3TN","executionInfo":{"status":"ok","timestamp":1616215193616,"user_tz":-330,"elapsed":230267,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"694e98fb-b01b-40a9-a065-0ce71619a0d2"},"source":["#model with 1% validation data with Adam optimizer.\n","optimizer = tf.keras.optimizers.Adam(0.0001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data],decoder_output_data,validation_data=([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data),batch_size=64,epochs=260,callbacks=[rl])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/260\n","31/31 [==============================] - 4s 50ms/step - loss: 0.6996 - val_loss: 0.7622\n","Epoch 2/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7056 - val_loss: 0.7612\n","Epoch 3/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7010 - val_loss: 0.7602\n","Epoch 4/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6909 - val_loss: 0.7590\n","Epoch 5/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7154 - val_loss: 0.7583\n","Epoch 6/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7101 - val_loss: 0.7575\n","Epoch 7/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6987 - val_loss: 0.7564\n","Epoch 8/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7134 - val_loss: 0.7552\n","Epoch 9/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6954 - val_loss: 0.7543\n","Epoch 10/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6859 - val_loss: 0.7531\n","Epoch 11/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.7005 - val_loss: 0.7524\n","Epoch 12/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6864 - val_loss: 0.7514\n","Epoch 13/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6956 - val_loss: 0.7504\n","Epoch 14/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7060 - val_loss: 0.7508\n","Epoch 15/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6961 - val_loss: 0.7506\n","Epoch 16/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6899 - val_loss: 0.7494\n","Epoch 17/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.7048 - val_loss: 0.7480\n","Epoch 18/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6883 - val_loss: 0.7470\n","Epoch 19/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6775 - val_loss: 0.7457\n","Epoch 20/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6973 - val_loss: 0.7445\n","Epoch 21/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6882 - val_loss: 0.7437\n","Epoch 22/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6990 - val_loss: 0.7428\n","Epoch 23/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6971 - val_loss: 0.7417\n","Epoch 24/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6901 - val_loss: 0.7409\n","Epoch 25/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6838 - val_loss: 0.7399\n","Epoch 26/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6831 - val_loss: 0.7391\n","Epoch 27/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6845 - val_loss: 0.7382\n","Epoch 28/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6767 - val_loss: 0.7373\n","Epoch 29/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6825 - val_loss: 0.7369\n","Epoch 30/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6825 - val_loss: 0.7359\n","Epoch 31/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6793 - val_loss: 0.7354\n","Epoch 32/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6944 - val_loss: 0.7345\n","Epoch 33/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6844 - val_loss: 0.7335\n","Epoch 34/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6789 - val_loss: 0.7326\n","Epoch 35/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6621 - val_loss: 0.7318\n","Epoch 36/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6810 - val_loss: 0.7312\n","Epoch 37/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6865 - val_loss: 0.7303\n","Epoch 38/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6747 - val_loss: 0.7304\n","Epoch 39/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6800 - val_loss: 0.7288\n","Epoch 40/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6711 - val_loss: 0.7285\n","Epoch 41/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6802 - val_loss: 0.7277\n","Epoch 42/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6827 - val_loss: 0.7272\n","Epoch 43/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6731 - val_loss: 0.7269\n","Epoch 44/260\n","31/31 [==============================] - 1s 31ms/step - loss: 0.6773 - val_loss: 0.7258\n","Epoch 45/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6616 - val_loss: 0.7247\n","Epoch 46/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6834 - val_loss: 0.7237\n","Epoch 47/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6500 - val_loss: 0.7230\n","Epoch 48/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6782 - val_loss: 0.7223\n","Epoch 49/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6715 - val_loss: 0.7211\n","Epoch 50/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6723 - val_loss: 0.7207\n","Epoch 51/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6621 - val_loss: 0.7200\n","Epoch 52/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6459 - val_loss: 0.7191\n","Epoch 53/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6722 - val_loss: 0.7186\n","Epoch 54/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6605 - val_loss: 0.7177\n","Epoch 55/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6726 - val_loss: 0.7174\n","Epoch 56/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6659 - val_loss: 0.7165\n","Epoch 57/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6695 - val_loss: 0.7163\n","Epoch 58/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6683 - val_loss: 0.7154\n","Epoch 59/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6595 - val_loss: 0.7144\n","Epoch 60/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6741 - val_loss: 0.7136\n","Epoch 61/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6573 - val_loss: 0.7128\n","Epoch 62/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6578 - val_loss: 0.7121\n","Epoch 63/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6445 - val_loss: 0.7116\n","Epoch 64/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6650 - val_loss: 0.7110\n","Epoch 65/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6536 - val_loss: 0.7105\n","Epoch 66/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6584 - val_loss: 0.7095\n","Epoch 67/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6426 - val_loss: 0.7091\n","Epoch 68/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6605 - val_loss: 0.7086\n","Epoch 69/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6728 - val_loss: 0.7079\n","Epoch 70/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6473 - val_loss: 0.7072\n","Epoch 71/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6529 - val_loss: 0.7066\n","Epoch 72/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6520 - val_loss: 0.7059\n","Epoch 73/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6614 - val_loss: 0.7051\n","Epoch 74/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6581 - val_loss: 0.7043\n","Epoch 75/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6541 - val_loss: 0.7039\n","Epoch 76/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6467 - val_loss: 0.7033\n","Epoch 77/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6555 - val_loss: 0.7026\n","Epoch 78/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6458 - val_loss: 0.7019\n","Epoch 79/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6578 - val_loss: 0.7017\n","Epoch 80/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6480 - val_loss: 0.7006\n","Epoch 81/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6652 - val_loss: 0.7002\n","Epoch 82/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6409 - val_loss: 0.6999\n","Epoch 83/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6427 - val_loss: 0.6990\n","Epoch 84/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6328 - val_loss: 0.6981\n","Epoch 85/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6418 - val_loss: 0.6980\n","Epoch 86/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6472 - val_loss: 0.6972\n","Epoch 87/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6458 - val_loss: 0.6966\n","Epoch 88/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6479 - val_loss: 0.6956\n","Epoch 89/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6550 - val_loss: 0.6953\n","Epoch 90/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6521 - val_loss: 0.6947\n","Epoch 91/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6448 - val_loss: 0.6942\n","Epoch 92/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6342 - val_loss: 0.6935\n","Epoch 93/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6402 - val_loss: 0.6929\n","Epoch 94/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6381 - val_loss: 0.6925\n","Epoch 95/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6538 - val_loss: 0.6918\n","Epoch 96/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6405 - val_loss: 0.6910\n","Epoch 97/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6414 - val_loss: 0.6906\n","Epoch 98/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6398 - val_loss: 0.6899\n","Epoch 99/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6525 - val_loss: 0.6896\n","Epoch 100/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6472 - val_loss: 0.6888\n","Epoch 101/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6432 - val_loss: 0.6887\n","Epoch 102/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6511 - val_loss: 0.6878\n","Epoch 103/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6489 - val_loss: 0.6870\n","Epoch 104/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6430 - val_loss: 0.6864\n","Epoch 105/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6434 - val_loss: 0.6859\n","Epoch 106/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6532 - val_loss: 0.6853\n","Epoch 107/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6289 - val_loss: 0.6846\n","Epoch 108/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6369 - val_loss: 0.6842\n","Epoch 109/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6381 - val_loss: 0.6836\n","Epoch 110/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6235 - val_loss: 0.6831\n","Epoch 111/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6424 - val_loss: 0.6829\n","Epoch 112/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6441 - val_loss: 0.6819\n","Epoch 113/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6432 - val_loss: 0.6816\n","Epoch 114/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6347 - val_loss: 0.6807\n","Epoch 115/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6301 - val_loss: 0.6804\n","Epoch 116/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6348 - val_loss: 0.6796\n","Epoch 117/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6331 - val_loss: 0.6794\n","Epoch 118/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6304 - val_loss: 0.6787\n","Epoch 119/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6247 - val_loss: 0.6782\n","Epoch 120/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6361 - val_loss: 0.6777\n","Epoch 121/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6089 - val_loss: 0.6770\n","Epoch 122/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6166 - val_loss: 0.6766\n","Epoch 123/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6263 - val_loss: 0.6760\n","Epoch 124/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6115 - val_loss: 0.6754\n","Epoch 125/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6233 - val_loss: 0.6751\n","Epoch 126/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6279 - val_loss: 0.6748\n","Epoch 127/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6343 - val_loss: 0.6737\n","Epoch 128/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6326 - val_loss: 0.6733\n","Epoch 129/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6249 - val_loss: 0.6726\n","Epoch 130/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6301 - val_loss: 0.6726\n","Epoch 131/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6205 - val_loss: 0.6719\n","Epoch 132/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6263 - val_loss: 0.6715\n","Epoch 133/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6321 - val_loss: 0.6710\n","Epoch 134/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6212 - val_loss: 0.6706\n","Epoch 135/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6296 - val_loss: 0.6698\n","Epoch 136/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6104 - val_loss: 0.6692\n","Epoch 137/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6211 - val_loss: 0.6690\n","Epoch 138/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6236 - val_loss: 0.6685\n","Epoch 139/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6276 - val_loss: 0.6677\n","Epoch 140/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6248 - val_loss: 0.6674\n","Epoch 141/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6203 - val_loss: 0.6668\n","Epoch 142/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6200 - val_loss: 0.6663\n","Epoch 143/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6168 - val_loss: 0.6660\n","Epoch 144/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6267 - val_loss: 0.6659\n","Epoch 145/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6214 - val_loss: 0.6649\n","Epoch 146/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6258 - val_loss: 0.6647\n","Epoch 147/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6112 - val_loss: 0.6642\n","Epoch 148/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6265 - val_loss: 0.6636\n","Epoch 149/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6189 - val_loss: 0.6638\n","Epoch 150/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6128 - val_loss: 0.6629\n","Epoch 151/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6201 - val_loss: 0.6623\n","Epoch 152/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6086 - val_loss: 0.6618\n","Epoch 153/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6178 - val_loss: 0.6615\n","Epoch 154/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5967 - val_loss: 0.6608\n","Epoch 155/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6297 - val_loss: 0.6605\n","Epoch 156/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.6115 - val_loss: 0.6598\n","Epoch 157/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5979 - val_loss: 0.6595\n","Epoch 158/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6199 - val_loss: 0.6592\n","Epoch 159/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5945 - val_loss: 0.6587\n","Epoch 160/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6218 - val_loss: 0.6579\n","Epoch 161/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6180 - val_loss: 0.6577\n","Epoch 162/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6043 - val_loss: 0.6573\n","Epoch 163/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6133 - val_loss: 0.6571\n","Epoch 164/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6151 - val_loss: 0.6561\n","Epoch 165/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6016 - val_loss: 0.6559\n","Epoch 166/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6115 - val_loss: 0.6556\n","Epoch 167/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6210 - val_loss: 0.6550\n","Epoch 168/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5979 - val_loss: 0.6546\n","Epoch 169/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6097 - val_loss: 0.6544\n","Epoch 170/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6053 - val_loss: 0.6539\n","Epoch 171/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6137 - val_loss: 0.6534\n","Epoch 172/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6043 - val_loss: 0.6530\n","Epoch 173/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5965 - val_loss: 0.6525\n","Epoch 174/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6023 - val_loss: 0.6520\n","Epoch 175/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6132 - val_loss: 0.6516\n","Epoch 176/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6153 - val_loss: 0.6516\n","Epoch 177/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6044 - val_loss: 0.6507\n","Epoch 178/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.6070 - val_loss: 0.6502\n","Epoch 179/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6132 - val_loss: 0.6499\n","Epoch 180/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6108 - val_loss: 0.6497\n","Epoch 181/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6000 - val_loss: 0.6491\n","Epoch 182/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6047 - val_loss: 0.6489\n","Epoch 183/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6042 - val_loss: 0.6483\n","Epoch 184/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6005 - val_loss: 0.6479\n","Epoch 185/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6083 - val_loss: 0.6475\n","Epoch 186/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5922 - val_loss: 0.6471\n","Epoch 187/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6024 - val_loss: 0.6462\n","Epoch 188/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6073 - val_loss: 0.6462\n","Epoch 189/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5985 - val_loss: 0.6457\n","Epoch 190/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6064 - val_loss: 0.6452\n","Epoch 191/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6034 - val_loss: 0.6449\n","Epoch 192/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5903 - val_loss: 0.6446\n","Epoch 193/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5986 - val_loss: 0.6442\n","Epoch 194/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5947 - val_loss: 0.6436\n","Epoch 195/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5898 - val_loss: 0.6435\n","Epoch 196/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5989 - val_loss: 0.6429\n","Epoch 197/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5886 - val_loss: 0.6424\n","Epoch 198/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5830 - val_loss: 0.6421\n","Epoch 199/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5893 - val_loss: 0.6417\n","Epoch 200/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5931 - val_loss: 0.6416\n","Epoch 201/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5852 - val_loss: 0.6411\n","Epoch 202/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5955 - val_loss: 0.6410\n","Epoch 203/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5882 - val_loss: 0.6399\n","Epoch 204/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5996 - val_loss: 0.6396\n","Epoch 205/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5859 - val_loss: 0.6397\n","Epoch 206/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5793 - val_loss: 0.6394\n","Epoch 207/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5927 - val_loss: 0.6389\n","Epoch 208/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5953 - val_loss: 0.6384\n","Epoch 209/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5847 - val_loss: 0.6379\n","Epoch 210/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5965 - val_loss: 0.6375\n","Epoch 211/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5919 - val_loss: 0.6368\n","Epoch 212/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5932 - val_loss: 0.6366\n","Epoch 213/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6105 - val_loss: 0.6366\n","Epoch 214/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5828 - val_loss: 0.6362\n","Epoch 215/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5874 - val_loss: 0.6353\n","Epoch 216/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5991 - val_loss: 0.6355\n","Epoch 217/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5813 - val_loss: 0.6350\n","Epoch 218/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6007 - val_loss: 0.6348\n","Epoch 219/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5730 - val_loss: 0.6342\n","Epoch 220/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5864 - val_loss: 0.6339\n","Epoch 221/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5899 - val_loss: 0.6334\n","Epoch 222/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5879 - val_loss: 0.6328\n","Epoch 223/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5857 - val_loss: 0.6326\n","Epoch 224/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5898 - val_loss: 0.6326\n","Epoch 225/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5792 - val_loss: 0.6318\n","Epoch 226/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5843 - val_loss: 0.6317\n","Epoch 227/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5802 - val_loss: 0.6313\n","Epoch 228/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5881 - val_loss: 0.6311\n","Epoch 229/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5735 - val_loss: 0.6306\n","Epoch 230/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5801 - val_loss: 0.6301\n","Epoch 231/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5848 - val_loss: 0.6301\n","Epoch 232/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5740 - val_loss: 0.6296\n","Epoch 233/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5826 - val_loss: 0.6291\n","Epoch 234/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5859 - val_loss: 0.6290\n","Epoch 235/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5858 - val_loss: 0.6285\n","Epoch 236/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5916 - val_loss: 0.6288\n","Epoch 237/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5875 - val_loss: 0.6278\n","Epoch 238/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.6013 - val_loss: 0.6281\n","Epoch 239/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5808 - val_loss: 0.6273\n","Epoch 240/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5773 - val_loss: 0.6268\n","Epoch 241/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5850 - val_loss: 0.6269\n","Epoch 242/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5733 - val_loss: 0.6263\n","Epoch 243/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5829 - val_loss: 0.6262\n","Epoch 244/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5850 - val_loss: 0.6258\n","Epoch 245/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5802 - val_loss: 0.6252\n","Epoch 246/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5738 - val_loss: 0.6253\n","Epoch 247/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5687 - val_loss: 0.6249\n","Epoch 248/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5857 - val_loss: 0.6247\n","Epoch 249/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5863 - val_loss: 0.6247\n","Epoch 250/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5674 - val_loss: 0.6239\n","Epoch 251/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5758 - val_loss: 0.6241\n","Epoch 252/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5748 - val_loss: 0.6236\n","Epoch 253/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5805 - val_loss: 0.6229\n","Epoch 254/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5797 - val_loss: 0.6229\n","Epoch 255/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5814 - val_loss: 0.6225\n","Epoch 256/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5978 - val_loss: 0.6224\n","Epoch 257/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5728 - val_loss: 0.6224\n","Epoch 258/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5521 - val_loss: 0.6216\n","Epoch 259/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5860 - val_loss: 0.6212\n","Epoch 260/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5669 - val_loss: 0.6211\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fac46d52a50>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"TRsCwTreHdAh"},"source":["<h3> Training GRU for another 260 epochs </h3>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYjmU0-d7tW_","executionInfo":{"status":"ok","timestamp":1616215434352,"user_tz":-330,"elapsed":230365,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"95a37281-0bf5-4e2c-ced1-413ea2e66c21"},"source":["#model with 1% validation data with Adam optimizer.\n","optimizer = tf.keras.optimizers.Adam(0.0001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data],decoder_output_data,validation_data=([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data),batch_size=64,epochs=260,callbacks=[rl])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/260\n","31/31 [==============================] - 4s 51ms/step - loss: 0.5780 - val_loss: 0.6210\n","Epoch 2/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5724 - val_loss: 0.6205\n","Epoch 3/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5736 - val_loss: 0.6201\n","Epoch 4/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5709 - val_loss: 0.6199\n","Epoch 5/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5774 - val_loss: 0.6197\n","Epoch 6/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5801 - val_loss: 0.6191\n","Epoch 7/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5639 - val_loss: 0.6193\n","Epoch 8/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5731 - val_loss: 0.6187\n","Epoch 9/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5725 - val_loss: 0.6185\n","Epoch 10/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5594 - val_loss: 0.6183\n","Epoch 11/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5700 - val_loss: 0.6178\n","Epoch 12/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5667 - val_loss: 0.6177\n","Epoch 13/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5723 - val_loss: 0.6172\n","Epoch 14/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5736 - val_loss: 0.6171\n","Epoch 15/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5685 - val_loss: 0.6169\n","Epoch 16/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5615 - val_loss: 0.6164\n","Epoch 17/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5681 - val_loss: 0.6163\n","Epoch 18/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5707 - val_loss: 0.6162\n","Epoch 19/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5858 - val_loss: 0.6159\n","Epoch 20/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5758 - val_loss: 0.6157\n","Epoch 21/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5771 - val_loss: 0.6150\n","Epoch 22/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5531 - val_loss: 0.6149\n","Epoch 23/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5670 - val_loss: 0.6144\n","Epoch 24/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5668 - val_loss: 0.6141\n","Epoch 25/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5622 - val_loss: 0.6141\n","Epoch 26/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5629 - val_loss: 0.6137\n","Epoch 27/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5568 - val_loss: 0.6136\n","Epoch 28/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5701 - val_loss: 0.6133\n","Epoch 29/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5716 - val_loss: 0.6131\n","Epoch 30/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5739 - val_loss: 0.6128\n","Epoch 31/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5648 - val_loss: 0.6126\n","Epoch 32/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5590 - val_loss: 0.6121\n","Epoch 33/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5756 - val_loss: 0.6121\n","Epoch 34/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5663 - val_loss: 0.6118\n","Epoch 35/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5695 - val_loss: 0.6113\n","Epoch 36/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5598 - val_loss: 0.6111\n","Epoch 37/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5555 - val_loss: 0.6110\n","Epoch 38/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5654 - val_loss: 0.6107\n","Epoch 39/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5522 - val_loss: 0.6105\n","Epoch 40/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5676 - val_loss: 0.6101\n","Epoch 41/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5619 - val_loss: 0.6098\n","Epoch 42/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5627 - val_loss: 0.6092\n","Epoch 43/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5662 - val_loss: 0.6093\n","Epoch 44/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5564 - val_loss: 0.6090\n","Epoch 45/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5694 - val_loss: 0.6090\n","Epoch 46/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5768 - val_loss: 0.6087\n","Epoch 47/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5669 - val_loss: 0.6085\n","Epoch 48/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5654 - val_loss: 0.6079\n","Epoch 49/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5704 - val_loss: 0.6078\n","Epoch 50/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5636 - val_loss: 0.6077\n","Epoch 51/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5562 - val_loss: 0.6076\n","Epoch 52/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5604 - val_loss: 0.6070\n","Epoch 53/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5619 - val_loss: 0.6069\n","Epoch 54/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5682 - val_loss: 0.6066\n","Epoch 55/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5676 - val_loss: 0.6063\n","Epoch 56/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5530 - val_loss: 0.6059\n","Epoch 57/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5680 - val_loss: 0.6059\n","Epoch 58/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5667 - val_loss: 0.6055\n","Epoch 59/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5614 - val_loss: 0.6056\n","Epoch 60/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5591 - val_loss: 0.6053\n","Epoch 61/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5602 - val_loss: 0.6047\n","Epoch 62/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5535 - val_loss: 0.6049\n","Epoch 63/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5493 - val_loss: 0.6046\n","Epoch 64/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5578 - val_loss: 0.6043\n","Epoch 65/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5700 - val_loss: 0.6041\n","Epoch 66/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5452 - val_loss: 0.6035\n","Epoch 67/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5554 - val_loss: 0.6035\n","Epoch 68/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5635 - val_loss: 0.6035\n","Epoch 69/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5611 - val_loss: 0.6034\n","Epoch 70/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5546 - val_loss: 0.6030\n","Epoch 71/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5581 - val_loss: 0.6028\n","Epoch 72/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5553 - val_loss: 0.6022\n","Epoch 73/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5463 - val_loss: 0.6022\n","Epoch 74/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5487 - val_loss: 0.6018\n","Epoch 75/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5480 - val_loss: 0.6015\n","Epoch 76/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5480 - val_loss: 0.6012\n","Epoch 77/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5602 - val_loss: 0.6016\n","Epoch 78/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5482 - val_loss: 0.6013\n","Epoch 79/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5572 - val_loss: 0.6012\n","Epoch 80/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5641 - val_loss: 0.6009\n","Epoch 81/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5536 - val_loss: 0.6006\n","Epoch 82/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5452 - val_loss: 0.6003\n","Epoch 83/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5459 - val_loss: 0.6003\n","Epoch 84/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5543 - val_loss: 0.5999\n","Epoch 85/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5430 - val_loss: 0.6000\n","Epoch 86/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5330 - val_loss: 0.5991\n","Epoch 87/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5546 - val_loss: 0.5995\n","Epoch 88/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5471 - val_loss: 0.5988\n","Epoch 89/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5350 - val_loss: 0.5989\n","Epoch 90/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5442 - val_loss: 0.5990\n","Epoch 91/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5454 - val_loss: 0.5982\n","Epoch 92/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5503 - val_loss: 0.5981\n","Epoch 93/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5502 - val_loss: 0.5982\n","Epoch 94/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5670 - val_loss: 0.5977\n","Epoch 95/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5473 - val_loss: 0.5977\n","Epoch 96/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5437 - val_loss: 0.5973\n","Epoch 97/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5477 - val_loss: 0.5970\n","Epoch 98/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5328 - val_loss: 0.5970\n","Epoch 99/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5507 - val_loss: 0.5970\n","Epoch 100/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5370 - val_loss: 0.5967\n","Epoch 101/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5534 - val_loss: 0.5965\n","Epoch 102/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5523 - val_loss: 0.5963\n","Epoch 103/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5450 - val_loss: 0.5960\n","Epoch 104/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5478 - val_loss: 0.5957\n","Epoch 105/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5538 - val_loss: 0.5958\n","Epoch 106/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5633 - val_loss: 0.5960\n","Epoch 107/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5424 - val_loss: 0.5952\n","Epoch 108/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5474 - val_loss: 0.5953\n","Epoch 109/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5495 - val_loss: 0.5948\n","Epoch 110/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5473 - val_loss: 0.5947\n","Epoch 111/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5494 - val_loss: 0.5948\n","Epoch 112/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5409 - val_loss: 0.5944\n","Epoch 113/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5416 - val_loss: 0.5944\n","Epoch 114/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5421 - val_loss: 0.5939\n","Epoch 115/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5547 - val_loss: 0.5938\n","Epoch 116/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5426 - val_loss: 0.5936\n","Epoch 117/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5279 - val_loss: 0.5933\n","Epoch 118/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5415 - val_loss: 0.5937\n","Epoch 119/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5476 - val_loss: 0.5933\n","Epoch 120/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5426 - val_loss: 0.5929\n","Epoch 121/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5438 - val_loss: 0.5925\n","Epoch 122/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5411 - val_loss: 0.5926\n","Epoch 123/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5526 - val_loss: 0.5923\n","Epoch 124/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5531 - val_loss: 0.5921\n","Epoch 125/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5459 - val_loss: 0.5918\n","Epoch 126/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5476 - val_loss: 0.5921\n","Epoch 127/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5498 - val_loss: 0.5918\n","Epoch 128/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5376 - val_loss: 0.5919\n","Epoch 129/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5263 - val_loss: 0.5915\n","Epoch 130/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5514 - val_loss: 0.5914\n","Epoch 131/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5345 - val_loss: 0.5911\n","Epoch 132/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5335 - val_loss: 0.5908\n","Epoch 133/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5421 - val_loss: 0.5909\n","Epoch 134/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5419 - val_loss: 0.5907\n","Epoch 135/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5415 - val_loss: 0.5907\n","Epoch 136/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5500 - val_loss: 0.5904\n","Epoch 137/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5414 - val_loss: 0.5902\n","Epoch 138/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5313 - val_loss: 0.5901\n","Epoch 139/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5224 - val_loss: 0.5895\n","Epoch 140/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5431 - val_loss: 0.5894\n","Epoch 141/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5443 - val_loss: 0.5894\n","Epoch 142/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5397 - val_loss: 0.5895\n","Epoch 143/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5378 - val_loss: 0.5892\n","Epoch 144/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5371 - val_loss: 0.5898\n","Epoch 145/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5263 - val_loss: 0.5887\n","Epoch 146/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5470 - val_loss: 0.5888\n","Epoch 147/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5416 - val_loss: 0.5887\n","Epoch 148/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5435 - val_loss: 0.5883\n","Epoch 149/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5411 - val_loss: 0.5881\n","Epoch 150/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5353 - val_loss: 0.5882\n","Epoch 151/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5481 - val_loss: 0.5880\n","Epoch 152/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5255 - val_loss: 0.5878\n","Epoch 153/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5441 - val_loss: 0.5876\n","Epoch 154/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5307 - val_loss: 0.5871\n","Epoch 155/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5389 - val_loss: 0.5877\n","Epoch 156/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5309 - val_loss: 0.5876\n","Epoch 157/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5363 - val_loss: 0.5872\n","Epoch 158/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5460 - val_loss: 0.5868\n","Epoch 159/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5273 - val_loss: 0.5868\n","Epoch 160/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5335 - val_loss: 0.5865\n","Epoch 161/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5279 - val_loss: 0.5862\n","Epoch 162/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5406 - val_loss: 0.5862\n","Epoch 163/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5351 - val_loss: 0.5859\n","Epoch 164/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5354 - val_loss: 0.5861\n","Epoch 165/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5438 - val_loss: 0.5859\n","Epoch 166/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5436 - val_loss: 0.5859\n","Epoch 167/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5327 - val_loss: 0.5858\n","Epoch 168/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5320 - val_loss: 0.5853\n","Epoch 169/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5366 - val_loss: 0.5855\n","Epoch 170/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5267 - val_loss: 0.5853\n","Epoch 171/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5319 - val_loss: 0.5851\n","Epoch 172/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5221 - val_loss: 0.5850\n","Epoch 173/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5357 - val_loss: 0.5849\n","Epoch 174/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5337 - val_loss: 0.5852\n","Epoch 175/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5199 - val_loss: 0.5843\n","Epoch 176/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5293 - val_loss: 0.5844\n","Epoch 177/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5231 - val_loss: 0.5843\n","Epoch 178/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5326 - val_loss: 0.5843\n","Epoch 179/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5231 - val_loss: 0.5839\n","Epoch 180/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5362 - val_loss: 0.5838\n","Epoch 181/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5199 - val_loss: 0.5839\n","Epoch 182/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5340 - val_loss: 0.5836\n","Epoch 183/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5276 - val_loss: 0.5836\n","Epoch 184/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5358 - val_loss: 0.5835\n","Epoch 185/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5296 - val_loss: 0.5832\n","Epoch 186/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5310 - val_loss: 0.5831\n","Epoch 187/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5241 - val_loss: 0.5827\n","Epoch 188/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5290 - val_loss: 0.5831\n","Epoch 189/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5411 - val_loss: 0.5830\n","Epoch 190/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5235 - val_loss: 0.5829\n","Epoch 191/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5394 - val_loss: 0.5825\n","Epoch 192/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5306 - val_loss: 0.5822\n","Epoch 193/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5240 - val_loss: 0.5823\n","Epoch 194/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5256 - val_loss: 0.5820\n","Epoch 195/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5149 - val_loss: 0.5822\n","Epoch 196/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5294 - val_loss: 0.5826\n","Epoch 197/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5269 - val_loss: 0.5820\n","Epoch 198/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5306 - val_loss: 0.5816\n","Epoch 199/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5186 - val_loss: 0.5813\n","Epoch 200/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5365 - val_loss: 0.5812\n","Epoch 201/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5223 - val_loss: 0.5814\n","Epoch 202/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5256 - val_loss: 0.5812\n","Epoch 203/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5353 - val_loss: 0.5812\n","Epoch 204/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5258 - val_loss: 0.5811\n","Epoch 205/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5226 - val_loss: 0.5811\n","Epoch 206/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5246 - val_loss: 0.5809\n","Epoch 207/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5348 - val_loss: 0.5808\n","Epoch 208/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5344 - val_loss: 0.5805\n","Epoch 209/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5344 - val_loss: 0.5806\n","Epoch 210/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5227 - val_loss: 0.5803\n","Epoch 211/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5469 - val_loss: 0.5806\n","Epoch 212/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5335 - val_loss: 0.5804\n","Epoch 213/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5225 - val_loss: 0.5797\n","Epoch 214/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5155 - val_loss: 0.5801\n","Epoch 215/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5257 - val_loss: 0.5799\n","Epoch 216/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5145 - val_loss: 0.5800\n","Epoch 217/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5249 - val_loss: 0.5794\n","Epoch 218/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5233 - val_loss: 0.5796\n","Epoch 219/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5285 - val_loss: 0.5791\n","Epoch 220/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5189 - val_loss: 0.5796\n","Epoch 221/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5342 - val_loss: 0.5792\n","Epoch 222/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5179 - val_loss: 0.5790\n","Epoch 223/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5293 - val_loss: 0.5789\n","Epoch 224/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5231 - val_loss: 0.5787\n","Epoch 225/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5217 - val_loss: 0.5788\n","Epoch 226/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5183 - val_loss: 0.5785\n","Epoch 227/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5238 - val_loss: 0.5789\n","Epoch 228/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5250 - val_loss: 0.5784\n","Epoch 229/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5139 - val_loss: 0.5784\n","Epoch 230/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5203 - val_loss: 0.5782\n","Epoch 231/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5258 - val_loss: 0.5779\n","Epoch 232/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5108 - val_loss: 0.5783\n","Epoch 233/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5275 - val_loss: 0.5778\n","Epoch 234/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5158 - val_loss: 0.5778\n","Epoch 235/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5251 - val_loss: 0.5776\n","Epoch 236/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5151 - val_loss: 0.5780\n","Epoch 237/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5178 - val_loss: 0.5779\n","Epoch 238/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5165 - val_loss: 0.5774\n","Epoch 239/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5289 - val_loss: 0.5774\n","Epoch 240/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5148 - val_loss: 0.5773\n","Epoch 241/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5250 - val_loss: 0.5773\n","Epoch 242/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5193 - val_loss: 0.5771\n","Epoch 243/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5180 - val_loss: 0.5771\n","Epoch 244/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5054 - val_loss: 0.5772\n","Epoch 245/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5137 - val_loss: 0.5769\n","Epoch 246/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5196 - val_loss: 0.5767\n","Epoch 247/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5168 - val_loss: 0.5768\n","Epoch 248/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5201 - val_loss: 0.5766\n","Epoch 249/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5257 - val_loss: 0.5767\n","Epoch 250/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5235 - val_loss: 0.5767\n","Epoch 251/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5262 - val_loss: 0.5763\n","Epoch 252/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5232 - val_loss: 0.5763\n","Epoch 253/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5065 - val_loss: 0.5760\n","Epoch 254/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5214 - val_loss: 0.5762\n","Epoch 255/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4998 - val_loss: 0.5758\n","Epoch 256/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5082 - val_loss: 0.5761\n","Epoch 257/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5190 - val_loss: 0.5760\n","Epoch 258/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5133 - val_loss: 0.5756\n","Epoch 259/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5167 - val_loss: 0.5756\n","Epoch 260/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5021 - val_loss: 0.5756\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fac26527210>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"qbuxAw_4Hip4"},"source":["<h3> Training GRU for another 260 epochs </h3>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ViTMoV6P8ouj","executionInfo":{"status":"ok","timestamp":1616215676269,"user_tz":-330,"elapsed":229562,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"3453bd14-f00f-47c6-b5bf-4268c01c37e6"},"source":["#model with 1% validation data with Adam optimizer.\n","optimizer = tf.keras.optimizers.Adam(0.0001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data],decoder_output_data,validation_data=([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data),batch_size=64,epochs=260,callbacks=[rl])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/260\n","31/31 [==============================] - 4s 51ms/step - loss: 0.5137 - val_loss: 0.5757\n","Epoch 2/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5316 - val_loss: 0.5757\n","Epoch 3/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5176 - val_loss: 0.5756\n","Epoch 4/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5201 - val_loss: 0.5755\n","Epoch 5/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5186 - val_loss: 0.5753\n","Epoch 6/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5114 - val_loss: 0.5749\n","Epoch 7/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5101 - val_loss: 0.5752\n","Epoch 8/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5187 - val_loss: 0.5747\n","Epoch 9/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5183 - val_loss: 0.5749\n","Epoch 10/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5106 - val_loss: 0.5749\n","Epoch 11/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5077 - val_loss: 0.5749\n","Epoch 12/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5293 - val_loss: 0.5750\n","Epoch 13/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5270 - val_loss: 0.5749\n","Epoch 14/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5086 - val_loss: 0.5747\n","Epoch 15/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5163 - val_loss: 0.5745\n","Epoch 16/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5141 - val_loss: 0.5742\n","Epoch 17/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5122 - val_loss: 0.5743\n","Epoch 18/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5086 - val_loss: 0.5740\n","Epoch 19/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5066 - val_loss: 0.5744\n","Epoch 20/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5177 - val_loss: 0.5738\n","Epoch 21/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5105 - val_loss: 0.5740\n","Epoch 22/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5121 - val_loss: 0.5734\n","Epoch 23/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5089 - val_loss: 0.5740\n","Epoch 24/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5113 - val_loss: 0.5737\n","Epoch 25/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5013 - val_loss: 0.5736\n","Epoch 26/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5065 - val_loss: 0.5735\n","Epoch 27/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5100 - val_loss: 0.5735\n","Epoch 28/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5069 - val_loss: 0.5737\n","Epoch 29/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5109 - val_loss: 0.5733\n","Epoch 30/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5084 - val_loss: 0.5730\n","Epoch 31/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5147 - val_loss: 0.5733\n","Epoch 32/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5228 - val_loss: 0.5733\n","Epoch 33/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5151 - val_loss: 0.5734\n","Epoch 34/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5121 - val_loss: 0.5732\n","Epoch 35/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5129 - val_loss: 0.5727\n","Epoch 36/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5076 - val_loss: 0.5729\n","Epoch 37/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5078 - val_loss: 0.5729\n","Epoch 38/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5219 - val_loss: 0.5727\n","Epoch 39/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5221 - val_loss: 0.5727\n","Epoch 40/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5149 - val_loss: 0.5725\n","Epoch 41/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5003 - val_loss: 0.5730\n","Epoch 42/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5073 - val_loss: 0.5723\n","Epoch 43/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5201 - val_loss: 0.5723\n","Epoch 44/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5142 - val_loss: 0.5725\n","Epoch 45/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5154 - val_loss: 0.5719\n","Epoch 46/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5089 - val_loss: 0.5721\n","Epoch 47/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5155 - val_loss: 0.5726\n","Epoch 48/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5074 - val_loss: 0.5720\n","Epoch 49/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5050 - val_loss: 0.5722\n","Epoch 50/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5089 - val_loss: 0.5717\n","Epoch 51/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5112 - val_loss: 0.5719\n","Epoch 52/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5109 - val_loss: 0.5719\n","Epoch 53/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5134 - val_loss: 0.5719\n","Epoch 54/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5171 - val_loss: 0.5726\n","Epoch 55/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5197 - val_loss: 0.5716\n","Epoch 56/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5011 - val_loss: 0.5723\n","Epoch 57/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5117 - val_loss: 0.5713\n","Epoch 58/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4994 - val_loss: 0.5714\n","Epoch 59/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5201 - val_loss: 0.5715\n","Epoch 60/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4954 - val_loss: 0.5711\n","Epoch 61/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5044 - val_loss: 0.5712\n","Epoch 62/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5005 - val_loss: 0.5709\n","Epoch 63/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5027 - val_loss: 0.5709\n","Epoch 64/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5160 - val_loss: 0.5711\n","Epoch 65/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5039 - val_loss: 0.5710\n","Epoch 66/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5038 - val_loss: 0.5712\n","Epoch 67/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4955 - val_loss: 0.5709\n","Epoch 68/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5085 - val_loss: 0.5711\n","Epoch 69/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5272 - val_loss: 0.5706\n","Epoch 70/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5158 - val_loss: 0.5707\n","Epoch 71/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5103 - val_loss: 0.5709\n","Epoch 72/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4972 - val_loss: 0.5709\n","Epoch 73/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5042 - val_loss: 0.5706\n","Epoch 74/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5122 - val_loss: 0.5711\n","Epoch 75/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5030 - val_loss: 0.5706\n","Epoch 76/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5029 - val_loss: 0.5707\n","Epoch 77/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5109 - val_loss: 0.5706\n","Epoch 78/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4951 - val_loss: 0.5708\n","Epoch 79/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5109 - val_loss: 0.5707\n","\n","Epoch 00079: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n","Epoch 80/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5093 - val_loss: 0.5700\n","Epoch 81/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5018 - val_loss: 0.5699\n","Epoch 82/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5002 - val_loss: 0.5701\n","Epoch 83/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5105 - val_loss: 0.5704\n","Epoch 84/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5047 - val_loss: 0.5702\n","Epoch 85/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5085 - val_loss: 0.5703\n","Epoch 86/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5094 - val_loss: 0.5699\n","Epoch 87/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5027 - val_loss: 0.5697\n","Epoch 88/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4972 - val_loss: 0.5699\n","Epoch 89/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4978 - val_loss: 0.5694\n","Epoch 90/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5031 - val_loss: 0.5695\n","Epoch 91/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5006 - val_loss: 0.5703\n","Epoch 92/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5014 - val_loss: 0.5695\n","Epoch 93/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4909 - val_loss: 0.5701\n","Epoch 94/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4975 - val_loss: 0.5698\n","Epoch 95/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5029 - val_loss: 0.5702\n","Epoch 96/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5063 - val_loss: 0.5699\n","Epoch 97/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4998 - val_loss: 0.5693\n","Epoch 98/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4938 - val_loss: 0.5695\n","Epoch 99/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5032 - val_loss: 0.5693\n","Epoch 100/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5023 - val_loss: 0.5695\n","Epoch 101/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5046 - val_loss: 0.5694\n","Epoch 102/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5028 - val_loss: 0.5695\n","Epoch 103/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4918 - val_loss: 0.5693\n","Epoch 104/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5001 - val_loss: 0.5690\n","Epoch 105/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5064 - val_loss: 0.5691\n","Epoch 106/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5055 - val_loss: 0.5689\n","Epoch 107/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5041 - val_loss: 0.5701\n","Epoch 108/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4965 - val_loss: 0.5690\n","Epoch 109/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4985 - val_loss: 0.5691\n","Epoch 110/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5054 - val_loss: 0.5698\n","Epoch 111/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5003 - val_loss: 0.5689\n","Epoch 112/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4938 - val_loss: 0.5688\n","Epoch 113/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4897 - val_loss: 0.5687\n","Epoch 114/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4993 - val_loss: 0.5690\n","Epoch 115/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4994 - val_loss: 0.5691\n","Epoch 116/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5092 - val_loss: 0.5686\n","Epoch 117/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5062 - val_loss: 0.5688\n","Epoch 118/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5017 - val_loss: 0.5691\n","Epoch 119/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4937 - val_loss: 0.5691\n","Epoch 120/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4976 - val_loss: 0.5689\n","Epoch 121/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5117 - val_loss: 0.5686\n","Epoch 122/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5079 - val_loss: 0.5685\n","Epoch 123/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4955 - val_loss: 0.5684\n","Epoch 124/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4930 - val_loss: 0.5682\n","Epoch 125/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4941 - val_loss: 0.5693\n","Epoch 126/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4975 - val_loss: 0.5682\n","Epoch 127/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5026 - val_loss: 0.5685\n","Epoch 128/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5053 - val_loss: 0.5685\n","Epoch 129/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5007 - val_loss: 0.5683\n","Epoch 130/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4979 - val_loss: 0.5678\n","Epoch 131/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4897 - val_loss: 0.5681\n","Epoch 132/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4914 - val_loss: 0.5680\n","Epoch 133/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4986 - val_loss: 0.5684\n","Epoch 134/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4942 - val_loss: 0.5682\n","Epoch 135/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4992 - val_loss: 0.5686\n","Epoch 136/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4951 - val_loss: 0.5680\n","Epoch 137/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4939 - val_loss: 0.5679\n","Epoch 138/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5116 - val_loss: 0.5680\n","Epoch 139/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4967 - val_loss: 0.5682\n","Epoch 140/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4976 - val_loss: 0.5683\n","\n","Epoch 00140: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n","Epoch 141/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4859 - val_loss: 0.5679\n","Epoch 142/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4907 - val_loss: 0.5681\n","Epoch 143/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5096 - val_loss: 0.5683\n","Epoch 144/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4935 - val_loss: 0.5678\n","Epoch 145/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4922 - val_loss: 0.5678\n","Epoch 146/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5030 - val_loss: 0.5679\n","Epoch 147/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4890 - val_loss: 0.5678\n","Epoch 148/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4979 - val_loss: 0.5681\n","Epoch 149/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5028 - val_loss: 0.5677\n","Epoch 150/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4975 - val_loss: 0.5680\n","\n","Epoch 00150: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n","Epoch 151/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4923 - val_loss: 0.5679\n","Epoch 152/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4947 - val_loss: 0.5677\n","Epoch 153/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4980 - val_loss: 0.5678\n","Epoch 154/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4975 - val_loss: 0.5679\n","Epoch 155/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4997 - val_loss: 0.5675\n","Epoch 156/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4926 - val_loss: 0.5676\n","Epoch 157/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4972 - val_loss: 0.5676\n","Epoch 158/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4950 - val_loss: 0.5676\n","Epoch 159/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4947 - val_loss: 0.5676\n","Epoch 160/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4968 - val_loss: 0.5679\n","Epoch 161/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4990 - val_loss: 0.5673\n","Epoch 162/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5011 - val_loss: 0.5675\n","Epoch 163/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4893 - val_loss: 0.5675\n","Epoch 164/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4872 - val_loss: 0.5677\n","Epoch 165/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4944 - val_loss: 0.5676\n","Epoch 166/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5069 - val_loss: 0.5680\n","Epoch 167/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4856 - val_loss: 0.5674\n","Epoch 168/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4973 - val_loss: 0.5676\n","Epoch 169/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4975 - val_loss: 0.5675\n","Epoch 170/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4989 - val_loss: 0.5674\n","Epoch 171/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4837 - val_loss: 0.5675\n","\n","Epoch 00171: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n","Epoch 172/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4918 - val_loss: 0.5675\n","Epoch 173/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4860 - val_loss: 0.5674\n","Epoch 174/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4933 - val_loss: 0.5674\n","Epoch 175/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4857 - val_loss: 0.5672\n","Epoch 176/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.5033 - val_loss: 0.5676\n","Epoch 177/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4849 - val_loss: 0.5673\n","Epoch 178/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4875 - val_loss: 0.5673\n","Epoch 179/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4947 - val_loss: 0.5675\n","Epoch 180/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5019 - val_loss: 0.5674\n","Epoch 181/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4860 - val_loss: 0.5672\n","Epoch 182/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4973 - val_loss: 0.5672\n","Epoch 183/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4904 - val_loss: 0.5672\n","Epoch 184/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5014 - val_loss: 0.5669\n","Epoch 185/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5075 - val_loss: 0.5672\n","Epoch 186/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5007 - val_loss: 0.5673\n","Epoch 187/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5004 - val_loss: 0.5672\n","Epoch 188/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4853 - val_loss: 0.5672\n","Epoch 189/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4798 - val_loss: 0.5673\n","Epoch 190/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4957 - val_loss: 0.5673\n","Epoch 191/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4936 - val_loss: 0.5669\n","Epoch 192/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4819 - val_loss: 0.5670\n","Epoch 193/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4802 - val_loss: 0.5672\n","Epoch 194/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5025 - val_loss: 0.5671\n","\n","Epoch 00194: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n","Epoch 195/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5001 - val_loss: 0.5672\n","Epoch 196/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4848 - val_loss: 0.5671\n","Epoch 197/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4854 - val_loss: 0.5669\n","Epoch 198/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4888 - val_loss: 0.5669\n","Epoch 199/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5014 - val_loss: 0.5672\n","Epoch 200/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4936 - val_loss: 0.5670\n","Epoch 201/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4953 - val_loss: 0.5673\n","Epoch 202/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4966 - val_loss: 0.5670\n","Epoch 203/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4893 - val_loss: 0.5669\n","Epoch 204/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4942 - val_loss: 0.5671\n","\n","Epoch 00204: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n","Epoch 205/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4817 - val_loss: 0.5671\n","Epoch 206/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4923 - val_loss: 0.5670\n","Epoch 207/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4918 - val_loss: 0.5670\n","Epoch 208/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5003 - val_loss: 0.5669\n","Epoch 209/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4957 - val_loss: 0.5669\n","Epoch 210/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4856 - val_loss: 0.5671\n","Epoch 211/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4793 - val_loss: 0.5667\n","Epoch 212/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4873 - val_loss: 0.5668\n","Epoch 213/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4924 - val_loss: 0.5669\n","Epoch 214/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4917 - val_loss: 0.5669\n","Epoch 215/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4790 - val_loss: 0.5670\n","Epoch 216/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5029 - val_loss: 0.5670\n","Epoch 217/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4782 - val_loss: 0.5669\n","Epoch 218/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4968 - val_loss: 0.5668\n","Epoch 219/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4937 - val_loss: 0.5669\n","Epoch 220/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4974 - val_loss: 0.5669\n","Epoch 221/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4910 - val_loss: 0.5669\n","\n","Epoch 00221: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n","Epoch 222/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5065 - val_loss: 0.5669\n","Epoch 223/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4914 - val_loss: 0.5667\n","Epoch 224/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4894 - val_loss: 0.5669\n","Epoch 225/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4908 - val_loss: 0.5669\n","Epoch 226/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4984 - val_loss: 0.5668\n","Epoch 227/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4902 - val_loss: 0.5667\n","Epoch 228/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5025 - val_loss: 0.5670\n","Epoch 229/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4875 - val_loss: 0.5668\n","Epoch 230/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4840 - val_loss: 0.5668\n","Epoch 231/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4907 - val_loss: 0.5668\n","\n","Epoch 00231: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n","Epoch 232/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4871 - val_loss: 0.5669\n","Epoch 233/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4804 - val_loss: 0.5667\n","Epoch 234/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4924 - val_loss: 0.5668\n","Epoch 235/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4940 - val_loss: 0.5669\n","Epoch 236/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4914 - val_loss: 0.5667\n","Epoch 237/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4888 - val_loss: 0.5667\n","Epoch 238/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4886 - val_loss: 0.5669\n","Epoch 239/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4897 - val_loss: 0.5670\n","Epoch 240/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4875 - val_loss: 0.5668\n","Epoch 241/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4832 - val_loss: 0.5669\n","\n","Epoch 00241: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n","Epoch 242/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4936 - val_loss: 0.5667\n","Epoch 243/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4857 - val_loss: 0.5667\n","Epoch 244/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4962 - val_loss: 0.5670\n","Epoch 245/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4929 - val_loss: 0.5669\n","Epoch 246/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4807 - val_loss: 0.5666\n","Epoch 247/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5015 - val_loss: 0.5668\n","Epoch 248/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4876 - val_loss: 0.5668\n","Epoch 249/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4828 - val_loss: 0.5666\n","Epoch 250/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4856 - val_loss: 0.5668\n","Epoch 251/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4880 - val_loss: 0.5667\n","Epoch 252/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4902 - val_loss: 0.5667\n","Epoch 253/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4938 - val_loss: 0.5667\n","Epoch 254/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4920 - val_loss: 0.5667\n","Epoch 255/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4905 - val_loss: 0.5669\n","Epoch 256/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.5053 - val_loss: 0.5667\n","Epoch 257/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4864 - val_loss: 0.5667\n","Epoch 258/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4891 - val_loss: 0.5667\n","Epoch 259/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4890 - val_loss: 0.5668\n","\n","Epoch 00259: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n","Epoch 260/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4948 - val_loss: 0.5667\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fabd61d41d0>"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"6cd9v4ulHoIL"},"source":["<h3> Training GRU for another 260 epochs </h3>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VIryseeI_BeI","executionInfo":{"status":"ok","timestamp":1616216306127,"user_tz":-330,"elapsed":231605,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"10f59243-b5b4-44e4-be25-25ebf1f557e1"},"source":["#model with 1% validation data with Adam optimizer.\n","optimizer = tf.keras.optimizers.Adam(0.0001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data],decoder_output_data,validation_data=([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data),batch_size=64,epochs=260,callbacks=[rl])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/260\n","31/31 [==============================] - 5s 51ms/step - loss: 0.4891 - val_loss: 0.5665\n","Epoch 2/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4928 - val_loss: 0.5665\n","Epoch 3/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4927 - val_loss: 0.5669\n","Epoch 4/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4864 - val_loss: 0.5665\n","Epoch 5/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4859 - val_loss: 0.5663\n","Epoch 6/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4879 - val_loss: 0.5662\n","Epoch 7/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4956 - val_loss: 0.5661\n","Epoch 8/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4926 - val_loss: 0.5655\n","Epoch 9/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4951 - val_loss: 0.5661\n","Epoch 10/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4919 - val_loss: 0.5661\n","Epoch 11/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4934 - val_loss: 0.5667\n","Epoch 12/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5006 - val_loss: 0.5665\n","Epoch 13/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4874 - val_loss: 0.5660\n","Epoch 14/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4780 - val_loss: 0.5662\n","Epoch 15/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4913 - val_loss: 0.5661\n","Epoch 16/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4958 - val_loss: 0.5663\n","Epoch 17/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4886 - val_loss: 0.5665\n","Epoch 18/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4838 - val_loss: 0.5663\n","\n","Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n","Epoch 19/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4824 - val_loss: 0.5662\n","Epoch 20/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4876 - val_loss: 0.5662\n","Epoch 21/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4920 - val_loss: 0.5658\n","Epoch 22/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4934 - val_loss: 0.5663\n","Epoch 23/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4887 - val_loss: 0.5658\n","Epoch 24/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4928 - val_loss: 0.5658\n","Epoch 25/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4813 - val_loss: 0.5659\n","Epoch 26/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4922 - val_loss: 0.5657\n","Epoch 27/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4797 - val_loss: 0.5660\n","Epoch 28/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4892 - val_loss: 0.5654\n","Epoch 29/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4996 - val_loss: 0.5658\n","Epoch 30/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4886 - val_loss: 0.5661\n","Epoch 31/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4790 - val_loss: 0.5656\n","Epoch 32/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4739 - val_loss: 0.5659\n","Epoch 33/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4885 - val_loss: 0.5659\n","Epoch 34/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4908 - val_loss: 0.5660\n","Epoch 35/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4927 - val_loss: 0.5658\n","Epoch 36/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4964 - val_loss: 0.5658\n","Epoch 37/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4938 - val_loss: 0.5654\n","Epoch 38/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4788 - val_loss: 0.5658\n","\n","Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n","Epoch 39/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4838 - val_loss: 0.5658\n","Epoch 40/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4909 - val_loss: 0.5656\n","Epoch 41/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4873 - val_loss: 0.5656\n","Epoch 42/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4813 - val_loss: 0.5658\n","Epoch 43/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4909 - val_loss: 0.5655\n","Epoch 44/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4974 - val_loss: 0.5657\n","Epoch 45/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4914 - val_loss: 0.5656\n","Epoch 46/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4870 - val_loss: 0.5657\n","Epoch 47/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4847 - val_loss: 0.5656\n","Epoch 48/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4860 - val_loss: 0.5657\n","\n","Epoch 00048: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n","Epoch 49/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4933 - val_loss: 0.5656\n","Epoch 50/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4920 - val_loss: 0.5656\n","Epoch 51/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4687 - val_loss: 0.5654\n","Epoch 52/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4811 - val_loss: 0.5656\n","Epoch 53/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4835 - val_loss: 0.5658\n","Epoch 54/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4821 - val_loss: 0.5654\n","Epoch 55/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4774 - val_loss: 0.5657\n","Epoch 56/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4963 - val_loss: 0.5655\n","Epoch 57/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4802 - val_loss: 0.5654\n","Epoch 58/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4809 - val_loss: 0.5657\n","\n","Epoch 00058: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n","Epoch 59/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4847 - val_loss: 0.5653\n","Epoch 60/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4806 - val_loss: 0.5652\n","Epoch 61/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4857 - val_loss: 0.5655\n","Epoch 62/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4915 - val_loss: 0.5653\n","Epoch 63/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4825 - val_loss: 0.5654\n","Epoch 64/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4801 - val_loss: 0.5655\n","Epoch 65/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4745 - val_loss: 0.5654\n","Epoch 66/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4865 - val_loss: 0.5654\n","Epoch 67/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4780 - val_loss: 0.5657\n","Epoch 68/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4891 - val_loss: 0.5652\n","Epoch 69/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4924 - val_loss: 0.5654\n","\n","Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n","Epoch 70/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4814 - val_loss: 0.5652\n","Epoch 71/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4908 - val_loss: 0.5653\n","Epoch 72/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4881 - val_loss: 0.5654\n","Epoch 73/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4724 - val_loss: 0.5651\n","Epoch 74/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4867 - val_loss: 0.5655\n","Epoch 75/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4944 - val_loss: 0.5653\n","Epoch 76/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4784 - val_loss: 0.5653\n","Epoch 77/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4791 - val_loss: 0.5651\n","Epoch 78/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4771 - val_loss: 0.5652\n","Epoch 79/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4835 - val_loss: 0.5653\n","Epoch 80/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4888 - val_loss: 0.5654\n","Epoch 81/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4850 - val_loss: 0.5653\n","Epoch 82/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4827 - val_loss: 0.5654\n","Epoch 83/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4893 - val_loss: 0.5654\n","\n","Epoch 00083: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n","Epoch 84/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4794 - val_loss: 0.5654\n","Epoch 85/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4944 - val_loss: 0.5653\n","Epoch 86/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4822 - val_loss: 0.5652\n","Epoch 87/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4970 - val_loss: 0.5653\n","Epoch 88/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4827 - val_loss: 0.5653\n","Epoch 89/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4852 - val_loss: 0.5653\n","Epoch 90/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4839 - val_loss: 0.5652\n","Epoch 91/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4824 - val_loss: 0.5652\n","Epoch 92/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4748 - val_loss: 0.5651\n","Epoch 93/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4884 - val_loss: 0.5654\n","\n","Epoch 00093: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n","Epoch 94/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4922 - val_loss: 0.5653\n","Epoch 95/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4796 - val_loss: 0.5652\n","Epoch 96/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4873 - val_loss: 0.5655\n","Epoch 97/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4849 - val_loss: 0.5654\n","Epoch 98/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4652 - val_loss: 0.5654\n","Epoch 99/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4983 - val_loss: 0.5652\n","Epoch 100/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4899 - val_loss: 0.5654\n","Epoch 101/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4760 - val_loss: 0.5652\n","Epoch 102/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4777 - val_loss: 0.5652\n","Epoch 103/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4909 - val_loss: 0.5652\n","\n","Epoch 00103: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n","Epoch 104/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4787 - val_loss: 0.5652\n","Epoch 105/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4790 - val_loss: 0.5653\n","Epoch 106/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4822 - val_loss: 0.5652\n","Epoch 107/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4720 - val_loss: 0.5653\n","Epoch 108/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4759 - val_loss: 0.5651\n","Epoch 109/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4821 - val_loss: 0.5653\n","Epoch 110/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4874 - val_loss: 0.5652\n","Epoch 111/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4877 - val_loss: 0.5652\n","Epoch 112/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4735 - val_loss: 0.5653\n","Epoch 113/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4944 - val_loss: 0.5651\n","\n","Epoch 00113: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n","Epoch 114/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4821 - val_loss: 0.5652\n","Epoch 115/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4913 - val_loss: 0.5653\n","Epoch 116/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4850 - val_loss: 0.5652\n","Epoch 117/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4781 - val_loss: 0.5651\n","Epoch 118/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4859 - val_loss: 0.5651\n","Epoch 119/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4902 - val_loss: 0.5653\n","Epoch 120/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4725 - val_loss: 0.5652\n","Epoch 121/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4808 - val_loss: 0.5652\n","Epoch 122/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4819 - val_loss: 0.5653\n","Epoch 123/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4773 - val_loss: 0.5653\n","\n","Epoch 00123: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n","Epoch 124/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4730 - val_loss: 0.5652\n","Epoch 125/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4862 - val_loss: 0.5652\n","Epoch 126/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4809 - val_loss: 0.5651\n","Epoch 127/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4853 - val_loss: 0.5652\n","Epoch 128/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4876 - val_loss: 0.5653\n","Epoch 129/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4931 - val_loss: 0.5651\n","Epoch 130/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4852 - val_loss: 0.5651\n","Epoch 131/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4954 - val_loss: 0.5652\n","Epoch 132/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4736 - val_loss: 0.5652\n","Epoch 133/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4809 - val_loss: 0.5653\n","\n","Epoch 00133: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n","Epoch 134/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4894 - val_loss: 0.5652\n","Epoch 135/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4784 - val_loss: 0.5651\n","Epoch 136/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4810 - val_loss: 0.5652\n","Epoch 137/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4712 - val_loss: 0.5652\n","Epoch 138/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4681 - val_loss: 0.5653\n","Epoch 139/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4913 - val_loss: 0.5652\n","Epoch 140/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4655 - val_loss: 0.5652\n","Epoch 141/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4888 - val_loss: 0.5652\n","Epoch 142/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4804 - val_loss: 0.5651\n","Epoch 143/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4710 - val_loss: 0.5651\n","\n","Epoch 00143: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n","Epoch 144/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4708 - val_loss: 0.5652\n","Epoch 145/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4715 - val_loss: 0.5652\n","Epoch 146/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4854 - val_loss: 0.5652\n","Epoch 147/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4845 - val_loss: 0.5652\n","Epoch 148/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4840 - val_loss: 0.5651\n","Epoch 149/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4797 - val_loss: 0.5652\n","Epoch 150/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4847 - val_loss: 0.5652\n","Epoch 151/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4770 - val_loss: 0.5651\n","Epoch 152/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4869 - val_loss: 0.5652\n","Epoch 153/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4777 - val_loss: 0.5652\n","\n","Epoch 00153: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n","Epoch 154/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4665 - val_loss: 0.5652\n","Epoch 155/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4922 - val_loss: 0.5651\n","Epoch 156/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4843 - val_loss: 0.5651\n","Epoch 157/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4777 - val_loss: 0.5652\n","Epoch 158/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4779 - val_loss: 0.5651\n","Epoch 159/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4933 - val_loss: 0.5652\n","Epoch 160/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4760 - val_loss: 0.5651\n","Epoch 161/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4895 - val_loss: 0.5651\n","Epoch 162/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4849 - val_loss: 0.5652\n","Epoch 163/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4811 - val_loss: 0.5652\n","\n","Epoch 00163: ReduceLROnPlateau reducing learning rate to 4.398046075948514e-06.\n","Epoch 164/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4883 - val_loss: 0.5652\n","Epoch 165/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4809 - val_loss: 0.5652\n","Epoch 166/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4823 - val_loss: 0.5651\n","Epoch 167/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4885 - val_loss: 0.5651\n","Epoch 168/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4756 - val_loss: 0.5652\n","Epoch 169/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4870 - val_loss: 0.5651\n","Epoch 170/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4856 - val_loss: 0.5651\n","Epoch 171/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4834 - val_loss: 0.5651\n","Epoch 172/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4802 - val_loss: 0.5652\n","Epoch 173/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4867 - val_loss: 0.5651\n","\n","Epoch 00173: ReduceLROnPlateau reducing learning rate to 3.518437006277964e-06.\n","Epoch 174/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4910 - val_loss: 0.5651\n","Epoch 175/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4840 - val_loss: 0.5651\n","Epoch 176/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4832 - val_loss: 0.5651\n","Epoch 177/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4838 - val_loss: 0.5651\n","Epoch 178/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4833 - val_loss: 0.5652\n","Epoch 179/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4923 - val_loss: 0.5651\n","Epoch 180/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4868 - val_loss: 0.5652\n","Epoch 181/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4847 - val_loss: 0.5651\n","Epoch 182/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4881 - val_loss: 0.5652\n","Epoch 183/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4699 - val_loss: 0.5651\n","\n","Epoch 00183: ReduceLROnPlateau reducing learning rate to 2.814749677781947e-06.\n","Epoch 184/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4851 - val_loss: 0.5652\n","Epoch 185/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4893 - val_loss: 0.5651\n","Epoch 186/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4819 - val_loss: 0.5651\n","Epoch 187/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4740 - val_loss: 0.5651\n","Epoch 188/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4828 - val_loss: 0.5651\n","Epoch 189/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4871 - val_loss: 0.5651\n","Epoch 190/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4697 - val_loss: 0.5651\n","Epoch 191/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4884 - val_loss: 0.5651\n","Epoch 192/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4739 - val_loss: 0.5652\n","Epoch 193/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4797 - val_loss: 0.5651\n","\n","Epoch 00193: ReduceLROnPlateau reducing learning rate to 2.2517997422255576e-06.\n","Epoch 194/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4884 - val_loss: 0.5652\n","Epoch 195/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4865 - val_loss: 0.5651\n","Epoch 196/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4814 - val_loss: 0.5651\n","Epoch 197/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4860 - val_loss: 0.5651\n","Epoch 198/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4870 - val_loss: 0.5651\n","Epoch 199/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4905 - val_loss: 0.5652\n","Epoch 200/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4844 - val_loss: 0.5651\n","Epoch 201/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4845 - val_loss: 0.5651\n","Epoch 202/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4853 - val_loss: 0.5651\n","Epoch 203/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4709 - val_loss: 0.5651\n","\n","Epoch 00203: ReduceLROnPlateau reducing learning rate to 1.801439793780446e-06.\n","Epoch 204/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4748 - val_loss: 0.5651\n","Epoch 205/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4842 - val_loss: 0.5651\n","Epoch 206/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4787 - val_loss: 0.5651\n","Epoch 207/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4826 - val_loss: 0.5651\n","Epoch 208/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4799 - val_loss: 0.5651\n","Epoch 209/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4787 - val_loss: 0.5651\n","Epoch 210/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4739 - val_loss: 0.5651\n","Epoch 211/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4918 - val_loss: 0.5651\n","Epoch 212/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4813 - val_loss: 0.5651\n","Epoch 213/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4866 - val_loss: 0.5651\n","\n","Epoch 00213: ReduceLROnPlateau reducing learning rate to 1.441151835024357e-06.\n","Epoch 214/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4794 - val_loss: 0.5651\n","Epoch 215/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4853 - val_loss: 0.5651\n","Epoch 216/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4933 - val_loss: 0.5651\n","Epoch 217/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4981 - val_loss: 0.5651\n","Epoch 218/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4775 - val_loss: 0.5651\n","Epoch 219/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4851 - val_loss: 0.5651\n","Epoch 220/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4853 - val_loss: 0.5651\n","Epoch 221/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4862 - val_loss: 0.5651\n","Epoch 222/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4800 - val_loss: 0.5651\n","Epoch 223/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4853 - val_loss: 0.5651\n","\n","Epoch 00223: ReduceLROnPlateau reducing learning rate to 1.1529215043992736e-06.\n","Epoch 224/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4831 - val_loss: 0.5651\n","Epoch 225/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4875 - val_loss: 0.5651\n","Epoch 226/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4760 - val_loss: 0.5651\n","Epoch 227/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4758 - val_loss: 0.5651\n","Epoch 228/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4916 - val_loss: 0.5651\n","Epoch 229/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4914 - val_loss: 0.5651\n","Epoch 230/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4857 - val_loss: 0.5651\n","Epoch 231/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4841 - val_loss: 0.5651\n","Epoch 232/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4848 - val_loss: 0.5651\n","Epoch 233/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4977 - val_loss: 0.5651\n","\n","Epoch 00233: ReduceLROnPlateau reducing learning rate to 9.223372217093129e-07.\n","Epoch 234/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4713 - val_loss: 0.5651\n","Epoch 235/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4812 - val_loss: 0.5651\n","Epoch 236/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4807 - val_loss: 0.5651\n","Epoch 237/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4867 - val_loss: 0.5651\n","Epoch 238/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4806 - val_loss: 0.5651\n","Epoch 239/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4828 - val_loss: 0.5651\n","Epoch 240/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4790 - val_loss: 0.5651\n","Epoch 241/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4752 - val_loss: 0.5651\n","Epoch 242/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4758 - val_loss: 0.5651\n","Epoch 243/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4780 - val_loss: 0.5651\n","\n","Epoch 00243: ReduceLROnPlateau reducing learning rate to 7.378697773674503e-07.\n","Epoch 244/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4855 - val_loss: 0.5651\n","Epoch 245/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4865 - val_loss: 0.5651\n","Epoch 246/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4768 - val_loss: 0.5651\n","Epoch 247/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4861 - val_loss: 0.5651\n","Epoch 248/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4846 - val_loss: 0.5651\n","Epoch 249/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4782 - val_loss: 0.5651\n","Epoch 250/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4759 - val_loss: 0.5651\n","Epoch 251/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4885 - val_loss: 0.5651\n","Epoch 252/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4835 - val_loss: 0.5651\n","Epoch 253/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4915 - val_loss: 0.5651\n","\n","Epoch 00253: ReduceLROnPlateau reducing learning rate to 5.902958037040663e-07.\n","Epoch 254/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4779 - val_loss: 0.5651\n","Epoch 255/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4890 - val_loss: 0.5651\n","Epoch 256/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4754 - val_loss: 0.5651\n","Epoch 257/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4820 - val_loss: 0.5651\n","Epoch 258/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4801 - val_loss: 0.5651\n","Epoch 259/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4719 - val_loss: 0.5651\n","Epoch 260/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4864 - val_loss: 0.5651\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fabb4f93410>"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"bEw62b1bICtM"},"source":["<h3> Training GRU for another 260 epochs </h3>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8i5kp-3QBJ3A","executionInfo":{"status":"ok","timestamp":1616216862429,"user_tz":-330,"elapsed":231633,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"3a10139b-fd8d-4a00-9c15-b1e306112e0e"},"source":["#model with 1% validation data with Adam optimizer.\n","optimizer = tf.keras.optimizers.Adam(0.0001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data],decoder_output_data,validation_data=([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data),batch_size=64,epochs=260,callbacks=[rl])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/260\n","31/31 [==============================] - 4s 52ms/step - loss: 0.4851 - val_loss: 0.5648\n","Epoch 2/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.5010 - val_loss: 0.5654\n","Epoch 3/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4765 - val_loss: 0.5650\n","Epoch 4/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4851 - val_loss: 0.5652\n","Epoch 5/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4851 - val_loss: 0.5656\n","Epoch 6/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4804 - val_loss: 0.5651\n","Epoch 7/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4766 - val_loss: 0.5651\n","Epoch 8/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4801 - val_loss: 0.5647\n","Epoch 9/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4792 - val_loss: 0.5652\n","Epoch 10/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4792 - val_loss: 0.5650\n","Epoch 11/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4735 - val_loss: 0.5648\n","Epoch 12/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4744 - val_loss: 0.5651\n","Epoch 13/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4819 - val_loss: 0.5650\n","Epoch 14/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4897 - val_loss: 0.5651\n","Epoch 15/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4816 - val_loss: 0.5652\n","Epoch 16/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4736 - val_loss: 0.5646\n","Epoch 17/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4856 - val_loss: 0.5640\n","Epoch 18/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4831 - val_loss: 0.5647\n","Epoch 19/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4738 - val_loss: 0.5650\n","Epoch 20/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4700 - val_loss: 0.5646\n","Epoch 21/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4795 - val_loss: 0.5647\n","Epoch 22/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4707 - val_loss: 0.5648\n","Epoch 23/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4726 - val_loss: 0.5648\n","Epoch 24/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4656 - val_loss: 0.5647\n","Epoch 25/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4731 - val_loss: 0.5654\n","Epoch 26/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4806 - val_loss: 0.5640\n","Epoch 27/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4853 - val_loss: 0.5648\n","\n","Epoch 00027: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n","Epoch 28/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4807 - val_loss: 0.5644\n","Epoch 29/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4760 - val_loss: 0.5651\n","Epoch 30/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4842 - val_loss: 0.5646\n","Epoch 31/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4923 - val_loss: 0.5649\n","Epoch 32/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4707 - val_loss: 0.5645\n","Epoch 33/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4854 - val_loss: 0.5648\n","Epoch 34/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4822 - val_loss: 0.5647\n","Epoch 35/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4829 - val_loss: 0.5652\n","Epoch 36/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4753 - val_loss: 0.5648\n","Epoch 37/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4773 - val_loss: 0.5650\n","\n","Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n","Epoch 38/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4837 - val_loss: 0.5645\n","Epoch 39/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4740 - val_loss: 0.5645\n","Epoch 40/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4847 - val_loss: 0.5651\n","Epoch 41/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4828 - val_loss: 0.5648\n","Epoch 42/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4898 - val_loss: 0.5650\n","Epoch 43/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4786 - val_loss: 0.5646\n","Epoch 44/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4649 - val_loss: 0.5651\n","Epoch 45/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4873 - val_loss: 0.5649\n","Epoch 46/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4817 - val_loss: 0.5648\n","Epoch 47/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4839 - val_loss: 0.5650\n","\n","Epoch 00047: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n","Epoch 48/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4786 - val_loss: 0.5645\n","Epoch 49/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4707 - val_loss: 0.5649\n","Epoch 50/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4796 - val_loss: 0.5650\n","Epoch 51/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4767 - val_loss: 0.5647\n","Epoch 52/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4699 - val_loss: 0.5646\n","Epoch 53/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4779 - val_loss: 0.5646\n","Epoch 54/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4710 - val_loss: 0.5649\n","Epoch 55/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4743 - val_loss: 0.5647\n","Epoch 56/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4839 - val_loss: 0.5647\n","Epoch 57/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4818 - val_loss: 0.5645\n","\n","Epoch 00057: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n","Epoch 58/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4780 - val_loss: 0.5646\n","Epoch 59/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4789 - val_loss: 0.5648\n","Epoch 60/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4826 - val_loss: 0.5646\n","Epoch 61/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4756 - val_loss: 0.5648\n","Epoch 62/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4694 - val_loss: 0.5648\n","Epoch 63/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4833 - val_loss: 0.5647\n","Epoch 64/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4686 - val_loss: 0.5647\n","Epoch 65/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4707 - val_loss: 0.5647\n","Epoch 66/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4824 - val_loss: 0.5646\n","Epoch 67/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4849 - val_loss: 0.5647\n","\n","Epoch 00067: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n","Epoch 68/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4760 - val_loss: 0.5646\n","Epoch 69/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4748 - val_loss: 0.5646\n","Epoch 70/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4757 - val_loss: 0.5646\n","Epoch 71/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4801 - val_loss: 0.5646\n","Epoch 72/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4627 - val_loss: 0.5648\n","Epoch 73/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4806 - val_loss: 0.5646\n","Epoch 74/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4651 - val_loss: 0.5646\n","Epoch 75/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4687 - val_loss: 0.5646\n","Epoch 76/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4749 - val_loss: 0.5646\n","Epoch 77/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4859 - val_loss: 0.5646\n","\n","Epoch 00077: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n","Epoch 78/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4665 - val_loss: 0.5646\n","Epoch 79/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4732 - val_loss: 0.5646\n","Epoch 80/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4749 - val_loss: 0.5647\n","Epoch 81/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4695 - val_loss: 0.5646\n","Epoch 82/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4939 - val_loss: 0.5647\n","Epoch 83/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4729 - val_loss: 0.5647\n","Epoch 84/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4742 - val_loss: 0.5646\n","Epoch 85/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4847 - val_loss: 0.5646\n","Epoch 86/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4789 - val_loss: 0.5647\n","Epoch 87/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4820 - val_loss: 0.5646\n","\n","Epoch 00087: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n","Epoch 88/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4748 - val_loss: 0.5647\n","Epoch 89/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4823 - val_loss: 0.5647\n","Epoch 90/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4688 - val_loss: 0.5648\n","Epoch 91/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4792 - val_loss: 0.5647\n","Epoch 92/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4926 - val_loss: 0.5647\n","Epoch 93/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4842 - val_loss: 0.5648\n","Epoch 94/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4784 - val_loss: 0.5647\n","Epoch 95/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4750 - val_loss: 0.5647\n","Epoch 96/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4673 - val_loss: 0.5647\n","Epoch 97/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4818 - val_loss: 0.5647\n","\n","Epoch 00097: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n","Epoch 98/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4730 - val_loss: 0.5646\n","Epoch 99/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4751 - val_loss: 0.5646\n","Epoch 100/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4699 - val_loss: 0.5647\n","Epoch 101/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4767 - val_loss: 0.5646\n","Epoch 102/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4747 - val_loss: 0.5647\n","Epoch 103/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4864 - val_loss: 0.5647\n","Epoch 104/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4795 - val_loss: 0.5646\n","Epoch 105/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4693 - val_loss: 0.5646\n","Epoch 106/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4824 - val_loss: 0.5646\n","Epoch 107/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4776 - val_loss: 0.5646\n","\n","Epoch 00107: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n","Epoch 108/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4768 - val_loss: 0.5646\n","Epoch 109/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4771 - val_loss: 0.5646\n","Epoch 110/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4624 - val_loss: 0.5647\n","Epoch 111/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4716 - val_loss: 0.5647\n","Epoch 112/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4742 - val_loss: 0.5646\n","Epoch 113/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4713 - val_loss: 0.5646\n","Epoch 114/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4637 - val_loss: 0.5647\n","Epoch 115/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4736 - val_loss: 0.5647\n","Epoch 116/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4699 - val_loss: 0.5647\n","Epoch 117/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4702 - val_loss: 0.5647\n","\n","Epoch 00117: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n","Epoch 118/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4698 - val_loss: 0.5646\n","Epoch 119/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4839 - val_loss: 0.5647\n","Epoch 120/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4755 - val_loss: 0.5647\n","Epoch 121/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4796 - val_loss: 0.5646\n","Epoch 122/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4776 - val_loss: 0.5647\n","Epoch 123/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4787 - val_loss: 0.5647\n","Epoch 124/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4710 - val_loss: 0.5647\n","Epoch 125/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4867 - val_loss: 0.5647\n","Epoch 126/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4735 - val_loss: 0.5647\n","Epoch 127/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4701 - val_loss: 0.5646\n","\n","Epoch 00127: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n","Epoch 128/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4770 - val_loss: 0.5647\n","Epoch 129/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4701 - val_loss: 0.5647\n","Epoch 130/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4816 - val_loss: 0.5646\n","Epoch 131/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4773 - val_loss: 0.5647\n","Epoch 132/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4794 - val_loss: 0.5646\n","Epoch 133/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4695 - val_loss: 0.5646\n","Epoch 134/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4706 - val_loss: 0.5646\n","Epoch 135/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4820 - val_loss: 0.5647\n","Epoch 136/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4743 - val_loss: 0.5647\n","Epoch 137/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4866 - val_loss: 0.5647\n","\n","Epoch 00137: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n","Epoch 138/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4690 - val_loss: 0.5647\n","Epoch 139/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4757 - val_loss: 0.5647\n","Epoch 140/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4781 - val_loss: 0.5647\n","Epoch 141/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4728 - val_loss: 0.5647\n","Epoch 142/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4688 - val_loss: 0.5647\n","Epoch 143/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4774 - val_loss: 0.5647\n","Epoch 144/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4816 - val_loss: 0.5647\n","Epoch 145/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4725 - val_loss: 0.5646\n","Epoch 146/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4864 - val_loss: 0.5647\n","Epoch 147/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4888 - val_loss: 0.5647\n","\n","Epoch 00147: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n","Epoch 148/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4742 - val_loss: 0.5647\n","Epoch 149/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4849 - val_loss: 0.5647\n","Epoch 150/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4707 - val_loss: 0.5647\n","Epoch 151/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4903 - val_loss: 0.5647\n","Epoch 152/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4726 - val_loss: 0.5647\n","Epoch 153/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4844 - val_loss: 0.5647\n","Epoch 154/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4745 - val_loss: 0.5647\n","Epoch 155/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4786 - val_loss: 0.5647\n","Epoch 156/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4738 - val_loss: 0.5646\n","Epoch 157/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4743 - val_loss: 0.5647\n","\n","Epoch 00157: ReduceLROnPlateau reducing learning rate to 4.398046075948514e-06.\n","Epoch 158/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4688 - val_loss: 0.5646\n","Epoch 159/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4740 - val_loss: 0.5646\n","Epoch 160/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4734 - val_loss: 0.5646\n","Epoch 161/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4719 - val_loss: 0.5647\n","Epoch 162/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4749 - val_loss: 0.5647\n","Epoch 163/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4649 - val_loss: 0.5646\n","Epoch 164/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4723 - val_loss: 0.5647\n","Epoch 165/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4737 - val_loss: 0.5647\n","Epoch 166/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4646 - val_loss: 0.5647\n","Epoch 167/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4706 - val_loss: 0.5647\n","\n","Epoch 00167: ReduceLROnPlateau reducing learning rate to 3.518437006277964e-06.\n","Epoch 168/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4691 - val_loss: 0.5647\n","Epoch 169/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4775 - val_loss: 0.5647\n","Epoch 170/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4851 - val_loss: 0.5647\n","Epoch 171/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4819 - val_loss: 0.5647\n","Epoch 172/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4674 - val_loss: 0.5647\n","Epoch 173/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4755 - val_loss: 0.5647\n","Epoch 174/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4766 - val_loss: 0.5646\n","Epoch 175/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4697 - val_loss: 0.5647\n","Epoch 176/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4865 - val_loss: 0.5646\n","Epoch 177/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4634 - val_loss: 0.5647\n","\n","Epoch 00177: ReduceLROnPlateau reducing learning rate to 2.814749677781947e-06.\n","Epoch 178/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4803 - val_loss: 0.5647\n","Epoch 179/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4655 - val_loss: 0.5646\n","Epoch 180/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4672 - val_loss: 0.5647\n","Epoch 181/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4784 - val_loss: 0.5647\n","Epoch 182/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4718 - val_loss: 0.5646\n","Epoch 183/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4686 - val_loss: 0.5647\n","Epoch 184/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4725 - val_loss: 0.5646\n","Epoch 185/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4824 - val_loss: 0.5647\n","Epoch 186/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4756 - val_loss: 0.5647\n","Epoch 187/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4843 - val_loss: 0.5647\n","\n","Epoch 00187: ReduceLROnPlateau reducing learning rate to 2.2517997422255576e-06.\n","Epoch 188/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4717 - val_loss: 0.5647\n","Epoch 189/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4689 - val_loss: 0.5647\n","Epoch 190/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4740 - val_loss: 0.5647\n","Epoch 191/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4725 - val_loss: 0.5647\n","Epoch 192/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4846 - val_loss: 0.5647\n","Epoch 193/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4789 - val_loss: 0.5647\n","Epoch 194/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4727 - val_loss: 0.5647\n","Epoch 195/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4738 - val_loss: 0.5647\n","Epoch 196/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4644 - val_loss: 0.5647\n","Epoch 197/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4905 - val_loss: 0.5646\n","\n","Epoch 00197: ReduceLROnPlateau reducing learning rate to 1.801439793780446e-06.\n","Epoch 198/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4699 - val_loss: 0.5647\n","Epoch 199/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4767 - val_loss: 0.5647\n","Epoch 200/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4871 - val_loss: 0.5647\n","Epoch 201/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4723 - val_loss: 0.5647\n","Epoch 202/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4827 - val_loss: 0.5647\n","Epoch 203/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4739 - val_loss: 0.5647\n","Epoch 204/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4737 - val_loss: 0.5647\n","Epoch 205/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4703 - val_loss: 0.5647\n","Epoch 206/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4807 - val_loss: 0.5647\n","Epoch 207/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4764 - val_loss: 0.5647\n","\n","Epoch 00207: ReduceLROnPlateau reducing learning rate to 1.441151835024357e-06.\n","Epoch 208/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4741 - val_loss: 0.5647\n","Epoch 209/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4747 - val_loss: 0.5647\n","Epoch 210/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4832 - val_loss: 0.5647\n","Epoch 211/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4647 - val_loss: 0.5647\n","Epoch 212/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4811 - val_loss: 0.5647\n","Epoch 213/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4664 - val_loss: 0.5647\n","Epoch 214/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4860 - val_loss: 0.5647\n","Epoch 215/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4680 - val_loss: 0.5647\n","Epoch 216/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4773 - val_loss: 0.5647\n","Epoch 217/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4772 - val_loss: 0.5647\n","\n","Epoch 00217: ReduceLROnPlateau reducing learning rate to 1.1529215043992736e-06.\n","Epoch 218/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4773 - val_loss: 0.5647\n","Epoch 219/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4795 - val_loss: 0.5647\n","Epoch 220/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4707 - val_loss: 0.5647\n","Epoch 221/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4631 - val_loss: 0.5647\n","Epoch 222/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4792 - val_loss: 0.5647\n","Epoch 223/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4744 - val_loss: 0.5647\n","Epoch 224/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4859 - val_loss: 0.5647\n","Epoch 225/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4728 - val_loss: 0.5647\n","Epoch 226/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4710 - val_loss: 0.5647\n","Epoch 227/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4746 - val_loss: 0.5647\n","\n","Epoch 00227: ReduceLROnPlateau reducing learning rate to 9.223372217093129e-07.\n","Epoch 228/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4710 - val_loss: 0.5647\n","Epoch 229/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4701 - val_loss: 0.5647\n","Epoch 230/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4727 - val_loss: 0.5647\n","Epoch 231/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4782 - val_loss: 0.5647\n","Epoch 232/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4710 - val_loss: 0.5647\n","Epoch 233/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4624 - val_loss: 0.5647\n","Epoch 234/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4809 - val_loss: 0.5647\n","Epoch 235/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4719 - val_loss: 0.5647\n","Epoch 236/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4795 - val_loss: 0.5647\n","Epoch 237/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4779 - val_loss: 0.5647\n","\n","Epoch 00237: ReduceLROnPlateau reducing learning rate to 7.378697773674503e-07.\n","Epoch 238/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4790 - val_loss: 0.5647\n","Epoch 239/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4767 - val_loss: 0.5647\n","Epoch 240/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4710 - val_loss: 0.5647\n","Epoch 241/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4672 - val_loss: 0.5647\n","Epoch 242/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4730 - val_loss: 0.5647\n","Epoch 243/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4779 - val_loss: 0.5647\n","Epoch 244/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4729 - val_loss: 0.5647\n","Epoch 245/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4830 - val_loss: 0.5647\n","Epoch 246/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4634 - val_loss: 0.5647\n","Epoch 247/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4904 - val_loss: 0.5647\n","\n","Epoch 00247: ReduceLROnPlateau reducing learning rate to 5.902958037040663e-07.\n","Epoch 248/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4694 - val_loss: 0.5647\n","Epoch 249/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4717 - val_loss: 0.5647\n","Epoch 250/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4663 - val_loss: 0.5647\n","Epoch 251/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4821 - val_loss: 0.5647\n","Epoch 252/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4758 - val_loss: 0.5647\n","Epoch 253/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4869 - val_loss: 0.5647\n","Epoch 254/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4749 - val_loss: 0.5647\n","Epoch 255/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4685 - val_loss: 0.5647\n","Epoch 256/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4883 - val_loss: 0.5647\n","Epoch 257/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4843 - val_loss: 0.5647\n","\n","Epoch 00257: ReduceLROnPlateau reducing learning rate to 4.72236661153147e-07.\n","Epoch 258/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4715 - val_loss: 0.5647\n","Epoch 259/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4747 - val_loss: 0.5647\n","Epoch 260/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4697 - val_loss: 0.5647\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fab8ff10d90>"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"CehV38X-IIIL"},"source":["<h3> Training GRU for another 260 epochs </h3>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8MEsGdLOGoq","executionInfo":{"status":"ok","timestamp":1616220259916,"user_tz":-330,"elapsed":234062,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"164901f3-c282-4921-f24b-23cea13a639b"},"source":["#model with 1% validation data with Adam optimizer.\n","optimizer = tf.keras.optimizers.Adam(0.0001)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n","model.fit([encoder_input_data, decoder_input_data],decoder_output_data,validation_data=([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data),batch_size=64,epochs=260,callbacks=[rl])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/260\n","31/31 [==============================] - 4s 52ms/step - loss: 0.4667 - val_loss: 0.5649\n","Epoch 2/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4882 - val_loss: 0.5649\n","Epoch 3/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4778 - val_loss: 0.5642\n","Epoch 4/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4641 - val_loss: 0.5647\n","Epoch 5/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4797 - val_loss: 0.5653\n","Epoch 6/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4826 - val_loss: 0.5648\n","Epoch 7/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4821 - val_loss: 0.5647\n","Epoch 8/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4885 - val_loss: 0.5651\n","Epoch 9/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4783 - val_loss: 0.5653\n","Epoch 10/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4654 - val_loss: 0.5650\n","Epoch 11/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4638 - val_loss: 0.5645\n","Epoch 12/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4697 - val_loss: 0.5649\n","Epoch 13/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4687 - val_loss: 0.5649\n","\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.\n","Epoch 14/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4616 - val_loss: 0.5644\n","Epoch 15/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4939 - val_loss: 0.5647\n","Epoch 16/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4780 - val_loss: 0.5647\n","Epoch 17/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4734 - val_loss: 0.5651\n","Epoch 18/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4762 - val_loss: 0.5655\n","Epoch 19/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4704 - val_loss: 0.5649\n","Epoch 20/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4728 - val_loss: 0.5635\n","Epoch 21/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4724 - val_loss: 0.5651\n","Epoch 22/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4681 - val_loss: 0.5645\n","Epoch 23/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4707 - val_loss: 0.5649\n","Epoch 24/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4668 - val_loss: 0.5649\n","Epoch 25/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4714 - val_loss: 0.5649\n","Epoch 26/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4835 - val_loss: 0.5651\n","Epoch 27/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4731 - val_loss: 0.5649\n","Epoch 28/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4774 - val_loss: 0.5645\n","Epoch 29/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4703 - val_loss: 0.5650\n","Epoch 30/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4605 - val_loss: 0.5650\n","\n","Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.\n","Epoch 31/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4647 - val_loss: 0.5647\n","Epoch 32/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4757 - val_loss: 0.5649\n","Epoch 33/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4712 - val_loss: 0.5648\n","Epoch 34/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4686 - val_loss: 0.5649\n","Epoch 35/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4865 - val_loss: 0.5646\n","Epoch 36/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4806 - val_loss: 0.5647\n","Epoch 37/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4683 - val_loss: 0.5647\n","Epoch 38/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4736 - val_loss: 0.5649\n","Epoch 39/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4768 - val_loss: 0.5646\n","Epoch 40/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4762 - val_loss: 0.5649\n","\n","Epoch 00040: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.\n","Epoch 41/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4644 - val_loss: 0.5649\n","Epoch 42/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4678 - val_loss: 0.5645\n","Epoch 43/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4639 - val_loss: 0.5648\n","Epoch 44/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4635 - val_loss: 0.5648\n","Epoch 45/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4731 - val_loss: 0.5647\n","Epoch 46/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4750 - val_loss: 0.5647\n","Epoch 47/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4573 - val_loss: 0.5645\n","Epoch 48/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4748 - val_loss: 0.5647\n","Epoch 49/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4739 - val_loss: 0.5648\n","Epoch 50/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4758 - val_loss: 0.5647\n","\n","Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.\n","Epoch 51/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4791 - val_loss: 0.5648\n","Epoch 52/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4668 - val_loss: 0.5650\n","Epoch 53/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4633 - val_loss: 0.5650\n","Epoch 54/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4622 - val_loss: 0.5646\n","Epoch 55/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4805 - val_loss: 0.5648\n","Epoch 56/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4702 - val_loss: 0.5649\n","Epoch 57/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4731 - val_loss: 0.5650\n","Epoch 58/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4661 - val_loss: 0.5647\n","Epoch 59/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4663 - val_loss: 0.5650\n","Epoch 60/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4708 - val_loss: 0.5649\n","\n","Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.\n","Epoch 61/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4721 - val_loss: 0.5651\n","Epoch 62/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4774 - val_loss: 0.5648\n","Epoch 63/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4729 - val_loss: 0.5648\n","Epoch 64/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4768 - val_loss: 0.5646\n","Epoch 65/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4689 - val_loss: 0.5647\n","Epoch 66/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4757 - val_loss: 0.5647\n","Epoch 67/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4676 - val_loss: 0.5647\n","Epoch 68/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4709 - val_loss: 0.5648\n","Epoch 69/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4744 - val_loss: 0.5648\n","Epoch 70/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4593 - val_loss: 0.5648\n","\n","Epoch 00070: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.\n","Epoch 71/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4686 - val_loss: 0.5648\n","Epoch 72/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4676 - val_loss: 0.5647\n","Epoch 73/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4726 - val_loss: 0.5651\n","Epoch 74/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4860 - val_loss: 0.5648\n","Epoch 75/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4696 - val_loss: 0.5648\n","Epoch 76/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4654 - val_loss: 0.5648\n","Epoch 77/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4735 - val_loss: 0.5648\n","Epoch 78/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4757 - val_loss: 0.5648\n","Epoch 79/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4644 - val_loss: 0.5647\n","Epoch 80/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4684 - val_loss: 0.5647\n","\n","Epoch 00080: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.\n","Epoch 81/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4771 - val_loss: 0.5648\n","Epoch 82/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4670 - val_loss: 0.5648\n","Epoch 83/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4704 - val_loss: 0.5647\n","Epoch 84/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4676 - val_loss: 0.5649\n","Epoch 85/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4764 - val_loss: 0.5648\n","Epoch 86/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4736 - val_loss: 0.5647\n","Epoch 87/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4715 - val_loss: 0.5650\n","Epoch 88/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4722 - val_loss: 0.5649\n","Epoch 89/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4716 - val_loss: 0.5647\n","Epoch 90/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4572 - val_loss: 0.5648\n","\n","Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.6777214477770033e-05.\n","Epoch 91/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4656 - val_loss: 0.5648\n","Epoch 92/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4772 - val_loss: 0.5648\n","Epoch 93/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4693 - val_loss: 0.5649\n","Epoch 94/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4693 - val_loss: 0.5648\n","Epoch 95/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4768 - val_loss: 0.5647\n","Epoch 96/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4758 - val_loss: 0.5648\n","Epoch 97/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4763 - val_loss: 0.5649\n","Epoch 98/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4717 - val_loss: 0.5649\n","Epoch 99/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4788 - val_loss: 0.5647\n","Epoch 100/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4630 - val_loss: 0.5649\n","\n","Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.3421771291177721e-05.\n","Epoch 101/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4727 - val_loss: 0.5649\n","Epoch 102/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4764 - val_loss: 0.5648\n","Epoch 103/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4742 - val_loss: 0.5648\n","Epoch 104/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4681 - val_loss: 0.5648\n","Epoch 105/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4649 - val_loss: 0.5648\n","Epoch 106/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4579 - val_loss: 0.5648\n","Epoch 107/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4729 - val_loss: 0.5649\n","Epoch 108/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4640 - val_loss: 0.5648\n","Epoch 109/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4712 - val_loss: 0.5648\n","Epoch 110/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4624 - val_loss: 0.5649\n","\n","Epoch 00110: ReduceLROnPlateau reducing learning rate to 1.0737417323980481e-05.\n","Epoch 111/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4655 - val_loss: 0.5648\n","Epoch 112/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4745 - val_loss: 0.5648\n","Epoch 113/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4575 - val_loss: 0.5648\n","Epoch 114/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4777 - val_loss: 0.5648\n","Epoch 115/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4640 - val_loss: 0.5649\n","Epoch 116/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4583 - val_loss: 0.5648\n","Epoch 117/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4688 - val_loss: 0.5648\n","Epoch 118/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4669 - val_loss: 0.5649\n","Epoch 119/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4773 - val_loss: 0.5648\n","Epoch 120/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4657 - val_loss: 0.5648\n","\n","Epoch 00120: ReduceLROnPlateau reducing learning rate to 8.589933713665232e-06.\n","Epoch 121/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4661 - val_loss: 0.5648\n","Epoch 122/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4693 - val_loss: 0.5648\n","Epoch 123/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4567 - val_loss: 0.5648\n","Epoch 124/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4685 - val_loss: 0.5648\n","Epoch 125/260\n","31/31 [==============================] - 1s 27ms/step - loss: 0.4770 - val_loss: 0.5648\n","Epoch 126/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4699 - val_loss: 0.5648\n","Epoch 127/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4698 - val_loss: 0.5648\n","Epoch 128/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4973 - val_loss: 0.5648\n","Epoch 129/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4539 - val_loss: 0.5649\n","Epoch 130/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4744 - val_loss: 0.5649\n","\n","Epoch 00130: ReduceLROnPlateau reducing learning rate to 6.871946970932186e-06.\n","Epoch 131/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4627 - val_loss: 0.5649\n","Epoch 132/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4703 - val_loss: 0.5648\n","Epoch 133/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4728 - val_loss: 0.5648\n","Epoch 134/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4596 - val_loss: 0.5649\n","Epoch 135/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4758 - val_loss: 0.5648\n","Epoch 136/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4570 - val_loss: 0.5648\n","Epoch 137/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4611 - val_loss: 0.5648\n","Epoch 138/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4648 - val_loss: 0.5649\n","Epoch 139/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4723 - val_loss: 0.5648\n","Epoch 140/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4731 - val_loss: 0.5649\n","\n","Epoch 00140: ReduceLROnPlateau reducing learning rate to 5.497557503986173e-06.\n","Epoch 141/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4716 - val_loss: 0.5649\n","Epoch 142/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4641 - val_loss: 0.5649\n","Epoch 143/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4703 - val_loss: 0.5648\n","Epoch 144/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4746 - val_loss: 0.5649\n","Epoch 145/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4591 - val_loss: 0.5648\n","Epoch 146/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4710 - val_loss: 0.5648\n","Epoch 147/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4698 - val_loss: 0.5649\n","Epoch 148/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4799 - val_loss: 0.5648\n","Epoch 149/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4837 - val_loss: 0.5648\n","Epoch 150/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4659 - val_loss: 0.5648\n","\n","Epoch 00150: ReduceLROnPlateau reducing learning rate to 4.398046075948514e-06.\n","Epoch 151/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4745 - val_loss: 0.5648\n","Epoch 152/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4681 - val_loss: 0.5649\n","Epoch 153/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4659 - val_loss: 0.5648\n","Epoch 154/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4732 - val_loss: 0.5649\n","Epoch 155/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4679 - val_loss: 0.5649\n","Epoch 156/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4689 - val_loss: 0.5649\n","Epoch 157/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4629 - val_loss: 0.5648\n","Epoch 158/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4654 - val_loss: 0.5649\n","Epoch 159/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4663 - val_loss: 0.5649\n","Epoch 160/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4636 - val_loss: 0.5648\n","\n","Epoch 00160: ReduceLROnPlateau reducing learning rate to 3.518437006277964e-06.\n","Epoch 161/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4684 - val_loss: 0.5648\n","Epoch 162/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4709 - val_loss: 0.5648\n","Epoch 163/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4798 - val_loss: 0.5648\n","Epoch 164/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4683 - val_loss: 0.5648\n","Epoch 165/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4699 - val_loss: 0.5648\n","Epoch 166/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4693 - val_loss: 0.5648\n","Epoch 167/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4703 - val_loss: 0.5649\n","Epoch 168/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4645 - val_loss: 0.5648\n","Epoch 169/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4729 - val_loss: 0.5648\n","Epoch 170/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4616 - val_loss: 0.5648\n","\n","Epoch 00170: ReduceLROnPlateau reducing learning rate to 2.814749677781947e-06.\n","Epoch 171/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4562 - val_loss: 0.5648\n","Epoch 172/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4696 - val_loss: 0.5648\n","Epoch 173/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4620 - val_loss: 0.5648\n","Epoch 174/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4590 - val_loss: 0.5648\n","Epoch 175/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4609 - val_loss: 0.5648\n","Epoch 176/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4653 - val_loss: 0.5648\n","Epoch 177/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4745 - val_loss: 0.5648\n","Epoch 178/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4691 - val_loss: 0.5648\n","Epoch 179/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4829 - val_loss: 0.5649\n","Epoch 180/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4699 - val_loss: 0.5648\n","\n","Epoch 00180: ReduceLROnPlateau reducing learning rate to 2.2517997422255576e-06.\n","Epoch 181/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4714 - val_loss: 0.5648\n","Epoch 182/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4626 - val_loss: 0.5648\n","Epoch 183/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4684 - val_loss: 0.5648\n","Epoch 184/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4621 - val_loss: 0.5648\n","Epoch 185/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4671 - val_loss: 0.5648\n","Epoch 186/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4800 - val_loss: 0.5648\n","Epoch 187/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4606 - val_loss: 0.5648\n","Epoch 188/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4585 - val_loss: 0.5648\n","Epoch 189/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4768 - val_loss: 0.5648\n","Epoch 190/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4689 - val_loss: 0.5648\n","\n","Epoch 00190: ReduceLROnPlateau reducing learning rate to 1.801439793780446e-06.\n","Epoch 191/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4801 - val_loss: 0.5648\n","Epoch 192/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4601 - val_loss: 0.5649\n","Epoch 193/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4685 - val_loss: 0.5648\n","Epoch 194/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4752 - val_loss: 0.5648\n","Epoch 195/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4735 - val_loss: 0.5648\n","Epoch 196/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4694 - val_loss: 0.5648\n","Epoch 197/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4761 - val_loss: 0.5648\n","Epoch 198/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4645 - val_loss: 0.5648\n","Epoch 199/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4547 - val_loss: 0.5648\n","Epoch 200/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4711 - val_loss: 0.5648\n","\n","Epoch 00200: ReduceLROnPlateau reducing learning rate to 1.441151835024357e-06.\n","Epoch 201/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4718 - val_loss: 0.5648\n","Epoch 202/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4698 - val_loss: 0.5648\n","Epoch 203/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4703 - val_loss: 0.5649\n","Epoch 204/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4741 - val_loss: 0.5648\n","Epoch 205/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4707 - val_loss: 0.5648\n","Epoch 206/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4678 - val_loss: 0.5648\n","Epoch 207/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4668 - val_loss: 0.5648\n","Epoch 208/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4672 - val_loss: 0.5648\n","Epoch 209/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4733 - val_loss: 0.5648\n","Epoch 210/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4633 - val_loss: 0.5648\n","\n","Epoch 00210: ReduceLROnPlateau reducing learning rate to 1.1529215043992736e-06.\n","Epoch 211/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4668 - val_loss: 0.5648\n","Epoch 212/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4743 - val_loss: 0.5648\n","Epoch 213/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4644 - val_loss: 0.5648\n","Epoch 214/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4761 - val_loss: 0.5648\n","Epoch 215/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4637 - val_loss: 0.5648\n","Epoch 216/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4629 - val_loss: 0.5648\n","Epoch 217/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4732 - val_loss: 0.5648\n","Epoch 218/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4721 - val_loss: 0.5648\n","Epoch 219/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4637 - val_loss: 0.5648\n","Epoch 220/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4660 - val_loss: 0.5648\n","\n","Epoch 00220: ReduceLROnPlateau reducing learning rate to 9.223372217093129e-07.\n","Epoch 221/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4770 - val_loss: 0.5648\n","Epoch 222/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4679 - val_loss: 0.5648\n","Epoch 223/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4695 - val_loss: 0.5648\n","Epoch 224/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4643 - val_loss: 0.5648\n","Epoch 225/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4714 - val_loss: 0.5648\n","Epoch 226/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4621 - val_loss: 0.5648\n","Epoch 227/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4599 - val_loss: 0.5648\n","Epoch 228/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4600 - val_loss: 0.5648\n","Epoch 229/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4645 - val_loss: 0.5648\n","Epoch 230/260\n","31/31 [==============================] - 1s 30ms/step - loss: 0.4587 - val_loss: 0.5648\n","\n","Epoch 00230: ReduceLROnPlateau reducing learning rate to 7.378697773674503e-07.\n","Epoch 231/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4636 - val_loss: 0.5648\n","Epoch 232/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4644 - val_loss: 0.5648\n","Epoch 233/260\n","31/31 [==============================] - 1s 30ms/step - loss: 0.4770 - val_loss: 0.5648\n","Epoch 234/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4687 - val_loss: 0.5648\n","Epoch 235/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4651 - val_loss: 0.5648\n","Epoch 236/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4763 - val_loss: 0.5648\n","Epoch 237/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4537 - val_loss: 0.5648\n","Epoch 238/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4691 - val_loss: 0.5648\n","Epoch 239/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4680 - val_loss: 0.5648\n","Epoch 240/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4660 - val_loss: 0.5648\n","\n","Epoch 00240: ReduceLROnPlateau reducing learning rate to 5.902958037040663e-07.\n","Epoch 241/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4595 - val_loss: 0.5648\n","Epoch 242/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4655 - val_loss: 0.5648\n","Epoch 243/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4698 - val_loss: 0.5648\n","Epoch 244/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4735 - val_loss: 0.5648\n","Epoch 245/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4645 - val_loss: 0.5648\n","Epoch 246/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4573 - val_loss: 0.5648\n","Epoch 247/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4716 - val_loss: 0.5648\n","Epoch 248/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4668 - val_loss: 0.5648\n","Epoch 249/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4653 - val_loss: 0.5648\n","Epoch 250/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4760 - val_loss: 0.5648\n","\n","Epoch 00250: ReduceLROnPlateau reducing learning rate to 4.72236661153147e-07.\n","Epoch 251/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4704 - val_loss: 0.5648\n","Epoch 252/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4676 - val_loss: 0.5648\n","Epoch 253/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4681 - val_loss: 0.5648\n","Epoch 254/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4693 - val_loss: 0.5648\n","Epoch 255/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4644 - val_loss: 0.5648\n","Epoch 256/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4754 - val_loss: 0.5648\n","Epoch 257/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4743 - val_loss: 0.5648\n","Epoch 258/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4671 - val_loss: 0.5648\n","Epoch 259/260\n","31/31 [==============================] - 1s 28ms/step - loss: 0.4718 - val_loss: 0.5648\n","Epoch 260/260\n","31/31 [==============================] - 1s 29ms/step - loss: 0.4592 - val_loss: 0.5648\n","\n","Epoch 00260: ReduceLROnPlateau reducing learning rate to 3.777893198275706e-07.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fab8fb4ecd0>"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"WlyoBaIW-dJr"},"source":["model.save('my_model_0.5647.h5') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g0BrakTiPGdp"},"source":["model = tf.keras.models.load_model('/content/my_model_0.5647.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FcJP03kYIW0k"},"source":["<h3> Model Predicition </h3>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QxAQCoRxo6ix","executionInfo":{"status":"ok","timestamp":1616302686407,"user_tz":-330,"elapsed":1031,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"0cf474b4-95e2-4bd5-f8c9-4cb860952d96"},"source":["int_2_char_input=dict((i, char) for char, i in input_token_index.items())\n","int_2_char_output=dict((i,char) for char, i in output_token_index.items())\n","print(int_2_char_input)\n","print(int_2_char_output)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '/', 16: '0', 17: '1', 18: '2', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9', 26: ':', 27: ';', 28: '<', 29: '=', 30: '>', 31: '?', 32: '@', 33: 'A', 34: 'B', 35: 'C', 36: 'D', 37: 'E', 38: 'F', 39: 'G', 40: 'H', 41: 'I', 42: 'J', 43: 'K', 44: 'L', 45: 'M', 46: 'N', 47: 'O', 48: 'P', 49: 'Q', 50: 'R', 51: 'S', 52: 'T', 53: 'U', 54: 'V', 55: 'W', 56: 'X', 57: 'Y', 58: 'Z', 59: '^', 60: '_', 61: 'a', 62: 'b', 63: 'c', 64: 'd', 65: 'e', 66: 'f', 67: 'g', 68: 'h', 69: 'i', 70: 'j', 71: 'k', 72: 'l', 73: 'm', 74: 'n', 75: 'o', 76: 'p', 77: 'q', 78: 'r', 79: 's', 80: 't', 81: 'u', 82: 'v', 83: 'w', 84: 'x', 85: 'y', 86: 'z', 87: '', 88: '', 89: '', 90: '', 91: '', 92: '', 93: '', 94: '', 95: '', 96: '', 97: '', 98: '', 99: '', 100: '', 101: '', 102: ''}\n","{0: '\\t', 1: '\\n', 2: ' ', 3: '!', 4: '\"', 5: '#', 6: '$', 7: '%', 8: '&', 9: \"'\", 10: '(', 11: ')', 12: '+', 13: ',', 14: '-', 15: '.', 16: '/', 17: '0', 18: '1', 19: '2', 20: '3', 21: '4', 22: '5', 23: '6', 24: '7', 25: '8', 26: '9', 27: ':', 28: ';', 29: '?', 30: '@', 31: 'A', 32: 'B', 33: 'C', 34: 'D', 35: 'E', 36: 'F', 37: 'G', 38: 'H', 39: 'I', 40: 'J', 41: 'K', 42: 'L', 43: 'M', 44: 'N', 45: 'O', 46: 'P', 47: 'Q', 48: 'R', 49: 'S', 50: 'T', 51: 'U', 52: 'V', 53: 'W', 54: 'X', 55: 'Y', 56: 'Z', 57: '_', 58: 'a', 59: 'b', 60: 'c', 61: 'd', 62: 'e', 63: 'f', 64: 'g', 65: 'h', 66: 'i', 67: 'j', 68: 'k', 69: 'l', 70: 'm', 71: 'n', 72: 'o', 73: 'p', 74: 'q', 75: 'r', 76: 's', 77: 't', 78: 'u', 79: 'v', 80: 'w', 81: 'x', 82: 'y', 83: 'z', 84: '', 85: '', 86: '', 87: '', 88: '', 89: '\\u3000', 90: '', 91: ''}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l2f3YLtNj6aT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616302768922,"user_tz":-330,"elapsed":1287,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"ed469ccd-e930-48ef-d34b-5c454274c566"},"source":["\n","encoder_inputs = model.input[0]  # input_1\n","encoder_outputs, state_h_enc = model.layers[2].output  # gru\n","encoder_states = state_h_enc\n","encoder_model = tf.keras.Model(encoder_inputs, encoder_states)\n","\n","encoder_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, None, 103)]       0         \n","_________________________________________________________________\n","gru (GRU)                    [(None, 100), (None, 100) 61500     \n","=================================================================\n","Total params: 61,500\n","Trainable params: 61,500\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"j0IfmDWIiphp","executionInfo":{"status":"ok","timestamp":1616040862884,"user_tz":-330,"elapsed":955,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"dc1ae600-8801-4f2e-a1e4-191e3c099459"},"source":["tf.keras.utils.plot_model(encoder_model, show_shapes=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"XNS4v3JkmzNA","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"ok","timestamp":1616302779326,"user_tz":-330,"elapsed":1840,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"bcb6c179-bd48-4d03-f2ad-3ab5de263165"},"source":["\n","decoder_inputs=model.inputs[1]\n","decoder_state_input_h = tf.keras.Input(shape=(100,))\n","decoder_outputs, state_h_dec= model.layers[3](decoder_inputs, initial_state=decoder_state_input_h)\n","decoder_model = tf.keras.Model([decoder_inputs,decoder_state_input_h],decoder_outputs)\n","decoder_states =state_h_dec\n","decoder_dense = model.layers[4]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = tf.keras.Model((decoder_inputs,decoder_state_input_h),(decoder_outputs,decoder_states))\n","tf.keras.utils.plot_model(decoder_model, show_shapes=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkZwzlpMrQVR","executionInfo":{"status":"ok","timestamp":1616079309837,"user_tz":-330,"elapsed":992,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"87796312-e926-4d13-94a4-e6c001f71ec1"},"source":["decoder_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, None, 92)]   0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","gru_1 (GRU)                     multiple             58200       input_2[0][0]                    \n","                                                                 input_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 92)     9292        gru_1[2][0]                      \n","==================================================================================================\n","Total params: 67,492\n","Trainable params: 67,492\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q0XDSzIHkB65"},"source":["def predictions(input_seq):\n","    #print(np.argmax(input_seq))\n","    states=encoder_model(input_seq)\n","    target_seq = np.zeros((1, 1, 92))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, output_token_index[\"\\t\"]] = 1\n","    stop_condition = False\n","    decoded_sentence = \"\"\n","    \n","    while not stop_condition:\n","        \n","        output_tokens,states= decoder_model((target_seq,states))\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        #print(sampled_token_index)\n","        sampled_char = int_2_char_output[sampled_token_index]\n","        if (sampled_char == '\\n' or len(decoded_sentence) > 202):\n","            stop_condition = True\n","            return decoded_sentence\n","        \n","        decoded_sentence += sampled_char\n","        target_seq = np.zeros((1, 1, 92))\n","        target_seq[0, 0, sampled_token_index] = 1\n","    \n","    return decoded_sentence    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMsHfU7ptSqr","executionInfo":{"status":"ok","timestamp":1616302855636,"user_tz":-330,"elapsed":47767,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"f097f827-cf65-4560-870b-d00f7a5e5f42"},"source":["for seq in range(len(test_data)):\n","    # Take one sequence (part of the training set)\n","    # for trying out decoding.\n","    print(\"English_SENTENCE\")\n","    print(test_data['ENGLISH_OUTPUT'].iloc[seq])\n","    input_seq = cv_encoder_input_data[seq:seq+1]\n","    print(\"Prediction\")\n","    print(predictions(input_seq))\n","    print()\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["English_SENTENCE\n","Yeah. That day I checked, did not have. So how? Where do you want? \n","\n","Prediction\n"," Yes. I am still and stay and then we are at home.                                                                                                                                                         \n","\n","English_SENTENCE\n","I think you can, just get the address from your friends first. Haha, I did a lot of shopping. Felt quite bad, because Aust shop a lot already. \n","\n","Prediction\n"," I think I want to go to the place to see you tomorrow.                                                                                                                                                    \n","\n","English_SENTENCE\n","Oh, want to go there? \n","\n","Prediction\n"," Oh. I am having to chat to go to the exam see you.                                                                                                                                                        \n","\n","English_SENTENCE\n","Are you driving there tomorrow? \n","\n","Prediction\n"," You are going to see you tomorrow?                                                                                                                                                                        \n","\n","English_SENTENCE\n","You occupy seats in the canteen before 2. Then I come out can eat already. \n","\n","Prediction\n"," You are going to see you tomorrow?                                                                                                                                                                        \n","\n","English_SENTENCE\n","Really? Yes, I'll probably see him in camp. Tomorrow is all company going. \n","\n","Prediction\n"," Yes. I am still and stay and then we are at home.                                                                                                                                                         \n","\n","English_SENTENCE\n","Hey, Xin. Are we going for lesson on Thursday? Oh, Friday night we are attending the theory lesson? \n","\n","Prediction\n"," Hey, I am still and me to meet you at the bus the because I want to go to the exam see you.                                                                                                               \n","\n","English_SENTENCE\n","Freshman Orientation Week. It starts this Friday, if you really really want to join, you can come down to school. There will be people around, just ask. \n","\n","Prediction\n"," So what time are you all at the place to see you tomorrow.                                                                                                                                                \n","\n","English_SENTENCE\n","Hey Yijue, how are you getting there later? We are meeting at 7:30 at Orchard MRT. \n","\n","Prediction\n"," Hey, I'm not going to chat?                                                                                                                                                                               \n","\n","English_SENTENCE\n","Hey, do you want to meet outside the lecture theatre? Haha. Time's a little tight though. \n","\n","Prediction\n"," Hey, I will be the too.                                                                                                                                                                                   \n","\n","English_SENTENCE\n","Joey: Hello, are you a boy or a girl? I'm a girl. \n","\n","Prediction\n"," Hey, I will be the too.                                                                                                                                                                                   \n","\n","English_SENTENCE\n","My phone has no battery. Pick me up at 2PM at Drive. Have you all eaten? Faint, here is using Huixin's phone. \n","\n","Prediction\n"," So what time are you all at the place to see you tomorrow.                                                                                                                                                \n","\n","English_SENTENCE\n","My sister does silly things you know. She was arguing with me about Sun's hair and then she accuse me of something I haven't thought of. I hate it when people accuse me. \n","\n","Prediction\n"," So what time are you all at the place to see you tomorrow?                                                                                                                                                \n","\n","English_SENTENCE\n","Bad news. I forgot to put my cash card in when entering ERP. \n","\n","Prediction\n"," You are going to see you tomorrow?                                                                                                                                                                        \n","\n","English_SENTENCE\n","At 5:45 I can. Because I finish work at this time. \n","\n","Prediction\n"," Hey, I will be the too.                                                                                                                                                                                   \n","\n","English_SENTENCE\n","Sorry, didn't check my phone yesterday. By the way, are you free later? Want to visit Fion? \n","\n","Prediction\n"," Yes. I am still and stay and then we are at home.                                                                                                                                                         \n","\n","English_SENTENCE\n","Just came to nydc, she just ordered a baked rice and I ordered a drink. You done already. \n","\n","Prediction\n"," Ok. I am having to chat to go to the place to see you.                                                                                                                                                    \n","\n","English_SENTENCE\n","Hey, I'll go Suntec and find you. Wait for me. I'm on my way. \n","\n","Prediction\n"," Hey, I will be the too.                                                                                                                                                                                   \n","\n","English_SENTENCE\n","Yes. I will be going with my hall. \n","\n","Prediction\n"," Yes. I am still and stay and then we are at home.                                                                                                                                                         \n","\n","English_SENTENCE\n","Sen, are you male or female? \n","\n","Prediction\n"," You are going to see you tomorrow?                                                                                                                                                                        \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UlHuBuqSPXcr","executionInfo":{"status":"ok","timestamp":1616220386192,"user_tz":-330,"elapsed":1420,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"b433cc2c-5a2f-4916-bb5a-77f3412154cc"},"source":["model.evaluate([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 1s 592ms/step - loss: 0.5647\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.564670741558075"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"markdown","metadata":{"id":"-DI5ReTEIcsy"},"source":["<h2> LSTM </h2>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fCaDe9oGk9UX","executionInfo":{"status":"ok","timestamp":1616228493821,"user_tz":-330,"elapsed":1429,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"81881cfc-36ea-4052-f9ce-28b2a68ea529"},"source":["tf.keras.backend.clear_session()\n","encoder_inputs = tf.keras.Input(shape=(None,len(input_token_index)))\n","encoder = tf.keras.layers.LSTM(100, return_state=True)\n","encoder_outputs,state_h,state_c= encoder(encoder_inputs)\n","#storing encoder states\n","encoder_states = [state_h,state_c]\n"," \n","# Set up the decoder, using encoder_states as initial state.\n","decoder_inputs = tf.keras.Input(shape=(None, len(output_token_index)))\n"," \n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_gru = tf.keras.layers.LSTM(100, return_sequences=True, return_state=True)\n","decoder_outputs, _,_ = decoder_gru(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = tf.keras.layers.Dense(len(output_token_index), activation=\"softmax\")\n","decoder_outputs = decoder_dense(decoder_outputs)\n"," \n","# Define the model\n","model2 = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None, 103)]  0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None, 92)]   0                                            \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 100), (None, 81600       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 100),  77200       input_2[0][0]                    \n","                                                                 lstm[0][1]                       \n","                                                                 lstm[0][2]                       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 92)     9292        lstm_1[0][0]                     \n","==================================================================================================\n","Total params: 168,092\n","Trainable params: 168,092\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MEgrLxlHlzAm","executionInfo":{"status":"ok","timestamp":1616228329921,"user_tz":-330,"elapsed":39469,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"4f8e8b47-4fe0-4a7f-8f6a-f4f6683979f5"},"source":["#model with 1% validation data with Adam optimizer.\n","optimizer = tf.keras.optimizers.Adam(0.01)\n","model2.compile(optimizer=optimizer, loss='categorical_crossentropy')\n","model2.fit([encoder_input_data, decoder_input_data],decoder_output_data,validation_data=([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data),batch_size=64,epochs=30,callbacks=[rl])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","31/31 [==============================] - 4s 61ms/step - loss: 2.5045 - val_loss: 1.6449\n","Epoch 2/30\n","31/31 [==============================] - 1s 39ms/step - loss: 1.4840 - val_loss: 1.2629\n","Epoch 3/30\n","31/31 [==============================] - 1s 39ms/step - loss: 1.1281 - val_loss: 1.1174\n","Epoch 4/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.9828 - val_loss: 0.9829\n","Epoch 5/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.8631 - val_loss: 0.9053\n","Epoch 6/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.7890 - val_loss: 0.8511\n","Epoch 7/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.7631 - val_loss: 0.8059\n","Epoch 8/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.7299 - val_loss: 0.7654\n","Epoch 9/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.7120 - val_loss: 0.7320\n","Epoch 10/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.6652 - val_loss: 0.7028\n","Epoch 11/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.6603 - val_loss: 0.6823\n","Epoch 12/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.6148 - val_loss: 0.6549\n","Epoch 13/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.6130 - val_loss: 0.6418\n","Epoch 14/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.6008 - val_loss: 0.6333\n","Epoch 15/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.5831 - val_loss: 0.6242\n","Epoch 16/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.5594 - val_loss: 0.6119\n","Epoch 17/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.5606 - val_loss: 0.6021\n","Epoch 18/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.5446 - val_loss: 0.5917\n","Epoch 19/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.5202 - val_loss: 0.5931\n","Epoch 20/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.5140 - val_loss: 0.5854\n","Epoch 21/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.5128 - val_loss: 0.5749\n","Epoch 22/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.4912 - val_loss: 0.5695\n","Epoch 23/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.4869 - val_loss: 0.5713\n","Epoch 24/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.4860 - val_loss: 0.5624\n","Epoch 25/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.4685 - val_loss: 0.5609\n","Epoch 26/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.4768 - val_loss: 0.5568\n","Epoch 27/30\n","31/31 [==============================] - 1s 38ms/step - loss: 0.4569 - val_loss: 0.5591\n","Epoch 28/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.4712 - val_loss: 0.5533\n","Epoch 29/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.4431 - val_loss: 0.5532\n","Epoch 30/30\n","31/31 [==============================] - 1s 39ms/step - loss: 0.4543 - val_loss: 0.5587\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f30aa46e4d0>"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"JywDf_-BnwQI"},"source":["model2.save('lstm_model_0.5566.h5') "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JocaBQ7sIgye"},"source":["<h3> Model Prediciton </h3>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRWOborbm9yY","executionInfo":{"status":"ok","timestamp":1616228675643,"user_tz":-330,"elapsed":1012,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"26409066-2aac-4d21-9f4c-c867d5c0816b"},"source":["\n","encoder_inputs = model2.input[0]  # input_1\n","encoder_outputs, state_h_enc,state_c_enc = model2.layers[2].output  # gru\n","encoder_states = [state_h_enc,state_c_enc]\n","encoder_model2 = tf.keras.Model(encoder_inputs, encoder_states)\n","\n","encoder_model2.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, None, 103)]       0         \n","_________________________________________________________________\n","lstm (LSTM)                  [(None, 100), (None, 100) 81600     \n","=================================================================\n","Total params: 81,600\n","Trainable params: 81,600\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QpjAncDQotEN"},"source":["\n","decoder_inputs=model2.inputs[1]\n","decoder_state_input_h= tf.keras.Input(shape=(100,))\n","decoder_state_input_c= tf.keras.Input(shape=(100,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_lstm =model2.layers[3]\n","decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h_dec, state_c_dec]\n","decoder_dense = model2.layers[4]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = tf.keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fdz8Sr9qKX1","executionInfo":{"status":"ok","timestamp":1616228681714,"user_tz":-330,"elapsed":1045,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"7409c133-f174-48f2-c1cb-a7cae0fd5f4b"},"source":["decoder_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, None, 92)]   0                                            \n","__________________________________________________________________________________________________\n","input_5 (InputLayer)            [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","input_6 (InputLayer)            [(None, 100)]        0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 100),  77200       input_2[0][0]                    \n","                                                                 input_5[0][0]                    \n","                                                                 input_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, None, 92)     9292        lstm_1[1][0]                     \n","==================================================================================================\n","Total params: 86,492\n","Trainable params: 86,492\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NGChdzw9qXOx"},"source":["def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model2.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, 92))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, output_token_index[\"\\t\"]] = 1\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = \"\"\n","    while not stop_condition:\n","        \n","        output_tokens,hidden_states,cell_states= decoder_model([target_seq] + states_value)\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        #print(sampled_token_index)\n","        sampled_char = int_2_char_output[sampled_token_index]\n","        if (sampled_char == '\\n' or len(decoded_sentence) > 202):\n","            stop_condition = True\n","            return decoded_sentence\n","        \n","        decoded_sentence += sampled_char\n","        target_seq = np.zeros((1, 1, 92))\n","        target_seq[0, 0, sampled_token_index] = 1\n","        states_value = [hidden_states, cell_states]\n","    return decoded_sentence    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mxwXD9jq9ad","executionInfo":{"status":"ok","timestamp":1616228705451,"user_tz":-330,"elapsed":18185,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"b5df3656-c97a-4094-b231-69ae2b298706"},"source":["for seq in range(len(test_data)):\n","    # Take one sequence (part of the training set)\n","    # for trying out decoding.\n","    print(\"English_SENTENCE\")\n","    print(test_data['ENGLISH_OUTPUT'].iloc[seq])\n","    input_seq = cv_encoder_input_data[seq:seq+1]\n","    print(\"Prediction\")\n","    print(decode_sequence(input_seq))\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["English_SENTENCE\n","Yeah. That day I checked, did not have. So how? Where do you want? \n","\n","Prediction\n"," Yes. I am not in the paster the bus still got to buy what time the place to the tomorrow we go to school to see you.                                                                                      \n","\n","English_SENTENCE\n","I think you can, just get the address from your friends first. Haha, I did a lot of shopping. Felt quite bad, because Aust shop a lot already. \n","\n","Prediction\n"," I am still go to see you all can go to school.                                                                                                                                                            \n","\n","English_SENTENCE\n","Oh, want to go there? \n","\n","Prediction\n"," Oh, I will be late of and the place to the tomorrow.                                                                                                                                                      \n","\n","English_SENTENCE\n","Are you driving there tomorrow? \n","\n","Prediction\n"," You are going to go to school then can you all can go to school to see you.                                                                                                                               \n","\n","English_SENTENCE\n","You occupy seats in the canteen before 2. Then I come out can eat already. \n","\n","Prediction\n"," You are going to go to school then can you all can go to school to see you.                                                                                                                               \n","\n","English_SENTENCE\n","Really? Yes, I'll probably see him in camp. Tomorrow is all company going. \n","\n","Prediction\n"," No. I am not in the the same too lesson.                                                                                                                                                                  \n","\n","English_SENTENCE\n","Hey, Xin. Are we going for lesson on Thursday? Oh, Friday night we are attending the theory lesson? \n","\n","Prediction\n"," Hey I will be late of and the place.                                                                                                                                                                      \n","\n","English_SENTENCE\n","Freshman Orientation Week. It starts this Friday, if you really really want to join, you can come down to school. There will be people around, just ask. \n","\n","Prediction\n"," Can you be the phone number?                                                                                                                                                                              \n","\n","English_SENTENCE\n","Hey Yijue, how are you getting there later? We are meeting at 7:30 at Orchard MRT. \n","\n","Prediction\n"," Hey, you got to go to the move your handphone number to school?                                                                                                                                           \n","\n","English_SENTENCE\n","Hey, do you want to meet outside the lecture theatre? Haha. Time's a little tight though. \n","\n","Prediction\n"," Hey, you got to go to the move your handphone number to school?                                                                                                                                           \n","\n","English_SENTENCE\n","Joey: Hello, are you a boy or a girl? I'm a girl. \n","\n","Prediction\n"," Hey I will be late of and the place.                                                                                                                                                                      \n","\n","English_SENTENCE\n","My phone has no battery. Pick me up at 2PM at Drive. Have you all eaten? Faint, here is using Huixin's phone. \n","\n","Prediction\n"," What are you all at the phone?                                                                                                                                                                            \n","\n","English_SENTENCE\n","My sister does silly things you know. She was arguing with me about Sun's hair and then she accuse me of something I haven't thought of. I hate it when people accuse me. \n","\n","Prediction\n"," What are you all at the phone?                                                                                                                                                                            \n","\n","English_SENTENCE\n","Bad news. I forgot to put my cash card in when entering ERP. \n","\n","Prediction\n"," Lea, the same too talk to you are going to see you.                                                                                                                                                       \n","\n","English_SENTENCE\n","At 5:45 I can. Because I finish work at this time. \n","\n","Prediction\n"," Yes. I am not in the paster the bus still got to buy what time the place to the tomorrow we go to school to see you.                                                                                      \n","\n","English_SENTENCE\n","Sorry, didn't check my phone yesterday. By the way, are you free later? Want to visit Fion? \n","\n","Prediction\n"," Can you be the phone number?                                                                                                                                                                              \n","\n","English_SENTENCE\n","Just came to nydc, she just ordered a baked rice and I ordered a drink. You done already. \n","\n","Prediction\n"," Yes. I am not in the paster the bus still got to buy what time the place to the tomorrow we go to school to see you.                                                                                      \n","\n","English_SENTENCE\n","Hey, I'll go Suntec and find you. Wait for me. I'm on my way. \n","\n","Prediction\n"," Hey, you got to go to the move your handphone number to school?                                                                                                                                           \n","\n","English_SENTENCE\n","Yes. I will be going with my hall. \n","\n","Prediction\n"," Yes. I am not in the paster the bus still got to buy what time the place to the tomorrow we go to school to see you.                                                                                      \n","\n","English_SENTENCE\n","Sen, are you male or female? \n","\n","Prediction\n"," Oh, I will be late of and the place to the tomorrow.                                                                                                                                                      \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fuPf3XhvsXQC"},"source":["model2 = tf.keras.models.load_model('/content/lstm_model_0.5566.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Hc7BjF7shAV","executionInfo":{"status":"ok","timestamp":1616228599178,"user_tz":-330,"elapsed":1390,"user":{"displayName":"Nipun Agrawal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEnTNOPKYA066Ly1RwsNs4132AgrMH5fVw2BuEAw=s64","userId":"18285146514188802906"}},"outputId":"808f5a32-b7de-4195-9d25-fdc73e0ea1d9"},"source":["model2.evaluate([cv_encoder_input_data,cv_decoder_input_data],cv_decoder_output_data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 1s 576ms/step - loss: 0.5556\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.5555940866470337"]},"metadata":{"tags":[]},"execution_count":62}]}]}